{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405b22a-d2cd-4af3-bdfe-5baa698d0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELDA 1 — Imports + rutas del repo + outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a786ed0-4cbe-4d2a-b6e9-4edac549dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# stats\n",
    "try:\n",
    "    from scipy.stats import ttest_ind\n",
    "    HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    HAVE_SCIPY = False\n",
    "\n",
    "from src.paths import project_paths\n",
    "\n",
    "P = project_paths(Path.cwd())\n",
    "PROJECT_ROOT = P[\"PROJECT_ROOT\"]\n",
    "RESULTS_DIR  = P[\"RESULTS_DIR\"]\n",
    "FIGURES_DIR  = P[\"FIGURES_DIR\"]\n",
    "\n",
    "OUT_SUMMARY = RESULTS_DIR / \"summary_tables\" / \"pseudobulk_de\"\n",
    "OUT_FIG     = FIGURES_DIR / \"pseudobulk_de\"\n",
    "OUT_SUMMARY.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RESULTS_DIR :\", RESULTS_DIR)\n",
    "print(\"FIGURES_DIR :\", FIGURES_DIR)\n",
    "print(\"OUT_SUMMARY :\", OUT_SUMMARY)\n",
    "print(\"OUT_FIG     :\", OUT_FIG)\n",
    "print(\"SciPy ttest :\", HAVE_SCIPY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb17c12-096c-4c3e-836e-7260fbd912ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELDA 2 — Localizar input h5ad + Level2_final_map.json (robusto) + parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68318942-3e16-4fe1-a62e-b5d6bb7e5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Inputs (robusto a legado)\n",
    "# -----------------------------\n",
    "IN_PATH_CANDIDATES = [\n",
    "    RESULTS_DIR / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\",\n",
    "    RESULTS_DIR / \"main\" / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\",\n",
    "    PROJECT_ROOT / \"data_processed\" / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\",  # legacy\n",
    "]\n",
    "IN_PATH = next((p for p in IN_PATH_CANDIDATES if p.exists()), None)\n",
    "print(\"IN_PATH:\", IN_PATH)\n",
    "if IN_PATH is None:\n",
    "    raise FileNotFoundError(\"No encuentro el .h5ad filtrado. Probé:\\n\" + \"\\n\".join([f\"- {x}\" for x in IN_PATH_CANDIDATES]))\n",
    "\n",
    "MAP_PATH_CANDIDATES = [\n",
    "    RESULTS_DIR / \"summary_tables_final\" / \"Level2_final_map.json\",      # legacy\n",
    "    RESULTS_DIR / \"summary_tables\" / \"Level2_final_map.json\",\n",
    "    PROJECT_ROOT / \"summary_tables_final\" / \"Level2_final_map.json\",     # legacy (fuera de results)\n",
    "]\n",
    "MAP_PATH = next((p for p in MAP_PATH_CANDIDATES if p.exists()), None)\n",
    "print(\"MAP_PATH:\", MAP_PATH)\n",
    "\n",
    "# -----------------------------\n",
    "# Parámetros\n",
    "# -----------------------------\n",
    "LAYER = \"log1p_10k\"\n",
    "\n",
    "# Modo:\n",
    "ANALYSIS_LEVEL = \"Level2_final\"   # \"Level2_final\" (recomendado) o \"Level1_refined\"\n",
    "\n",
    "# Etiquetas disease (deben existir tal cual en obs['disease'])\n",
    "CONTROL_LABEL = \"Healthy\"\n",
    "CASE_LABEL    = \"Cirrhosis\"\n",
    "\n",
    "# Targets a correr (si ANALYSIS_LEVEL == \"Level2_final\")\n",
    "LEVEL2_FINAL_TO_RUN = [\n",
    "    # B / Plasma\n",
    "    \"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"Plasma\",\n",
    "    # T\n",
    "    \"CD4_Naive\", \"CD4_Memory\", \"CD8_Naive\", \"CD8_Effector_Cytotoxic\", \"Treg\", \"MAIT\", \"GammaDelta_T\",\n",
    "    # NK\n",
    "    \"NK\",\n",
    "    # Mono / DC\n",
    "    \"Classical_Mono\", \"NonClassical_Mono\", \"ISG_Myeloid\", \"MonoDC_Other\",\n",
    "    \"cDC1\", \"cDC2\", \"DC3\", \"DC4\", \"aDC\",\n",
    "    # pDC / HSCs (si existen y quieres)\n",
    "    \"pDC\", \"HSCs\",\n",
    "]\n",
    "\n",
    "# Targets legacy (si ANALYSIS_LEVEL == \"Level1_refined\")\n",
    "LEVEL1_TO_RUN = [\"T\", \"Mono\", \"NK\", \"B\", \"DC\"]\n",
    "\n",
    "# Genes\n",
    "GENE_MODE = \"HVG\"     # \"HVG\" recomendado\n",
    "MAX_GENES = 2000\n",
    "GENE_CHUNK = 200\n",
    "\n",
    "# Estadística / umbrales\n",
    "PSEUDOCOUNT = 1e-6\n",
    "ALPHA_FDR = 0.05\n",
    "\n",
    "# Filtrado pacientes por target\n",
    "MIN_CELLS_PER_PATIENT = 20\n",
    "MIN_PATIENTS_PER_GROUP = 4\n",
    "MIN_PATIENTS_PER_TARGET = 6\n",
    "\n",
    "# RBC-out robusto\n",
    "EXCLUDE_LEVEL1REFINED = {\"RBC\"}\n",
    "EXCLUDE_LEVEL2 = {\"RBC\"}\n",
    "\n",
    "# Volcano “FOR_FIGURE”\n",
    "MIN_ABS_LOG2FC = 0.5\n",
    "MIN_MEAN_LOG1P = 0.20\n",
    "MIN_FRAC_PATIENTS = 0.50\n",
    "TOP_N_LABEL = 20\n",
    "\n",
    "# Blacklist opcional para linfoides (solo afecta highlights/labels)\n",
    "AMBIENT_MYELOID = {\"S100A8\",\"S100A9\",\"S100A12\",\"LYZ\",\"LST1\",\"TREM1\",\"CXCL8\"}\n",
    "APPLY_BLACKLIST_FOR_GROUPS = {\"T\", \"NK\", \"B\"}  # linfoides\n",
    "\n",
    "FC_COL = \"log2FC_Healthy_vs_Cirrhosis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f135c-baec-457d-b633-ec517dfeb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELDA 3 — Helpers (FDR, tags, genes, volcán, grupos Level2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550cde3-6912-478f-9640-b6a4cdf6a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bh_fdr(pvals: np.ndarray) -> np.ndarray:\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    n = p.size\n",
    "    order = np.argsort(p)\n",
    "    ranked = p[order]\n",
    "    q = ranked * n / (np.arange(1, n + 1))\n",
    "    q = np.minimum.accumulate(q[::-1])[::-1]\n",
    "    out = np.empty_like(q)\n",
    "    out[order] = np.clip(q, 0, 1)\n",
    "    return out\n",
    "\n",
    "def safe_tag(name: str) -> str:\n",
    "    s = str(name).strip().replace(\" \", \"_\")\n",
    "    s = re.sub(r\"[^A-Za-z0-9_\\-\\.]+\", \"_\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s)\n",
    "    return s\n",
    "\n",
    "def get_gene_list(adata_b) -> List[str]:\n",
    "    if GENE_MODE == \"HVG\" and \"highly_variable\" in adata_b.var.columns:\n",
    "        hv = adata_b.var[\"highly_variable\"].values.astype(bool)\n",
    "        genes = adata_b.var_names[hv].tolist()\n",
    "        if len(genes) == 0:\n",
    "            print(\"[WARN] highly_variable existe pero vacío; uso primeras MAX_GENES.\")\n",
    "            genes = adata_b.var_names[:MAX_GENES].tolist()\n",
    "        else:\n",
    "            genes = genes[:MAX_GENES]\n",
    "        return genes\n",
    "    return adata_b.var_names[:MAX_GENES].tolist()\n",
    "\n",
    "def ensure_fc_col(df: pd.DataFrame, where: str = \"\") -> pd.DataFrame:\n",
    "    if FC_COL in df.columns:\n",
    "        return df\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        cl = str(c).lower()\n",
    "        if \"log2fc\" in cl or \"logfc\" in cl or (\"fold\" in cl and \"log\" in cl):\n",
    "            candidates.append(c)\n",
    "    if len(candidates) == 1:\n",
    "        print(f\"[WARN] {where}: renombrando columna '{candidates[0]}' -> '{FC_COL}'\")\n",
    "        return df.rename(columns={candidates[0]: FC_COL})\n",
    "    raise KeyError(f\"[{where}] No encuentro '{FC_COL}'. Columnas={df.columns.tolist()}\")\n",
    "\n",
    "def volcano_plot_base(df_de: pd.DataFrame, out_png: Path, title: str, alpha_fdr: float = 0.05):\n",
    "    df_de = ensure_fc_col(df_de, where=f\"volcano_plot_base({out_png.name})\")\n",
    "    x = df_de[FC_COL].to_numpy(dtype=float)\n",
    "    q = df_de[\"FDR\"].to_numpy(dtype=float)\n",
    "    y = -np.log10(np.clip(q, 1e-300, 1.0))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
    "    ax.scatter(x, y, s=10, alpha=0.8)\n",
    "    ax.axhline(-np.log10(alpha_fdr), linestyle=\"--\", linewidth=1)\n",
    "    ax.axvline(0, linestyle=\":\", linewidth=1)\n",
    "    ax.set_xlabel(\"log2FC (Healthy vs Cirrhosis) [pseudobulk per patient]\")\n",
    "    ax.set_ylabel(\"-log10(FDR)\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def volcano_for_figure(\n",
    "    df_all: pd.DataFrame,\n",
    "    out_png: Path,\n",
    "    title: str,\n",
    "    alpha_fdr: float = 0.05,\n",
    "    highlight_mask: Optional[np.ndarray] = None,\n",
    "    genes_to_label: Optional[List[str]] = None,\n",
    "    abs_log2fc_line: Optional[float] = None,\n",
    "):\n",
    "    df_all = ensure_fc_col(df_all, where=f\"volcano_for_figure({out_png.name})\")\n",
    "    x = df_all[FC_COL].to_numpy(dtype=float)\n",
    "    q = df_all[\"FDR\"].to_numpy(dtype=float)\n",
    "    y = -np.log10(np.clip(q, 1e-300, 1.0))\n",
    "\n",
    "    sig = q < alpha_fdr\n",
    "    up = sig & (x > 0)\n",
    "    down = sig & (x < 0)\n",
    "    ns = ~sig\n",
    "\n",
    "    cycle = plt.rcParams[\"axes.prop_cycle\"].by_key().get(\"color\", [\"C0\",\"C1\",\"C2\",\"C3\"])\n",
    "    col_down = cycle[0 % len(cycle)]\n",
    "    col_up   = cycle[1 % len(cycle)]\n",
    "    col_ns   = \"0.75\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.8, 5.8))\n",
    "    ax.scatter(x[ns], y[ns], s=10, alpha=0.6, c=col_ns, edgecolors=\"none\", label=\"Not significant\")\n",
    "    ax.scatter(x[down], y[down], s=12, alpha=0.85, c=col_down, edgecolors=\"none\",\n",
    "               label=f\"FDR<{alpha_fdr} (Higher in Cirrhosis)\")\n",
    "    ax.scatter(x[up], y[up], s=12, alpha=0.85, c=col_up, edgecolors=\"none\",\n",
    "               label=f\"FDR<{alpha_fdr} (Higher in Healthy)\")\n",
    "\n",
    "    if highlight_mask is not None:\n",
    "        hm = np.asarray(highlight_mask, dtype=bool)\n",
    "        hm = hm & np.isfinite(x) & np.isfinite(y)\n",
    "        ax.scatter(x[hm], y[hm], s=26, alpha=0.95, facecolors=\"none\", edgecolors=\"k\", linewidths=0.7,\n",
    "                   label=\"Highlighted (filters)\")\n",
    "\n",
    "    ax.axhline(-np.log10(alpha_fdr), linestyle=\"--\", linewidth=1)\n",
    "    ax.axvline(0, linestyle=\":\", linewidth=1)\n",
    "    if abs_log2fc_line is not None and abs_log2fc_line > 0:\n",
    "        ax.axvline(+abs_log2fc_line, linestyle=\"--\", linewidth=0.8)\n",
    "        ax.axvline(-abs_log2fc_line, linestyle=\"--\", linewidth=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"log2FC (Healthy vs Cirrhosis) [pseudobulk per patient]\")\n",
    "    ax.set_ylabel(\"-log10(FDR)\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend(frameon=False, fontsize=8, loc=\"upper right\")\n",
    "\n",
    "    if genes_to_label:\n",
    "        df_lab = df_all[df_all[\"gene\"].astype(str).isin([str(g) for g in genes_to_label])].copy()\n",
    "        df_lab = df_lab.sort_values(\"FDR\", ascending=True)\n",
    "        offsets = [(6, 6), (6, -10), (-18, 6), (-18, -10)]\n",
    "        for k, (_, r) in enumerate(df_lab.iterrows()):\n",
    "            gx = float(r[FC_COL])\n",
    "            gy = -np.log10(max(float(r[\"FDR\"]), 1e-300))\n",
    "            ox, oy = offsets[k % len(offsets)]\n",
    "            ax.annotate(\n",
    "                str(r[\"gene\"]), (gx, gy),\n",
    "                textcoords=\"offset points\", xytext=(ox, oy),\n",
    "                ha=\"left\", fontsize=8,\n",
    "                arrowprops=dict(arrowstyle=\"-\", lw=0.4, alpha=0.6),\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Grupos (para decidir blacklist en highlights/labels)\n",
    "order_by_group = {\n",
    "    \"B\":     [\"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"B_Other\"],\n",
    "    \"Plasma\":[\"Plasma\"],\n",
    "    \"pDC\":   [\"pDC\"],\n",
    "    \"T\":     [\"CD4_Naive\",\"CD4_Memory\",\"CD8_Naive\",\"CD8_Effector_Cytotoxic\",\"Treg\",\"MAIT\",\"GammaDelta_T\",\"Proliferative_T\",\"Exhausted_T\"],\n",
    "    \"NK\":    [\"NK\"],\n",
    "    \"Mono\":  [\"Classical_Mono\",\"NonClassical_Mono\",\"ISG_Myeloid\",\"MonoDC_Other\"],\n",
    "    \"DC\":    [\"cDC1\",\"cDC2\",\"DC3\",\"DC4\",\"aDC\"],\n",
    "    \"HSCs\":  [\"HSCs\"],\n",
    "}\n",
    "\n",
    "def group_of_l2(l2: str) -> str:\n",
    "    for g, l2_list in order_by_group.items():\n",
    "        if l2 in l2_list:\n",
    "            return g\n",
    "    return \"Other\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab0f64d-499b-4c8f-aa2d-7db9e75b5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELDA 4 — Abrir objeto backed + preparar obs + Level2_final + seleccionar targets/genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185557fd-143e-4538-b0b4-671d051502bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) cargar mapa Level2_final\n",
    "level2_map = {}\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    if MAP_PATH is None:\n",
    "        raise FileNotFoundError(\n",
    "            \"ANALYSIS_LEVEL=Level2_final pero no encuentro Level2_final_map.json.\\nProbé:\\n\"\n",
    "            + \"\\n\".join([f\"- {x}\" for x in MAP_PATH_CANDIDATES])\n",
    "        )\n",
    "    with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        level2_map = json.load(f)\n",
    "    print(\"Loaded Level2_final_map:\", level2_map)\n",
    "\n",
    "# 1) cargar h5ad backed\n",
    "adata_b = sc.read_h5ad(IN_PATH, backed=\"r\")\n",
    "print(\"Loaded:\", adata_b)\n",
    "\n",
    "required_obs = [\"patientID\", \"disease\", \"Level1_refined\"]\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    required_obs.append(\"Level2\")\n",
    "\n",
    "for col in required_obs:\n",
    "    if col not in adata_b.obs.columns:\n",
    "        adata_b.file.close()\n",
    "        raise KeyError(f\"Falta columna en obs: {col}\")\n",
    "\n",
    "if LAYER not in adata_b.layers.keys():\n",
    "    adata_b.file.close()\n",
    "    raise KeyError(f\"No existe layer '{LAYER}' en adata.layers. Layers: {list(adata_b.layers.keys())}\")\n",
    "\n",
    "obs = adata_b.obs[required_obs].copy()\n",
    "obs[\"patientID\"] = obs[\"patientID\"].astype(str)\n",
    "obs[\"disease\"]   = obs[\"disease\"].astype(str)\n",
    "obs[\"Level1_refined\"] = obs[\"Level1_refined\"].astype(str)\n",
    "\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    l2_obj = obs[\"Level2\"].astype(\"object\")  # NO str antes de mapear (evita NaN->\"nan\")\n",
    "    obs[\"Level2_final\"] = l2_obj.replace(level2_map).astype(\"object\")\n",
    "\n",
    "# RBC-out robusto\n",
    "valid_mask_global = ~obs[\"Level1_refined\"].isin(EXCLUDE_LEVEL1REFINED)\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    valid_mask_global = valid_mask_global & (~obs[\"Level2_final\"].astype(str).isin(EXCLUDE_LEVEL2))\n",
    "\n",
    "# patient meta\n",
    "patient_meta = (\n",
    "    obs.loc[valid_mask_global, [\"patientID\", \"disease\"]]\n",
    "       .drop_duplicates([\"patientID\", \"disease\"])\n",
    "       .set_index(\"patientID\")\n",
    ")\n",
    "patients = patient_meta.index.tolist()\n",
    "\n",
    "print(\"\\nPatients:\", len(patients))\n",
    "print(patient_meta[\"disease\"].value_counts())\n",
    "\n",
    "# genes\n",
    "genes = get_gene_list(adata_b)\n",
    "print(\"\\nGenes used:\", len(genes), f\"(mode={GENE_MODE}, MAX_GENES={MAX_GENES})\")\n",
    "\n",
    "# targets\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    target_col = \"Level2_final\"\n",
    "    targets = list(LEVEL2_FINAL_TO_RUN)\n",
    "else:\n",
    "    target_col = \"Level1_refined\"\n",
    "    targets = list(LEVEL1_TO_RUN)\n",
    "\n",
    "present_targets = set(obs.loc[valid_mask_global, target_col].dropna().astype(str).unique().tolist())\n",
    "missing_targets = [t for t in targets if t not in present_targets]\n",
    "targets = [t for t in targets if t in present_targets]\n",
    "\n",
    "print(\"\\nANALYSIS_LEVEL:\", ANALYSIS_LEVEL)\n",
    "print(\"target_col    :\", target_col)\n",
    "print(\"Targets presentes:\", len(targets))\n",
    "if missing_targets:\n",
    "    print(\"[INFO] Targets no presentes (omitidos):\", missing_targets)\n",
    "\n",
    "# sanity disease labels\n",
    "disease_levels = sorted(patient_meta[\"disease\"].unique().tolist())\n",
    "print(\"\\nDisease levels:\", disease_levels)\n",
    "if CONTROL_LABEL not in disease_levels or CASE_LABEL not in disease_levels:\n",
    "    print(\"[WARN] CONTROL_LABEL/CASE_LABEL no encontrados tal cual en disease_levels.\")\n",
    "    print(\"       Ajusta CONTROL_LABEL y CASE_LABEL en parámetros si hace falta.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6214b991-e7cf-4995-93b2-06237a12c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELDA 5 — Pseudobulk + DE + volcano base (por target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9db734-2a92-480a-9ac6-e820a3250a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_summary: List[Tuple[str, int, str]] = []\n",
    "\n",
    "for target in targets:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"{ANALYSIS_LEVEL} target:\", target)\n",
    "\n",
    "    mask_target = valid_mask_global & (obs[target_col].astype(str).values == str(target))\n",
    "\n",
    "    # index cells por paciente\n",
    "    idx_by_patient: Dict[str, np.ndarray] = {}\n",
    "    n_cells_by_patient: Dict[str, int] = {}\n",
    "    for pid in patients:\n",
    "        idx = np.where(mask_target.values & (obs[\"patientID\"].values == pid))[0]\n",
    "        idx_by_patient[pid] = idx\n",
    "        n_cells_by_patient[pid] = int(idx.size)\n",
    "\n",
    "    keep_pids = [pid for pid, n in n_cells_by_patient.items() if n >= MIN_CELLS_PER_PATIENT]\n",
    "    print(f\"Pacientes con >={MIN_CELLS_PER_PATIENT} células:\", len(keep_pids), \"/\", len(patients))\n",
    "\n",
    "    if len(keep_pids) < MIN_PATIENTS_PER_TARGET:\n",
    "        print(\"[SKIP] Muy pocos pacientes con suficientes células para este target.\")\n",
    "        results_summary.append((str(target), len(keep_pids), \"SKIP_low_n\"))\n",
    "        continue\n",
    "\n",
    "    # construir pseudobulk mean(log1p) por paciente con chunks de genes\n",
    "    pb = np.full((len(keep_pids), len(genes)), np.nan, dtype=np.float32)\n",
    "    diseases: List[str] = []\n",
    "\n",
    "    for i, pid in enumerate(keep_pids):\n",
    "        idx_cells = idx_by_patient[pid]\n",
    "        n = idx_cells.size\n",
    "        diseases.append(patient_meta.loc[pid, \"disease\"])\n",
    "\n",
    "        sums = np.zeros(len(genes), dtype=np.float64)\n",
    "\n",
    "        for start in range(0, len(genes), GENE_CHUNK):\n",
    "            gchunk = genes[start:start + GENE_CHUNK]\n",
    "            view = adata_b[idx_cells, gchunk]\n",
    "            X = view.layers[LAYER]\n",
    "            chunk_sum = np.asarray(X.sum(axis=0)).ravel()\n",
    "            sums[start:start + len(gchunk)] = chunk_sum\n",
    "\n",
    "        pb[i, :] = (sums / float(n)).astype(np.float32)\n",
    "\n",
    "    diseases = np.array(diseases, dtype=str)\n",
    "    keep_pids = np.array(keep_pids, dtype=str)\n",
    "\n",
    "    df_pb = pd.DataFrame(pb, index=keep_pids, columns=genes)\n",
    "    df_pb.insert(0, \"disease\", diseases)\n",
    "\n",
    "    tag = safe_tag(target)\n",
    "    out_pb_csv = OUT_SUMMARY / f\"pseudobulk_{ANALYSIS_LEVEL}_{tag}_mean_{LAYER}.csv\"\n",
    "    df_pb.to_csv(out_pb_csv)\n",
    "    print(\"Saved pseudobulk:\", out_pb_csv)\n",
    "\n",
    "    # DE (paciente-level)\n",
    "    A_case = (df_pb[\"disease\"].values == CASE_LABEL)      # Cirrhosis\n",
    "    B_ctrl = (df_pb[\"disease\"].values == CONTROL_LABEL)   # Healthy\n",
    "    nA, nB = int(A_case.sum()), int(B_ctrl.sum())\n",
    "    print(f\"n patients {CASE_LABEL}:\", nA, \"|\", CONTROL_LABEL, \":\", nB)\n",
    "\n",
    "    if nA < MIN_PATIENTS_PER_GROUP or nB < MIN_PATIENTS_PER_GROUP:\n",
    "        print(\"[SKIP] Muy pocos pacientes por grupo para DE en este target.\")\n",
    "        results_summary.append((str(target), len(keep_pids), \"SKIP_group_n\"))\n",
    "        continue\n",
    "\n",
    "    # log2FC en escala lineal aproximada: expm1(mean log1p)\n",
    "    X_lin = np.expm1(df_pb[genes].values.astype(np.float64))\n",
    "    meanA = np.nanmean(X_lin[A_case, :], axis=0)  # CASE\n",
    "    meanB = np.nanmean(X_lin[B_ctrl, :], axis=0)  # CONTROL\n",
    "    log2fc = np.log2((meanB + PSEUDOCOUNT) / (meanA + PSEUDOCOUNT))  # Healthy vs Cirrhosis\n",
    "\n",
    "    # pvals: Welch t-test sobre pseudobulk log1p (paciente-level)\n",
    "    X_log = df_pb[genes].values.astype(np.float64)\n",
    "    if HAVE_SCIPY:\n",
    "        _, pvals = ttest_ind(X_log[B_ctrl, :], X_log[A_case, :], axis=0, equal_var=False, nan_policy=\"omit\")\n",
    "        pvals = np.nan_to_num(pvals, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "    else:\n",
    "        pvals = np.ones_like(log2fc, dtype=float)\n",
    "\n",
    "    fdr = bh_fdr(pvals)\n",
    "\n",
    "    df_de = pd.DataFrame({\n",
    "        \"gene\": genes,\n",
    "        f\"mean_lin_{CASE_LABEL}\": meanA,\n",
    "        f\"mean_lin_{CONTROL_LABEL}\": meanB,\n",
    "        FC_COL: log2fc,\n",
    "        \"pval\": pvals,\n",
    "        \"FDR\": fdr,\n",
    "    }).sort_values(\"FDR\", ascending=True)\n",
    "\n",
    "    out_de_csv = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_{CONTROL_LABEL}_vs_{CASE_LABEL}.csv\"\n",
    "    df_de.to_csv(out_de_csv, index=False)\n",
    "    print(\"Saved DE:\", out_de_csv)\n",
    "\n",
    "    out_png = OUT_FIG / f\"Volcano_pseudobulk_{ANALYSIS_LEVEL}_{tag}_{CONTROL_LABEL}_vs_{CASE_LABEL}.png\"\n",
    "    volcano_plot_base(\n",
    "        df_de,\n",
    "        out_png,\n",
    "        title=f\"{ANALYSIS_LEVEL}={target}: {CONTROL_LABEL} vs {CASE_LABEL} (pseudobulk, per patient)\",\n",
    "        alpha_fdr=ALPHA_FDR\n",
    "    )\n",
    "    print(\"Saved volcano (base):\", out_png)\n",
    "\n",
    "    n_sig = int((df_de[\"FDR\"].values < ALPHA_FDR).sum())\n",
    "    results_summary.append((str(target), len(keep_pids), f\"OK_sigFDR<{ALPHA_FDR}:{n_sig}\"))\n",
    "\n",
    "# cerrar backed\n",
    "adata_b.file.close()\n",
    "\n",
    "print(\"\\n=== RESUMEN (base) ===\")\n",
    "for row in results_summary:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\n[OK] Pseudobulk + DE + volcano (base) terminado.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b418c51-7177-4c5f-b1fc-70da4c94d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELDA 6 — Volcano “FOR_FIGURE” + CSV filtrado por target (all genes + highlights + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc152ef-b21f-4417-b84c-1f3831597e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[SEC6] Generando volcanos FOR_FIGURE (all genes + highlights + TOP labels) ...\")\n",
    "\n",
    "sec6_summary: List[Tuple[str, int, int]] = []\n",
    "targets_for_figure_generated: List[str] = []\n",
    "\n",
    "for target in targets:\n",
    "    tag = safe_tag(target)\n",
    "\n",
    "    de_path = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_{CONTROL_LABEL}_vs_{CASE_LABEL}.csv\"\n",
    "    pb_path = OUT_SUMMARY / f\"pseudobulk_{ANALYSIS_LEVEL}_{tag}_mean_{LAYER}.csv\"\n",
    "\n",
    "    if not de_path.exists() or not pb_path.exists():\n",
    "        print(\"[SKIP] faltan archivos para\", target)\n",
    "        continue\n",
    "\n",
    "    df_de = pd.read_csv(de_path)\n",
    "    df_de = ensure_fc_col(df_de, where=str(de_path))\n",
    "\n",
    "    df_pb = pd.read_csv(pb_path, index_col=0)  # patientID índice\n",
    "    gene_cols = [c for c in df_pb.columns if c != \"disease\"]\n",
    "\n",
    "    X = df_pb[gene_cols].astype(float).values\n",
    "    mean_log1p = X.mean(axis=0)\n",
    "    frac_pat = (X > 0.10).mean(axis=0)  # fracción de pacientes con mean_log1p>0.10\n",
    "\n",
    "    df_f = df_de.merge(\n",
    "        pd.DataFrame({\"gene\": gene_cols, \"mean_log1p\": mean_log1p, \"frac_patients\": frac_pat}),\n",
    "        on=\"gene\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    df_f = ensure_fc_col(df_f, where=f\"merge(df_de, df_pb) target={target}\")\n",
    "\n",
    "    # filtros de highlight\n",
    "    keep = (\n",
    "        (df_f[\"FDR\"] < ALPHA_FDR) &\n",
    "        (df_f[FC_COL].abs() >= MIN_ABS_LOG2FC) &\n",
    "        (df_f[\"mean_log1p\"] >= MIN_MEAN_LOG1P) &\n",
    "        (df_f[\"frac_patients\"] >= MIN_FRAC_PATIENTS)\n",
    "    )\n",
    "\n",
    "    keep2 = keep.copy()\n",
    "\n",
    "    # blacklist SOLO para highlights/labels, según grupo (linfoides)\n",
    "    if ANALYSIS_LEVEL == \"Level1_refined\":\n",
    "        apply_blacklist = (str(target) in {\"T\", \"NK\", \"B\"})\n",
    "    else:\n",
    "        apply_blacklist = (group_of_l2(str(target)) in APPLY_BLACKLIST_FOR_GROUPS)\n",
    "\n",
    "    if apply_blacklist:\n",
    "        keep2 = keep2 & (~df_f[\"gene\"].isin(AMBIENT_MYELOID))\n",
    "\n",
    "    df_plot = df_f.loc[keep2].copy().sort_values(\"FDR\", ascending=True)\n",
    "\n",
    "    out_csv = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_{CONTROL_LABEL}_vs_{CASE_LABEL}_FOR_FIGURE.csv\"\n",
    "    df_plot.to_csv(out_csv, index=False)\n",
    "\n",
    "    # genes a etiquetar (balanceado up/down por FDR)\n",
    "    cand = df_f.loc[keep2].copy().sort_values(\"FDR\", ascending=True)\n",
    "    n_each = TOP_N_LABEL // 2\n",
    "    cand_up = cand[cand[FC_COL] > 0].head(n_each)\n",
    "    cand_dn = cand[cand[FC_COL] < 0].head(n_each)\n",
    "\n",
    "    genes_to_label = pd.concat([cand_up, cand_dn], axis=0)[\"gene\"].astype(str).tolist()\n",
    "    if len(genes_to_label) < TOP_N_LABEL:\n",
    "        extra = cand[~cand[\"gene\"].astype(str).isin(genes_to_label)].head(TOP_N_LABEL - len(genes_to_label))\n",
    "        genes_to_label += extra[\"gene\"].astype(str).tolist()\n",
    "\n",
    "    out_png = OUT_FIG / f\"Volcano_pseudobulk_{ANALYSIS_LEVEL}_{tag}_{CONTROL_LABEL}_vs_{CASE_LABEL}_FOR_FIGURE.png\"\n",
    "    volcano_for_figure(\n",
    "        df_all=df_f,\n",
    "        out_png=out_png,\n",
    "        title=f\"{ANALYSIS_LEVEL}={target}: {CONTROL_LABEL} vs {CASE_LABEL} (pseudobulk) — volcano (all genes)\",\n",
    "        alpha_fdr=ALPHA_FDR,\n",
    "        highlight_mask=keep2.to_numpy(),\n",
    "        genes_to_label=genes_to_label,\n",
    "        abs_log2fc_line=MIN_ABS_LOG2FC,\n",
    "    )\n",
    "\n",
    "    n_high = int(np.sum(keep2.to_numpy()))\n",
    "    sec6_summary.append((str(target), n_high, len(genes_to_label)))\n",
    "    targets_for_figure_generated.append(str(target))\n",
    "\n",
    "    print(f\"{target}: highlights={n_high} | labels={len(genes_to_label)}\")\n",
    "    print(\"  Saved:\", out_png)\n",
    "    print(\"  Saved:\", out_csv)\n",
    "\n",
    "print(\"\\n[OK] Volcanos 'FOR_FIGURE' generados.\")\n",
    "print(\"Targets generados (FOR_FIGURE):\", len(targets_for_figure_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776141b8-c63d-4e35-9028-76bb8e9dcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CELDA 7 — Tablas agregadas top10 (FOR_FIGURE / FOR_REPORT / FOR_REPORT_LINFO_CLEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be21e1f-24f4-4bbe-834a-c348d2fba89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[SEC7] Generando tablas top10 agregadas ...\")\n",
    "\n",
    "HOUSEKEEPING = {\n",
    "    \"GAPDH\",\"ACTB\",\"ACTG1\",\"B2M\",\"MALAT1\",\"EEF1A1\",\"RPLP0\",\"RPSA\",\"TMSB10\",\"FTH1\",\"FTL\"\n",
    "}\n",
    "def is_bad_gene(g: str) -> bool:\n",
    "    g = str(g)\n",
    "    if g in HOUSEKEEPING: return True\n",
    "    if g.startswith(\"MT-\"): return True\n",
    "    if g.startswith(\"RPL\") or g.startswith(\"RPS\"): return True\n",
    "    return False\n",
    "\n",
    "rows_fig: List[List[object]] = []\n",
    "rows_rep: List[List[object]] = []\n",
    "rows_rep_linfo: List[List[object]] = []\n",
    "\n",
    "targets_iter = list(targets_for_figure_generated) if \"targets_for_figure_generated\" in globals() else list(targets)\n",
    "\n",
    "for target in targets_iter:\n",
    "    tag = safe_tag(target)\n",
    "    path = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_{CONTROL_LABEL}_vs_{CASE_LABEL}_FOR_FIGURE.csv\"\n",
    "\n",
    "    if not path.exists():\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    df = ensure_fc_col(df, where=str(path))\n",
    "    df = df.sort_values(\"FDR\", ascending=True)\n",
    "    df[\"gene\"] = df[\"gene\"].astype(str)\n",
    "\n",
    "    # FOR_FIGURE: top10 por dirección (dentro de los genes filtrados)\n",
    "    top_healthy = df[df[FC_COL] > 0].head(10)\n",
    "    top_cirr    = df[df[FC_COL] < 0].head(10)\n",
    "\n",
    "    for _, r in top_healthy.iterrows():\n",
    "        rows_fig.append([str(target), \"Higher_in_Healthy\", r[\"gene\"], float(r[FC_COL]), float(r[\"FDR\"])])\n",
    "    for _, r in top_cirr.iterrows():\n",
    "        rows_fig.append([str(target), \"Higher_in_Cirrhosis\", r[\"gene\"], float(r[FC_COL]), float(r[\"FDR\"])])\n",
    "\n",
    "    # FOR_REPORT: quita housekeeping/ribo/MT\n",
    "    df_rep0 = df.loc[~df[\"gene\"].map(is_bad_gene)].copy()\n",
    "\n",
    "    top_healthy_r = df_rep0[df_rep0[FC_COL] > 0].head(10)\n",
    "    top_cirr_r    = df_rep0[df_rep0[FC_COL] < 0].head(10)\n",
    "\n",
    "    for _, r in top_healthy_r.iterrows():\n",
    "        rows_rep.append([str(target), \"Higher_in_Healthy\", r[\"gene\"], float(r[FC_COL]), float(r[\"FDR\"])])\n",
    "    for _, r in top_cirr_r.iterrows():\n",
    "        rows_rep.append([str(target), \"Higher_in_Cirrhosis\", r[\"gene\"], float(r[FC_COL]), float(r[\"FDR\"])])\n",
    "\n",
    "    # FOR_REPORT_LINFO_CLEAN: además quita “ambient myeloid” en linfoides\n",
    "    df_rep_l = df_rep0.copy()\n",
    "\n",
    "    if ANALYSIS_LEVEL == \"Level1_refined\":\n",
    "        apply_blacklist = (str(target) in {\"T\", \"NK\", \"B\"})\n",
    "    else:\n",
    "        apply_blacklist = (group_of_l2(str(target)) in APPLY_BLACKLIST_FOR_GROUPS)\n",
    "\n",
    "    if apply_blacklist:\n",
    "        df_rep_l = df_rep_l[~df_rep_l[\"gene\"].isin(AMBIENT_MYELOID)].copy()\n",
    "\n",
    "    top_healthy_l = df_rep_l[df_rep_l[FC_COL] > 0].head(10)\n",
    "    top_cirr_l    = df_rep_l[df_rep_l[FC_COL] < 0].head(10)\n",
    "\n",
    "    for _, r in top_healthy_l.iterrows():\n",
    "        rows_rep_linfo.append([str(target), \"Higher_in_Healthy\", r[\"gene\"], float(r[FC_COL]), float(r[\"FDR\"])])\n",
    "    for _, r in top_cirr_l.iterrows():\n",
    "        rows_rep_linfo.append([str(target), \"Higher_in_Cirrhosis\", r[\"gene\"], float(r[FC_COL]), float(r[\"FDR\"])])\n",
    "\n",
    "df_fig = pd.DataFrame(rows_fig, columns=[ANALYSIS_LEVEL, \"direction\", \"gene\", FC_COL, \"FDR\"])\n",
    "df_rep = pd.DataFrame(rows_rep, columns=[ANALYSIS_LEVEL, \"direction\", \"gene\", FC_COL, \"FDR\"])\n",
    "df_rep_l = pd.DataFrame(rows_rep_linfo, columns=[ANALYSIS_LEVEL, \"direction\", \"gene\", FC_COL, \"FDR\"])\n",
    "\n",
    "out_fig = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{CONTROL_LABEL}_vs_{CASE_LABEL}_FOR_FIGURE_top10_by_target.csv\"\n",
    "out_rep = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{CONTROL_LABEL}_vs_{CASE_LABEL}_FOR_REPORT_top10_by_target.csv\"\n",
    "out_rep_l = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{CONTROL_LABEL}_vs_{CASE_LABEL}_FOR_REPORT_LINFO_CLEAN_top10_by_target.csv\"\n",
    "\n",
    "df_fig.to_csv(out_fig, index=False)\n",
    "df_rep.to_csv(out_rep, index=False)\n",
    "df_rep_l.to_csv(out_rep_l, index=False)\n",
    "\n",
    "print(\"Saved:\", out_fig)\n",
    "print(\"Saved:\", out_rep)\n",
    "print(\"Saved:\", out_rep_l)\n",
    "print(\"\\n[OK] Tablas top10 generadas.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

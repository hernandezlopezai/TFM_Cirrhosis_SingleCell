{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c659b9-b880-4cf5-96c8-000d22d0fd43",
   "metadata": {},
   "source": [
    "### 1. Imports + paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3981d0d-2a95-4eea-9eda-d64d8fedf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from src.paths import project_paths\n",
    "\n",
    "print(\"Scanpy:\", sc.__version__)\n",
    "\n",
    "P = project_paths(Path.cwd())\n",
    "PROJECT_ROOT = P[\"PROJECT_ROOT\"]\n",
    "CONFIG_DIR   = P[\"CONFIG_DIR\"]\n",
    "DATA_DIR     = P[\"DATA_DIR\"]\n",
    "RESULTS_DIR  = P[\"RESULTS_DIR\"]\n",
    "FIGURES_DIR  = P[\"FIGURES_DIR\"]\n",
    "\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CONFIG_DIR  :\", CONFIG_DIR)\n",
    "print(\"DATA_DIR    :\", DATA_DIR)\n",
    "print(\"RESULTS_DIR :\", RESULTS_DIR)\n",
    "print(\"FIGURES_DIR :\", FIGURES_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2a169-9445-469d-854c-1fd355a58e3c",
   "metadata": {},
   "source": [
    "### 2. Leer config + parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e68c3-e207-4298-8568-9cf2faa7511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simple_yaml(path: Path) -> dict:\n",
    "    cfg = {}\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\":\", 1)\n",
    "        cfg[k.strip()] = v.strip().strip('\"').strip(\"'\")\n",
    "    return cfg\n",
    "\n",
    "cfg_path = CONFIG_DIR / \"config.yaml\"\n",
    "if not cfg_path.exists():\n",
    "    raise FileNotFoundError(f\"Falta {cfg_path}\")\n",
    "\n",
    "CFG = load_simple_yaml(cfg_path)\n",
    "\n",
    "LEVEL1_KEY = CFG.get(\"level1_key\", \"Level1\")\n",
    "LEVEL2_KEY = CFG.get(\"level2_key\", \"Level2\")  # normalmente \"Level2\"\n",
    "\n",
    "# Input: salida de NB09 (global anotado)\n",
    "MAIN_ANNOTATED_FILENAME = CFG.get(\"main_annotated_h5ad_filename\", \"TFM_CIRRHOSIS_main_annotated.h5ad\")\n",
    "\n",
    "# Outputs (RBC-out)\n",
    "OUT_FULL_NAME   = CFG.get(\"main_annotated_clean_h5ad_filename\", \"TFM_CIRRHOSIS_main_annotated_clean.h5ad\")\n",
    "OUT_FILTER_NAME = CFG.get(\"main_filtered_for_analysis_h5ad_filename\", \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\")\n",
    "\n",
    "IN_PATH    = RESULTS_DIR / MAIN_ANNOTATED_FILENAME\n",
    "OUT_FULL   = RESULTS_DIR / OUT_FULL_NAME\n",
    "OUT_FILTER = RESULTS_DIR / OUT_FILTER_NAME\n",
    "\n",
    "print(\"LEVEL1_KEY :\", LEVEL1_KEY)\n",
    "print(\"LEVEL2_KEY :\", LEVEL2_KEY)\n",
    "print(\"IN_PATH    :\", IN_PATH)\n",
    "print(\"OUT_FULL   :\", OUT_FULL)\n",
    "print(\"OUT_FILTER :\", OUT_FILTER)\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe IN_PATH:\\n{IN_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e456c0-04a7-4107-a268-770255e2b170",
   "metadata": {},
   "source": [
    "### 3. Cargar objeto anotado y revisar estado actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b976aa7-63fc-4ac1-b27e-322c4c2eea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(IN_PATH)\n",
    "print(adata)\n",
    "\n",
    "print(\"\\nColumnas obs:\")\n",
    "print(adata.obs.columns.tolist())\n",
    "\n",
    "if LEVEL1_KEY not in adata.obs.columns:\n",
    "    raise KeyError(f\"Falta obs['{LEVEL1_KEY}'] en el objeto de entrada.\")\n",
    "\n",
    "print(\"\\nDistribución Level1:\")\n",
    "print(adata.obs[LEVEL1_KEY].value_counts())\n",
    "\n",
    "if LEVEL2_KEY in adata.obs.columns:\n",
    "    # asegurar categorical para evitar fallos con .cat\n",
    "    adata.obs[LEVEL2_KEY] = adata.obs[LEVEL2_KEY].astype(\"category\")\n",
    "    print(\"\\nDistribución Level2 (top 30):\")\n",
    "    print(adata.obs[LEVEL2_KEY].value_counts().head(30))\n",
    "else:\n",
    "    print(f\"\\n[AVISO] No existe columna '{LEVEL2_KEY}' en adata.obs.\")\n",
    "\n",
    "# Comprobar NaN en Level2 por Level1\n",
    "if LEVEL2_KEY in adata.obs.columns:\n",
    "    print(\"\\nConteo de NaN en Level2 por Level1:\")\n",
    "    tmp = adata.obs.copy()\n",
    "    tmp[\"is_Level2_NA\"] = tmp[LEVEL2_KEY].isna()\n",
    "    print(tmp.groupby(LEVEL1_KEY)[\"is_Level2_NA\"].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad4ae9a-e324-45ce-a780-12d607e51068",
   "metadata": {},
   "source": [
    "### 4. Completar Level2 para HSCs / Plasma / pDC (y RBC si existiera en input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ceb463-3dbb-496b-b75f-01c3ec6e684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar Level2 para linajes simples donde a veces queda NaN\n",
    "LEVEL1_TO_LEVEL2_FILL = {\n",
    "    \"RBC\": \"RBC\",\n",
    "    \"HSCs\": \"HSCs\",\n",
    "    \"Plasma\": \"Plasma\",\n",
    "    \"pDC\": \"pDC\",\n",
    "}\n",
    "\n",
    "if LEVEL2_KEY not in adata.obs.columns:\n",
    "    adata.obs[LEVEL2_KEY] = np.nan\n",
    "\n",
    "lvl2 = adata.obs[LEVEL2_KEY].astype(\"object\")\n",
    "\n",
    "for lvl1, lvl2_name in LEVEL1_TO_LEVEL2_FILL.items():\n",
    "    mask = (adata.obs[LEVEL1_KEY].astype(str) == lvl1) & (pd.isna(lvl2))\n",
    "    n_before = int(mask.sum())\n",
    "    if n_before > 0:\n",
    "        print(f\"Asignando {LEVEL2_KEY}='{lvl2_name}' a {n_before} células con {LEVEL1_KEY}='{lvl1}' y {LEVEL2_KEY} NaN\")\n",
    "        lvl2.loc[mask] = lvl2_name\n",
    "    else:\n",
    "        print(f\"No hay células con {LEVEL1_KEY}='{lvl1}' y {LEVEL2_KEY} NaN (n=0)\")\n",
    "\n",
    "adata.obs[LEVEL2_KEY] = pd.Categorical(lvl2)\n",
    "\n",
    "print(\"\\nDistribución Level2 tras rellenar linajes simples:\")\n",
    "print(adata.obs[LEVEL2_KEY].value_counts())\n",
    "\n",
    "print(\"NaN total en Level2 (DESPUÉS del fill):\", int(adata.obs[LEVEL2_KEY].isna().sum()))\n",
    "tmp = adata.obs.copy()\n",
    "tmp[\"is_Level2_NA\"] = tmp[LEVEL2_KEY].isna()\n",
    "print(tmp.groupby(LEVEL1_KEY)[\"is_Level2_NA\"].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa717a6-04bb-4e28-bc06-1f981f8253e9",
   "metadata": {},
   "source": [
    "### 5. Marcar poblaciones doublet-like / artefacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9a9fa-054a-4c1d-8c00-41d77b1b90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOUBLETS_LEVEL2 = [\n",
    "    \"Platelet_like_T\",\n",
    "    \"T_NK_doublets\",\n",
    "    \"Myeloid_like_T\",\n",
    "]\n",
    "\n",
    "# Info si faltan categorías\n",
    "if pd.api.types.is_categorical_dtype(adata.obs[LEVEL2_KEY]):\n",
    "    current_cats = set(adata.obs[LEVEL2_KEY].cat.categories.astype(str))\n",
    "else:\n",
    "    current_cats = set(adata.obs[LEVEL2_KEY].astype(str).unique())\n",
    "\n",
    "missing_doublets = [x for x in DOUBLETS_LEVEL2 if x not in current_cats]\n",
    "if missing_doublets:\n",
    "    print(\"\\n[INFO] Alguna categoría de DOUBLETS_LEVEL2 no está en Level2. (Puede ser normal según dataset.)\")\n",
    "    print(\"Faltan:\", missing_doublets)\n",
    "\n",
    "adata.obs[\"doublet_like\"] = adata.obs[LEVEL2_KEY].astype(str).isin(DOUBLETS_LEVEL2)\n",
    "\n",
    "print(\"\\nConteo de doublet_like=True por Level2 (sin ceros):\")\n",
    "print(adata.obs.loc[adata.obs[\"doublet_like\"], LEVEL2_KEY].astype(str).value_counts())\n",
    "\n",
    "print(\"\\nTotal doublets-like:\", int(adata.obs[\"doublet_like\"].sum()))\n",
    "print(\"Total células:\", adata.n_obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196e2c3-99b8-4d58-9613-70fe6c0f9899",
   "metadata": {},
   "source": [
    "### 6. Crear objeto filtrado sin doublets y SIN RBC + hotfix RBC_and_HSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aa9693-6cb8-495e-a592-0c7dfc608527",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_full = adata  # alias explícito\n",
    "\n",
    "# HOTFIX post-NB09:\n",
    "# - excluir RBC y RBC_and_HSC del filtrado (RBC-out robusto)\n",
    "RBC_LIKE_L1 = [\"RBC\", \"RBC_and_HSC\"]\n",
    "\n",
    "mask_keep = (\n",
    "    (~adata_full.obs[\"doublet_like\"].to_numpy())\n",
    "    & (~adata_full.obs[LEVEL1_KEY].astype(str).isin(RBC_LIKE_L1).to_numpy())\n",
    ")\n",
    "\n",
    "# VISTA (view) para no duplicar RAM (igual que el notebook original)\n",
    "adata_filt = adata_full[mask_keep]\n",
    "\n",
    "print(\"\\n=== Resumen tras filtrar doublets + RBC-out (SIN COPY) ===\")\n",
    "print(adata_filt)\n",
    "\n",
    "print(\"\\nLevel1 (filtrado):\")\n",
    "print(adata_filt.obs[LEVEL1_KEY].value_counts())\n",
    "\n",
    "print(\"\\nLevel2 (filtrado, top 30):\")\n",
    "print(adata_filt.obs[LEVEL2_KEY].value_counts().head(30))\n",
    "\n",
    "print(\"Doublet categories after filter (should be 0):\")\n",
    "print(int(adata_filt.obs[LEVEL2_KEY].astype(str).isin(DOUBLETS_LEVEL2).sum()))\n",
    "\n",
    "print(\"RBC-like presentes en filtrado (debería ser 0):\")\n",
    "print(int(adata_filt.obs[LEVEL1_KEY].astype(str).isin(RBC_LIKE_L1).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4426a97-80af-4eb8-9b9e-0440415db308",
   "metadata": {},
   "source": [
    "### 7. Construir Level1_refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca5a9d-d5af-4806-82a3-f41f9e73e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos con Level1_refined = Level1\n",
    "adata_filt.obs[\"Level1_refined\"] = adata_filt.obs[LEVEL1_KEY].astype(\"object\")\n",
    "\n",
    "T_L2 = [\n",
    "    \"CD4_Naive\",\n",
    "    \"CD8_Naive\",\n",
    "    \"CD8_Effector_Cytotoxic\",\n",
    "    \"Conv_T_other\",\n",
    "    \"MAIT\",\n",
    "    \"GammaDelta_T\",\n",
    "    \"Treg\",\n",
    "    \"Proliferative_T\",\n",
    "    \"Exhausted_T\",\n",
    "]\n",
    "\n",
    "NK_L2 = [\"NK\"]\n",
    "\n",
    "MONO_L2 = [\n",
    "    \"Classical_Mono\",\n",
    "    \"NonClassical_Mono\",\n",
    "    \"ISG_Myeloid\",\n",
    "    \"MonoDC_Other\",\n",
    "]\n",
    "\n",
    "# HOTFIX post-NB09: incluir DC3 como DC\n",
    "DC_L2 = [\n",
    "    \"cDC1\",\n",
    "    \"cDC2\",\n",
    "    \"DC4\",\n",
    "    \"aDC\",\n",
    "    \"DC3\",\n",
    "]\n",
    "\n",
    "# Linajes simples que se mantienen tal cual (RBC puede existir en input, pero ya fue filtrado)\n",
    "SIMPLE_L1 = [\"B\", \"Plasma\", \"pDC\", \"RBC\", \"HSCs\"]\n",
    "\n",
    "mask_simple = adata_filt.obs[LEVEL1_KEY].astype(str).isin(SIMPLE_L1)\n",
    "print(f\"[INFO] Linajes simples (B/Plasma/pDC/RBC/HSCs): {int(mask_simple.sum())} células\")\n",
    "\n",
    "# T_and_NK -> T vs NK según Level2\n",
    "mask_TNK = adata_filt.obs[LEVEL1_KEY].astype(str) == \"T_and_NK\"\n",
    "mask_T = mask_TNK & adata_filt.obs[LEVEL2_KEY].astype(str).isin(T_L2)\n",
    "mask_NK = mask_TNK & adata_filt.obs[LEVEL2_KEY].astype(str).isin(NK_L2)\n",
    "\n",
    "print(f\"[INFO] T subtypes dentro de T_and_NK  → 'T'  : {int(mask_T.sum())} células\")\n",
    "print(f\"[INFO] NK subtypes dentro de T_and_NK → 'NK' : {int(mask_NK.sum())} células\")\n",
    "\n",
    "adata_filt.obs.loc[mask_T, \"Level1_refined\"] = \"T\"\n",
    "adata_filt.obs.loc[mask_NK, \"Level1_refined\"] = \"NK\"\n",
    "\n",
    "# Mono_and_DC -> Mono vs DC según Level2\n",
    "mask_MonoDC = adata_filt.obs[LEVEL1_KEY].astype(str) == \"Mono_and_DC\"\n",
    "mask_Mono = mask_MonoDC & adata_filt.obs[LEVEL2_KEY].astype(str).isin(MONO_L2)\n",
    "mask_DC   = mask_MonoDC & adata_filt.obs[LEVEL2_KEY].astype(str).isin(DC_L2)\n",
    "\n",
    "print(f\"[INFO] Mono subtypes dentro de Mono_and_DC → 'Mono': {int(mask_Mono.sum())} células\")\n",
    "print(f\"[INFO] DC subtypes dentro de Mono_and_DC   → 'DC'  : {int(mask_DC.sum())} células\")\n",
    "\n",
    "adata_filt.obs.loc[mask_Mono, \"Level1_refined\"] = \"Mono\"\n",
    "adata_filt.obs.loc[mask_DC,   \"Level1_refined\"] = \"DC\"\n",
    "\n",
    "print(\"\\n[CHECK] Distribución final de Level1_refined:\")\n",
    "print(adata_filt.obs[\"Level1_refined\"].value_counts())\n",
    "\n",
    "ALL_KNOWN_L2 = set(\n",
    "    T_L2 + NK_L2 + MONO_L2 + DC_L2 +\n",
    "    [\"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"B_Other\", \"RBC\", \"HSCs\", \"Plasma\", \"pDC\", \"DC3\"]\n",
    ")\n",
    "\n",
    "l2_present = set(pd.Series(adata_filt.obs[LEVEL2_KEY]).dropna().astype(str).unique())\n",
    "unknown_l2 = sorted(l2_present - ALL_KNOWN_L2)\n",
    "\n",
    "print(\"\\n[CHECK] Level2 presentes en el objeto que NO están en las listas esperadas:\")\n",
    "print(unknown_l2)\n",
    "\n",
    "bad = int(adata_filt.obs[\"Level1_refined\"].astype(str).isin([\"T_and_NK\", \"Mono_and_DC\"]).sum())\n",
    "print(\"Cells still labeled T_and_NK / Mono_and_DC in Level1_refined:\", bad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47ee1d-dc08-4594-b8e3-3237fdfdac43",
   "metadata": {},
   "source": [
    "### 8. Eliminar columna Type_L1L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0614f-3baf-47db-b36e-9d90176d0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Type_L1L2\", \"TypeL1L2\"]:\n",
    "    if col in adata_full.obs.columns:\n",
    "        print(f\"Eliminando columna '{col}' de adata_full.obs\")\n",
    "        del adata_full.obs[col]\n",
    "    if col in adata_filt.obs.columns:\n",
    "        print(f\"Eliminando columna '{col}' de adata_filt.obs\")\n",
    "        del adata_filt.obs[col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6080291-221f-4812-a5b6-1439b55cf960",
   "metadata": {},
   "source": [
    "### 9. Guardar objetos finales en results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a6fce-0d7c-4de8-8c38-79d8c7e47b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtypes recomendados\n",
    "adata_full.obs[LEVEL2_KEY] = adata_full.obs[LEVEL2_KEY].astype(\"category\")\n",
    "adata_full.obs[\"doublet_like\"] = adata_full.obs[\"doublet_like\"].astype(bool)\n",
    "\n",
    "# IMPORTANTE RBC-out: limpiar categorías no usadas en el filtrado para que RBC no aparezca como categoría vacía\n",
    "if pd.api.types.is_categorical_dtype(adata_filt.obs[LEVEL2_KEY]):\n",
    "    adata_filt.obs[LEVEL2_KEY] = adata_filt.obs[LEVEL2_KEY].cat.remove_unused_categories()\n",
    "\n",
    "adata_filt.obs[LEVEL2_KEY] = adata_filt.obs[LEVEL2_KEY].astype(\"category\")\n",
    "adata_filt.obs[\"Level1_refined\"] = adata_filt.obs[\"Level1_refined\"].astype(\"category\")\n",
    "adata_filt.obs[\"doublet_like\"] = adata_filt.obs[\"doublet_like\"].astype(bool)\n",
    "\n",
    "print(\"\\nGuardando objeto completo (con doublets marcados) en (RBC-out):\")\n",
    "print(\" \", OUT_FULL)\n",
    "adata_full[~adata_full.obs[LEVEL1_KEY].astype(str).isin(RBC_LIKE_L1)].write_h5ad(OUT_FULL, compression=\"gzip\")\n",
    "\n",
    "print(\"\\nGuardando objeto filtrado (sin doublets, con Level1_refined) en (ya RBC-out):\")\n",
    "print(\" \", OUT_FILTER)\n",
    "adata_filt.write_h5ad(OUT_FILTER, compression=\"gzip\")\n",
    "\n",
    "print(\"\\n[OK] Guardado completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898098f-a066-4d6c-94a8-506c2ed440c0",
   "metadata": {},
   "source": [
    "### 10. Check final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4c003-7796-4901-b1c5-fcb31998801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== CHECK FINAL ===\")\n",
    "print(\"Objeto completo (en RAM) :\", adata_full)\n",
    "print(\"Objeto filtrado (en RAM) :\", adata_filt)\n",
    "\n",
    "print(\"\\nLevel1_refined en adata_filt:\")\n",
    "print(adata_filt.obs[\"Level1_refined\"].value_counts())\n",
    "\n",
    "print(\"\\nDoublets en adata_full (deberían ser > 0) y en adata_filt (debería ser 0):\")\n",
    "print(\"doublet_like True en full :\", int(adata_full.obs[\"doublet_like\"].sum()))\n",
    "print(\"doublet_like True en filt :\", int(adata_filt.obs[\"doublet_like\"].sum()))\n",
    "\n",
    "print(\"\\nRBC-like en adata_filt (debería ser 0):\", int(adata_filt.obs[LEVEL1_KEY].astype(str).isin(RBC_LIKE_L1).sum()))\n",
    "print(\"Conv_T_other count (filtrado):\", int(adata_filt.obs[LEVEL2_KEY].astype(str).value_counts().get(\"Conv_T_other\", 0)))\n",
    "print(\"DC3 count (filtrado):\", int(adata_filt.obs[LEVEL2_KEY].astype(str).value_counts().get(\"DC3\", 0)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

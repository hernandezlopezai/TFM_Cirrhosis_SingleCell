{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dacfc3c5-20d4-44b6-8411-735009706c8e",
   "metadata": {},
   "source": [
    "### 1. Imports + paths del repo + directorios de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ca2f5-bae3-43c6-b9ef-89d5576e4b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from src.paths import project_paths\n",
    "\n",
    "print(\"Scanpy:\", getattr(sc, \"__version__\", \"unknown\"))\n",
    "\n",
    "P = project_paths(Path.cwd())\n",
    "PROJECT_ROOT = P[\"PROJECT_ROOT\"]\n",
    "CONFIG_DIR   = P[\"CONFIG_DIR\"]\n",
    "DATA_DIR     = P[\"DATA_DIR\"]\n",
    "RESULTS_DIR  = P[\"RESULTS_DIR\"]\n",
    "FIGURES_DIR  = P[\"FIGURES_DIR\"]\n",
    "\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FIG_DIR = FIGURES_DIR / \"main\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "QA_DIR = RESULTS_DIR / \"summary_tables\" / \"umap_harmony_final\"\n",
    "QA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CONFIG_DIR  :\", CONFIG_DIR)\n",
    "print(\"RESULTS_DIR :\", RESULTS_DIR)\n",
    "print(\"FIG_DIR     :\", FIG_DIR)\n",
    "print(\"QA_DIR      :\", QA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e43cb-7de4-455d-9810-6f33061204df",
   "metadata": {},
   "source": [
    "### 2. Leer config + resolver IN_PATH + cargar Level2_final_map.json (Conv_T_other -> CD4_Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e25ddf-f070-4ede-b635-dcb284177982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simple_yaml(path: Path) -> dict:\n",
    "    cfg = {}\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\":\", 1)\n",
    "        cfg[k.strip()] = v.strip().strip('\"').strip(\"'\")\n",
    "    return cfg\n",
    "\n",
    "cfg_path = CONFIG_DIR / \"config.yaml\"\n",
    "if not cfg_path.exists():\n",
    "    raise FileNotFoundError(f\"Falta {cfg_path}\")\n",
    "CFG = load_simple_yaml(cfg_path)\n",
    "\n",
    "# Input: salida del NB10 (objeto filtrado RBC-out, sin doublets)\n",
    "IN_NAME = CFG.get(\"main_filtered_for_analysis_h5ad_filename\", \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\")\n",
    "IN_PATH = RESULTS_DIR / IN_NAME\n",
    "\n",
    "# Keys (fallbacks)\n",
    "PATIENT_KEY        = CFG.get(\"patient_id_key\", \"patientID\")\n",
    "DISEASE_KEY        = CFG.get(\"disease_key\", \"disease\")\n",
    "LEVEL2_KEY         = CFG.get(\"level2_key\", \"Level2\")\n",
    "LEVEL1_REFINED_KEY = CFG.get(\"level1_refined_key\", \"Level1_refined\")\n",
    "\n",
    "# PCA key (para lectura vía h5py)\n",
    "PCA_KEY = CFG.get(\"pca_key\", \"X_pca\")\n",
    "\n",
    "# Params Harmony/UMAP\n",
    "BATCH_KEY     = CFG.get(\"umap_final_harmony_batch_key\", PATIENT_KEY)\n",
    "N_PCS         = int(CFG.get(\"harmony_n_pcs\", \"50\"))\n",
    "N_NEIGHBORS   = int(CFG.get(\"umap_n_neighbors\", \"15\"))\n",
    "RANDOM_STATE  = int(CFG.get(\"umap_random_state\", \"0\"))\n",
    "MAX_ITER_HMY  = int(CFG.get(\"harmony_max_iter\", \"20\"))\n",
    "\n",
    "print(\"IN_PATH           :\", IN_PATH)\n",
    "print(\"PATIENT_KEY       :\", PATIENT_KEY)\n",
    "print(\"DISEASE_KEY       :\", DISEASE_KEY)\n",
    "print(\"LEVEL1_REFINED_KEY:\", LEVEL1_REFINED_KEY)\n",
    "print(\"LEVEL2_KEY        :\", LEVEL2_KEY)\n",
    "print(\"PCA_KEY           :\", PCA_KEY)\n",
    "print(\"BATCH_KEY (FINAL) :\", BATCH_KEY)\n",
    "print(\"N_PCS             :\", N_PCS)\n",
    "print(\"N_NEIGHBORS       :\", N_NEIGHBORS)\n",
    "print(\"RANDOM_STATE      :\", RANDOM_STATE)\n",
    "print(\"MAX_ITER_HMY      :\", MAX_ITER_HMY)\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe IN_PATH:\\n{IN_PATH}\")\n",
    "\n",
    "# Map Level2_final (de Conv_T_other_cleanup)\n",
    "candidate_maps = [\n",
    "    RESULTS_DIR / \"summary_tables\" / \"conv_t_other_cleanup\" / \"Level2_final_map.json\",\n",
    "    RESULTS_DIR / \"summary_tables\" / \"Level2_final_map.json\",\n",
    "]\n",
    "MAP_PATH = next((p for p in candidate_maps if p.exists()), None)\n",
    "if MAP_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encuentro Level2_final_map.json en ubicaciones esperadas.\\nProbé:\\n\"\n",
    "        + \"\\n\".join([f\"- {x}\" for x in candidate_maps])\n",
    "    )\n",
    "\n",
    "with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    level2_map = json.load(f)\n",
    "\n",
    "print(\"MAP_PATH:\", MAP_PATH)\n",
    "print(\"Level2_final_map.json loaded:\", level2_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4605c-2396-43da-a9a4-dde9a0ec141a",
   "metadata": {},
   "source": [
    "### 3. Lectura mínima vía h5py (obs + X_pca) + construir Level2_final + excluir RBC solo para UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc8c18-f26c-404b-8199-734aa54c8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_elem(h5obj):\n",
    "    \"\"\"\n",
    "    Lee un elemento AnnData desde h5py sin materializar /layers.\n",
    "    Funciona en anndata>=0.8 (rutas pueden variar).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from anndata.experimental import read_elem as _re\n",
    "        return _re(h5obj)\n",
    "    except Exception:\n",
    "        try:\n",
    "            from anndata._io.specs import read_elem as _re\n",
    "            return _re(h5obj)\n",
    "        except Exception as e:\n",
    "            raise ImportError(\n",
    "                \"No puedo importar read_elem (anndata.experimental.read_elem / anndata._io.specs.read_elem). \"\n",
    "                \"Necesitas anndata con soporte de lectura de elementos.\"\n",
    "            ) from e\n",
    "\n",
    "# INCLUYE también BATCH_KEY por si umap_final_harmony_batch_key != patientID\n",
    "needed_obs = sorted(set([PATIENT_KEY, DISEASE_KEY, LEVEL1_REFINED_KEY, LEVEL2_KEY, BATCH_KEY]))\n",
    "\n",
    "with h5py.File(IN_PATH, \"r\") as f:\n",
    "    if \"obs\" not in f:\n",
    "        raise KeyError(\"No existe grupo /obs en el .h5ad (archivo corrupto o no estándar).\")\n",
    "\n",
    "    obs_full = _read_elem(f[\"obs\"])\n",
    "    if not isinstance(obs_full, pd.DataFrame):\n",
    "        raise TypeError(f\"read_elem(/obs) no devolvió DataFrame. Tipo: {type(obs_full)}\")\n",
    "\n",
    "    missing = [c for c in needed_obs if c not in obs_full.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Faltan columnas en obs: {missing}\")\n",
    "\n",
    "    obs_full = obs_full.copy()\n",
    "    obs_full[PATIENT_KEY] = obs_full[PATIENT_KEY].astype(str)\n",
    "    obs_full[DISEASE_KEY] = obs_full[DISEASE_KEY].astype(str)\n",
    "    obs_full[LEVEL1_REFINED_KEY] = obs_full[LEVEL1_REFINED_KEY].astype(str)\n",
    "    obs_full[BATCH_KEY] = obs_full[BATCH_KEY].astype(str)\n",
    "\n",
    "    # Mantener Level2 como object (sin convertir NaN->\"nan\")\n",
    "    l2_obj = obs_full[LEVEL2_KEY].astype(\"object\")\n",
    "\n",
    "    # Level2_final (mapping Conv_T_other -> CD4_Memory)\n",
    "    l2_final = l2_obj.replace(level2_map)\n",
    "    obs_full[\"Level2_final\"] = pd.Categorical(l2_final)\n",
    "\n",
    "    print(\"[CHECK] Conv_T_other remaining en Level2_final (debe ser 0):\",\n",
    "          int((obs_full[\"Level2_final\"].astype(str) == \"Conv_T_other\").sum()))\n",
    "    print(\"[CHECK] CD4_Memory count en Level2_final:\",\n",
    "          int((obs_full[\"Level2_final\"].astype(str) == \"CD4_Memory\").sum()))\n",
    "\n",
    "    # RBC-out sanity (si aparece, se excluye SOLO para UMAP)\n",
    "    keep = ~(\n",
    "        (obs_full[LEVEL1_REFINED_KEY].astype(str) == \"RBC\") |\n",
    "        (l2_obj.astype(str) == \"RBC\") |\n",
    "        (obs_full[\"Level2_final\"].astype(str) == \"RBC\")\n",
    "    )\n",
    "    n_rbc = int((~keep).sum())\n",
    "    if n_rbc > 0:\n",
    "        print(f\"[WARN] Aún hay RBC en el objeto ({n_rbc} células). Para UMAP Harmony se excluirán.\")\n",
    "\n",
    "    idx_keep = np.flatnonzero(keep.to_numpy(dtype=bool))\n",
    "    obs_keep = obs_full.iloc[idx_keep].copy()\n",
    "\n",
    "    # X_pca\n",
    "    if \"obsm\" not in f or PCA_KEY not in f[\"obsm\"]:\n",
    "        raise KeyError(f\"No existe /obsm/{PCA_KEY} en el .h5ad. Necesitas PCA calculado antes.\")\n",
    "\n",
    "    X_pca_ds = f[\"obsm\"][PCA_KEY]\n",
    "    X_pca = np.asarray(X_pca_ds[idx_keep, :], dtype=np.float32)\n",
    "\n",
    "print(\"X_pca shape:\", X_pca.shape)\n",
    "print(\"n_obs total :\", obs_full.shape[0])\n",
    "print(\"n_obs keep  :\", obs_keep.shape[0])\n",
    "\n",
    "adata_umap = ad.AnnData(\n",
    "    X=np.zeros((obs_keep.shape[0], 1), dtype=np.float32),\n",
    "    obs=obs_keep\n",
    ")\n",
    "\n",
    "N_PCS_USED = int(min(N_PCS, X_pca.shape[1]))\n",
    "adata_umap.obsm[\"X_pca\"] = X_pca[:, :N_PCS_USED].astype(np.float32, copy=False)\n",
    "\n",
    "print(\"AnnData mínimo para Harmony:\", adata_umap)\n",
    "print(\"obs columns:\", adata_umap.obs.columns.tolist())\n",
    "print(\"X_pca used shape:\", adata_umap.obsm[\"X_pca\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d823b8d-1609-43cd-a956-ba15083d6ef6",
   "metadata": {},
   "source": [
    "### 4. Import markers + construir dict Level2→genes + overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c4d90-5a73-4150-a67e-d7620006bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import markers as mk\n",
    "\n",
    "geneMarkers_level2 = getattr(mk, \"geneMarkers_level2\", {})\n",
    "if not geneMarkers_level2:\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(\"src/markers.py no expone geneMarkers_level2 (vacío/no definido).\")\n",
    "\n",
    "# base: dict Level2 -> lista genes (agregando sobre linajes)\n",
    "lvl2_to_symbols = {}\n",
    "for _l1, subdict in geneMarkers_level2.items():\n",
    "    if not isinstance(subdict, dict):\n",
    "        continue\n",
    "    for _l2, genes in subdict.items():\n",
    "        if genes:\n",
    "            lvl2_to_symbols[_l2] = list(genes)\n",
    "\n",
    "# overrides mínimos para poblaciones problemáticas / nuevas por Level2_final_map\n",
    "OVERRIDE_2MARKERS = {\n",
    "    \"B_Other\":      [\"MS4A1\", \"CD74\"],\n",
    "    \"CD4_Memory\":   [\"IL7R\", \"CCR7\"],     # <- clave tras Conv_T_other -> CD4_Memory\n",
    "    \"ISG_Myeloid\":  [\"ISG15\", \"IFIT3\"],\n",
    "    \"MonoDC_Other\": [\"LYZ\", \"FCER1G\"],\n",
    "    \"DC3\":          [\"CD1C\", \"S100A8\"],   # <- asegurar DC3\n",
    "    \"DC4\":          [\"FCGR3A\", \"LST1\"],   # <- fallback\n",
    "    \"HSCs\":         [\"CD34\", \"KIT\"],\n",
    "    \"Plasma\":       [\"MZB1\", \"JCHAIN\"],\n",
    "    \"pDC\":          [\"IL3RA\", \"IRF7\"],\n",
    "}\n",
    "\n",
    "for l2, genes2 in OVERRIDE_2MARKERS.items():\n",
    "    if (l2 not in lvl2_to_symbols) or (len([g for g in lvl2_to_symbols.get(l2, []) if g]) < 2):\n",
    "        lvl2_to_symbols[l2] = genes2\n",
    "\n",
    "print(\"Markers dict construido. N Level2 con panel:\", len(lvl2_to_symbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d22537-5ddc-4122-bbb6-05e6b3f0888c",
   "metadata": {},
   "source": [
    "### 5. Preparar obs + Level2_final + orden por bloques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991b0edf-d8fa-432e-95ad-d722f87e0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = adata_b.obs.copy()\n",
    "\n",
    "obs[\"Level2_final\"] = obs[LEVEL2_KEY].astype(str).replace(level2_map).astype(str)\n",
    "obs[\"Level2_final\"] = pd.Categorical(obs[\"Level2_final\"])\n",
    "\n",
    "print(\"[CHECK] Conv_T_other remaining en Level2_final (debe ser 0):\",\n",
    "      int((obs[\"Level2_final\"].astype(str) == \"Conv_T_other\").sum()))\n",
    "print(\"[CHECK] CD4_Memory count en Level2_final:\",\n",
    "      int((obs[\"Level2_final\"].astype(str) == \"CD4_Memory\").sum()))\n",
    "\n",
    "# Orden por bloques usando Level2_final\n",
    "order_by_group = {\n",
    "    \"B\":     [\"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"B_Other\"],\n",
    "    \"Plasma\":[\"Plasma\"],\n",
    "    \"pDC\":   [\"pDC\"],\n",
    "    \"T\":     [\"CD4_Naive\",\"CD4_Memory\",\"CD8_Naive\",\"CD8_Effector_Cytotoxic\",\"Treg\",\"MAIT\",\"GammaDelta_T\",\"Proliferative_T\",\"Exhausted_T\"],\n",
    "    \"NK\":    [\"NK\"],\n",
    "    \"Mono\":  [\"Classical_Mono\",\"NonClassical_Mono\",\"ISG_Myeloid\",\"MonoDC_Other\"],\n",
    "    \"DC\":    [\"cDC1\",\"cDC2\",\"DC3\",\"DC4\",\"aDC\"],  # <- DC3 incluido\n",
    "    \"HSCs\":  [\"HSCs\"],\n",
    "}\n",
    "\n",
    "present_l2 = sorted(set(obs[\"Level2_final\"].astype(str).dropna().unique()))\n",
    "\n",
    "level2_order = []\n",
    "for g, l2_list in order_by_group.items():\n",
    "    for l2 in l2_list:\n",
    "        if l2 in present_l2:\n",
    "            level2_order.append(l2)\n",
    "\n",
    "extras = [x for x in present_l2 if x not in level2_order]\n",
    "level2_order = level2_order + sorted(extras)\n",
    "\n",
    "def group_of_l2(l2: str) -> str:\n",
    "    for g, l2_list in order_by_group.items():\n",
    "        if l2 in l2_list:\n",
    "            return g\n",
    "    return \"Other\"\n",
    "\n",
    "# Label final para plot: \"Grupo | Level2_final\"\n",
    "obs[\"Level2_plot\"] = obs[\"Level2_final\"].astype(str).map(lambda l2: f\"{group_of_l2(l2)} | {l2}\")\n",
    "level2_plot_order = [f\"{group_of_l2(l2)} | {l2}\" for l2 in level2_order]\n",
    "obs[\"Level2_plot\"] = pd.Categorical(obs[\"Level2_plot\"], categories=level2_plot_order, ordered=True)\n",
    "\n",
    "print(\"[CHECK] Level2_final presentes:\", len(present_l2))\n",
    "print(\"[CHECK] Primeros 30:\", present_l2[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5189d5-665d-4011-924a-317ac49def3e",
   "metadata": {},
   "source": [
    "### 6. Lista final de genes + symbols -> varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd7bec-6b70-445d-ab0e-eae202c6215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista final de genes\n",
    "gene_symbols = []\n",
    "for l2 in level2_order:\n",
    "    gene_symbols.extend(lvl2_to_symbols.get(l2, [])[:2])\n",
    "\n",
    "# dedup manteniendo orden\n",
    "seen = set()\n",
    "gene_symbols = [g for g in gene_symbols if not (g in seen or seen.add(g))]\n",
    "\n",
    "# mapear symbols->varnames\n",
    "gene_varnames = mk.symbols_to_varnames(adata_b, gene_symbols)\n",
    "\n",
    "missing = [s for s, v in zip(gene_symbols, gene_varnames) if v is None]\n",
    "gene_varnames = [v for v in gene_varnames if v is not None]\n",
    "\n",
    "print(\"Markers symbols total:\", len(gene_symbols))\n",
    "print(\"Markers genes found :\", len(gene_varnames))\n",
    "if missing:\n",
    "    print(\"[WARN] Símbolos no encontrados (omitidos):\", missing)\n",
    "\n",
    "if len(gene_varnames) == 0:\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(\"No se encontró ningún gen marcador en adata.var_names. Revisa var_names / var['symbol'].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f101b-184f-4894-a5c1-a5ad63f08318",
   "metadata": {},
   "source": [
    "### 7. Cargar SOLO esos genes a RAM + dotplot FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7674e52-0e00-41a0-8c03-889c22a13d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar SOLO genes del dotplot a RAM\n",
    "adata_plot = adata_b[:, gene_varnames].to_memory()\n",
    "\n",
    "# cerrar el backed\n",
    "try:\n",
    "    adata_b.file.close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# añadir Level2_plot al objeto pequeño\n",
    "adata_plot.obs[\"Level2_plot\"] = obs.loc[adata_plot.obs_names, \"Level2_plot\"].values\n",
    "adata_plot.obs[\"Level2_plot\"] = pd.Categorical(\n",
    "    adata_plot.obs[\"Level2_plot\"], categories=level2_plot_order, ordered=True\n",
    ")\n",
    "\n",
    "sc.settings.autoshow = False\n",
    "\n",
    "dp = sc.pl.dotplot(\n",
    "    adata_plot,\n",
    "    var_names=gene_varnames,\n",
    "    groupby=\"Level2_plot\",\n",
    "    layer=LAYER,\n",
    "    use_raw=False,\n",
    "    dendrogram=False,\n",
    "    standard_scale=\"var\",\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "dp = dp.add_totals().style(dot_edge_color=\"black\", dot_edge_lw=0.5)\n",
    "\n",
    "out_png = FIG_DIR / \"Fig1C_Dotplot_Global_Level2_clean_FINAL.png\"\n",
    "dp.savefig(out_png, dpi=300)\n",
    "print(\"Saved:\", out_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f6790-9db4-43b5-a832-4636bce21752",
   "metadata": {},
   "source": [
    "### 8. Guardar tablas auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dc0c1-7b6f-4355-a361-712e050ed4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = (\n",
    "    obs[\"Level2_plot\"].value_counts()\n",
    "    .reindex(level2_plot_order)\n",
    "    .dropna()\n",
    "    .astype(int)\n",
    "    .reset_index()\n",
    ")\n",
    "totals.columns = [\"Level2_plot\", \"n_cells\"]\n",
    "totals[\"group\"] = totals[\"Level2_plot\"].str.split(\" \\\\| \").str[0]\n",
    "totals[\"Level2_final\"] = totals[\"Level2_plot\"].str.split(\" \\\\| \").str[1]\n",
    "\n",
    "totals_path = OUT_SUMMARY / \"QA_dotplot_totals_by_Level2_plot_noRBC.csv\"\n",
    "totals.to_csv(totals_path, index=False)\n",
    "print(\"Saved:\", totals_path)\n",
    "\n",
    "marker_rows = []\n",
    "for l2 in level2_order:\n",
    "    genes = lvl2_to_symbols.get(l2, [])\n",
    "    m1 = genes[0] if len(genes) > 0 else None\n",
    "    m2 = genes[1] if len(genes) > 1 else None\n",
    "    marker_rows.append({\"Level2_final\": l2, \"group\": group_of_l2(l2), \"marker1\": m1, \"marker2\": m2})\n",
    "\n",
    "markers_df = pd.DataFrame(marker_rows)\n",
    "markers_df[\"Level2_plot\"] = markers_df.apply(lambda r: f\"{r['group']} | {r['Level2_final']}\", axis=1)\n",
    "\n",
    "markers_path = OUT_SUMMARY / \"QA_dotplot_markers_2perLevel2_noRBC.csv\"\n",
    "markers_df.to_csv(markers_path, index=False)\n",
    "print(\"Saved:\", markers_path)\n",
    "\n",
    "print(\"[OK] Dotplot global + tablas QA guardadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58334d3f-1c30-4537-8294-067153a9801c",
   "metadata": {},
   "source": [
    "### 9. EXTRA QA “Dotplot en números”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddeb411-55c3-4a94-baf4-08e42b5b5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "# genes usados = los del dotplot\n",
    "genes_used = list(gene_varnames)\n",
    "\n",
    "# Filtramos a genes presentes\n",
    "# aquí adata_plot ya está en memoria, pero genes_used se valida igual\n",
    "genes_used = [g for g in genes_used if g in adata_plot.var_names]\n",
    "if len(genes_used) == 0:\n",
    "    raise RuntimeError(\"genes_used quedó vacío. Revisa gene_varnames vs var_names.\")\n",
    "\n",
    "# reconstruir Level2_final en el objeto pequeño\n",
    "# (obs original está en RAM y gene_varnames se definió con el backed)\n",
    "lvl2_final_small = obs.loc[adata_plot.obs_names, \"Level2_final\"].astype(str).values\n",
    "adata_plot.obs[\"Level2_final\"] = lvl2_final_small\n",
    "\n",
    "# seleccionar matriz desde layer\n",
    "X = adata_plot.layers[LAYER] if LAYER in adata_plot.layers.keys() else adata_plot.X\n",
    "if sp.issparse(X):\n",
    "    X = X.tocsr()\n",
    "\n",
    "groups = pd.Series(adata_plot.obs[\"Level2_final\"].astype(str).values, index=adata_plot.obs_names)\n",
    "uniq = sorted(groups.unique())\n",
    "\n",
    "rows = []\n",
    "for g in uniq:\n",
    "    idx = np.where(groups.values == g)[0]\n",
    "    n = int(idx.size)\n",
    "    if n == 0:\n",
    "        continue\n",
    "\n",
    "    Xg = X[idx, :]\n",
    "\n",
    "    if sp.issparse(Xg):\n",
    "        mean = np.asarray(Xg.mean(axis=0)).ravel()\n",
    "        nnz = np.asarray((Xg > 0).mean(axis=0)).ravel()\n",
    "    else:\n",
    "        Xg = np.asarray(Xg)\n",
    "        mean = np.mean(Xg, axis=0)\n",
    "        nnz = np.mean((Xg > 0), axis=0)\n",
    "\n",
    "    row = {\"Level2_final\": g, \"n_cells\": n}\n",
    "    for j, gene in enumerate(genes_used):\n",
    "        row[f\"{gene}__mean_log1p\"] = float(mean[j])\n",
    "        row[f\"{gene}__frac_nonzero\"] = float(nnz[j])\n",
    "    rows.append(row)\n",
    "\n",
    "df_num = pd.DataFrame(rows).sort_values(\"n_cells\", ascending=False)\n",
    "\n",
    "out_path = OUT_SUMMARY / \"QA_dotplot_numeric_matrix_Level2final.csv\"\n",
    "df_num.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"Shape:\", df_num.shape)\n",
    "print(df_num.head(8).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

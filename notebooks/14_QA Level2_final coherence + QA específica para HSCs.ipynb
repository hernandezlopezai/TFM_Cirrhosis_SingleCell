{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93dd4ed2-017e-43c9-9bc4-9bd42175cad9",
   "metadata": {},
   "source": [
    "### 1. Imports + paths del repo + directorios de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0833d60-bb7b-4b36-9170-aa24126f24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from src.paths import project_paths\n",
    "\n",
    "print(\"Scanpy:\", sc.__version__)\n",
    "\n",
    "P = project_paths(Path.cwd())\n",
    "PROJECT_ROOT = P[\"PROJECT_ROOT\"]\n",
    "CONFIG_DIR   = P[\"CONFIG_DIR\"]\n",
    "DATA_DIR     = P[\"DATA_DIR\"]\n",
    "RESULTS_DIR  = P[\"RESULTS_DIR\"]\n",
    "FIGURES_DIR  = P[\"FIGURES_DIR\"]\n",
    "\n",
    "OUT_DIR = RESULTS_DIR / \"summary_tables\" / \"qa_level2final_coherence_hscs\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CONFIG_DIR  :\", CONFIG_DIR)\n",
    "print(\"RESULTS_DIR :\", RESULTS_DIR)\n",
    "print(\"OUT_DIR     :\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554b730-50f8-4417-a206-6475acf42aaa",
   "metadata": {},
   "source": [
    "### 2. Leer config + resolver inputs + keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34544f-40ec-4463-86c7-3ca973264206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simple_yaml(path: Path) -> dict:\n",
    "    cfg = {}\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\":\", 1)\n",
    "        cfg[k.strip()] = v.strip().strip('\"').strip(\"'\")\n",
    "    return cfg\n",
    "\n",
    "cfg_path = CONFIG_DIR / \"config.yaml\"\n",
    "if not cfg_path.exists():\n",
    "    raise FileNotFoundError(f\"Falta {cfg_path}\")\n",
    "CFG = load_simple_yaml(cfg_path)\n",
    "\n",
    "# Input principal: salida del NB10\n",
    "OUT_FILTER_NAME = CFG.get(\"main_filtered_for_analysis_h5ad_filename\", \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\")\n",
    "OUT_FILTER = RESULTS_DIR / OUT_FILTER_NAME\n",
    "\n",
    "# Keys\n",
    "PATIENT_KEY        = CFG.get(\"patient_id_key\", \"patientID\")\n",
    "DISEASE_KEY        = CFG.get(\"disease_key\", \"disease\")\n",
    "LEVEL1_REFINED_KEY = CFG.get(\"level1_refined_key\", \"Level1_refined\")\n",
    "LEVEL2_KEY         = CFG.get(\"level2_key\", \"Level2\")\n",
    "\n",
    "# Layer para expresión\n",
    "LAYER = CFG.get(\"analysis_layer\", CFG.get(\"l2_base_layer\", \"log1p_10k\"))\n",
    "\n",
    "# Neighbors key (para localizar obsp['{key}_connectivities'])\n",
    "NEIGHBORS_KEY = CFG.get(\"neighbors_key\", \"harmony\")\n",
    "\n",
    "print(\"OUT_FILTER        :\", OUT_FILTER)\n",
    "print(\"PATIENT_KEY       :\", PATIENT_KEY)\n",
    "print(\"DISEASE_KEY       :\", DISEASE_KEY)\n",
    "print(\"LEVEL1_REFINED_KEY:\", LEVEL1_REFINED_KEY)\n",
    "print(\"LEVEL2_KEY        :\", LEVEL2_KEY)\n",
    "print(\"LAYER             :\", LAYER)\n",
    "print(\"NEIGHBORS_KEY     :\", NEIGHBORS_KEY)\n",
    "\n",
    "if not OUT_FILTER.exists():\n",
    "    raise FileNotFoundError(f\"No existe OUT_FILTER:\\n{OUT_FILTER}\")\n",
    "\n",
    "# Level2_final_map.json\n",
    "candidate_maps = [\n",
    "    RESULTS_DIR / \"summary_tables\" / \"conv_t_other_cleanup\" / \"Level2_final_map.json\",\n",
    "    RESULTS_DIR / \"summary_tables\" / \"Level2_final_map.json\",\n",
    "]\n",
    "MAP_PATH = next((p for p in candidate_maps if p.exists()), None)\n",
    "if MAP_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encuentro Level2_final_map.json.\\nProbé:\\n\" + \"\\n\".join([f\"- {x}\" for x in candidate_maps])\n",
    "    )\n",
    "\n",
    "with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    level2_map = json.load(f)\n",
    "\n",
    "print(\"MAP_PATH:\", MAP_PATH)\n",
    "print(\"Level2_final_map:\", level2_map)\n",
    "\n",
    "# Embeddings UMAP Harmony (output del NB13)\n",
    "candidate_emb = [\n",
    "    RESULTS_DIR / \"summary_tables\" / \"umap_harmony_final\" / \"UMAP_Harmony_embeddings.csv\",\n",
    "    RESULTS_DIR / \"summary_tables\" / \"UMAP_Harmony_embeddings.csv\",\n",
    "]\n",
    "EMB_PATH = next((p for p in candidate_emb if p.exists()), None)\n",
    "if EMB_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encuentro UMAP_Harmony_embeddings.csv.\\nProbé:\\n\" + \"\\n\".join([f\"- {x}\" for x in candidate_emb])\n",
    "    )\n",
    "\n",
    "print(\"EMB_PATH:\", EMB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713eca60-5922-45c4-89ee-2373ca8d07cd",
   "metadata": {},
   "source": [
    "### 3. Coherencia Level2_final por pureza de vecinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb0bfd9-95e3-43ad-9b36-c384d705e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "need = [PATIENT_KEY, DISEASE_KEY, LEVEL1_REFINED_KEY, LEVEL2_KEY]\n",
    "\n",
    "adata_b = sc.read_h5ad(OUT_FILTER, backed=\"r\")\n",
    "try:\n",
    "    missing = [c for c in need if c not in adata_b.obs.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Faltan columnas obs: {missing}\")\n",
    "\n",
    "    obs = adata_b.obs[need].copy()\n",
    "\n",
    "    l2_obj = obs[LEVEL2_KEY].astype(\"object\")\n",
    "    obs[\"Level2_final\"] = l2_obj.replace(level2_map).astype(\"object\")\n",
    "\n",
    "    # Elegir conectividades\n",
    "    candidates = [\n",
    "        f\"{NEIGHBORS_KEY}_connectivities\",\n",
    "        \"harmony_connectivities\",\n",
    "        \"connectivities\",\n",
    "    ]\n",
    "\n",
    "    graph_name = None\n",
    "    C = None\n",
    "    for k in candidates:\n",
    "        if k in adata_b.obsp.keys():\n",
    "            graph_name = k\n",
    "            C = adata_b.obsp[k]\n",
    "            break\n",
    "\n",
    "    if C is None:\n",
    "        raise KeyError(\n",
    "            \"No encuentro connectivities en obsp.\\nProbé:\\n\"\n",
    "            + \"\\n\".join([f\"- obsp['{k}']\" for k in candidates])\n",
    "        )\n",
    "\n",
    "    print(f\"[OK] Usando grafo: obsp['{graph_name}'] -> {C.shape}\")\n",
    "\n",
    "    K = 15\n",
    "    try:\n",
    "        if graph_name.endswith(\"_connectivities\"):\n",
    "            base = graph_name.replace(\"_connectivities\", \"\")\n",
    "            uns_key = f\"{base}_neighbors\"\n",
    "            if uns_key in adata_b.uns and \"params\" in adata_b.uns[uns_key]:\n",
    "                K = int(adata_b.uns[uns_key][\"params\"].get(\"n_neighbors\", 15))\n",
    "            elif \"neighbors\" in adata_b.uns and \"params\" in adata_b.uns[\"neighbors\"]:\n",
    "                K = int(adata_b.uns[\"neighbors\"][\"params\"].get(\"n_neighbors\", 15))\n",
    "        elif \"neighbors\" in adata_b.uns and \"params\" in adata_b.uns[\"neighbors\"]:\n",
    "            K = int(adata_b.uns[\"neighbors\"][\"params\"].get(\"n_neighbors\", 15))\n",
    "    except Exception:\n",
    "        K = 15\n",
    "    print(\"K (n_neighbors):\", K)\n",
    "\n",
    "    def topk_neighbors_from_connectivities(C, k=15):\n",
    "        if not sp.issparse(C):\n",
    "            C = sp.csr_matrix(C)\n",
    "        C = C.tocsr()\n",
    "        n = C.shape[0]\n",
    "        neigh_idx = []\n",
    "        for i in range(n):\n",
    "            start, end = C.indptr[i], C.indptr[i + 1]\n",
    "            cols = C.indices[start:end]\n",
    "            data = C.data[start:end]\n",
    "\n",
    "            # quitar self\n",
    "            m = cols != i\n",
    "            cols = cols[m]\n",
    "            data = data[m]\n",
    "\n",
    "            if cols.size == 0:\n",
    "                neigh_idx.append(np.array([], dtype=int))\n",
    "                continue\n",
    "\n",
    "            # limitar a top-k por peso\n",
    "            if cols.size > k:\n",
    "                sel = np.argpartition(-data, k - 1)[:k]\n",
    "                cols = cols[sel]\n",
    "                data = data[sel]\n",
    "                ord2 = np.argsort(-data)\n",
    "                cols = cols[ord2]\n",
    "\n",
    "            neigh_idx.append(cols.astype(int))\n",
    "        return neigh_idx\n",
    "\n",
    "    neigh_idx = topk_neighbors_from_connectivities(C, k=K)\n",
    "\n",
    "    labels = obs[\"Level2_final\"].astype(str).to_numpy()\n",
    "    all_levels = pd.Index(sorted(pd.unique(labels)))\n",
    "\n",
    "    # per-cell same-label fraction\n",
    "    same_frac = np.full(labels.shape[0], np.nan, dtype=float)\n",
    "    for i in range(labels.shape[0]):\n",
    "        nb = neigh_idx[i]\n",
    "        if nb.size == 0:\n",
    "            continue\n",
    "        same_frac[i] = np.mean(labels[nb] == labels[i])\n",
    "\n",
    "    df_purity = []\n",
    "    for lvl in all_levels:\n",
    "        m = labels == lvl\n",
    "        v = same_frac[m]\n",
    "        df_purity.append({\n",
    "            \"Level2_final\": lvl,\n",
    "            \"n_cells\": int(m.sum()),\n",
    "            \"mean_sameLabel_inNeighbors\": float(np.nanmean(v)),\n",
    "            \"median_sameLabel_inNeighbors\": float(np.nanmedian(v)),\n",
    "            \"p25_sameLabel_inNeighbors\": float(np.nanpercentile(v, 25)),\n",
    "            \"p75_sameLabel_inNeighbors\": float(np.nanpercentile(v, 75)),\n",
    "            \"na_cells\": int(np.isnan(v).sum()),\n",
    "        })\n",
    "\n",
    "    df_purity = pd.DataFrame(df_purity).sort_values(\n",
    "        [\"mean_sameLabel_inNeighbors\", \"n_cells\"], ascending=[True, False]\n",
    "    )\n",
    "\n",
    "    purity_path = OUT_DIR / \"QA_Level2final_neighbor_purity.csv\"\n",
    "    df_purity.to_csv(purity_path, index=False)\n",
    "    print(\"Saved:\", purity_path)\n",
    "    print(df_purity.head(10).to_string(index=False))\n",
    "\n",
    "    # distribución de etiquetas vecinas para HSCs\n",
    "    hsc_mask = labels == \"HSCs\"\n",
    "    if int(hsc_mask.sum()) > 0:\n",
    "        counts = {}\n",
    "        idx_hsc = np.where(hsc_mask)[0]\n",
    "        for i in idx_hsc:\n",
    "            for j in neigh_idx[i]:\n",
    "                lab = labels[j]\n",
    "                counts[lab] = counts.get(lab, 0) + 1\n",
    "\n",
    "        df_hsc_nb = (\n",
    "            pd.DataFrame({\"neighbor_label\": list(counts.keys()), \"n_edges\": list(counts.values())})\n",
    "              .sort_values(\"n_edges\", ascending=False)\n",
    "        )\n",
    "        df_hsc_nb[\"share\"] = df_hsc_nb[\"n_edges\"] / df_hsc_nb[\"n_edges\"].sum()\n",
    "\n",
    "        hsc_nb_path = OUT_DIR / \"QA_HSCs_neighbor_label_distribution.csv\"\n",
    "        df_hsc_nb.to_csv(hsc_nb_path, index=False)\n",
    "        print(\"Saved:\", hsc_nb_path)\n",
    "        print(df_hsc_nb.head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"[WARN] No hay HSCs en Level2_final (n=0). Se omite QA_HSCs_neighbor_label_distribution.csv\")\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a821bcdf-c413-415c-934e-87133d5a4185",
   "metadata": {},
   "source": [
    "### 4. Compactación en UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785d9b2-14c6-457c-86e9-83b178e2f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar solo columnas necesarias\n",
    "emb_cols = pd.read_csv(EMB_PATH, nrows=1).columns.tolist()\n",
    "usecols = [\"UMAP1_harmony\", \"UMAP2_harmony\"]\n",
    "\n",
    "if \"Level2_final\" in emb_cols:\n",
    "    usecols = [\"Level2_final\"] + usecols\n",
    "elif LEVEL2_KEY in emb_cols:\n",
    "    usecols = [LEVEL2_KEY] + usecols\n",
    "else:\n",
    "    raise KeyError(f\"{EMB_PATH.name} no contiene ni 'Level2_final' ni '{LEVEL2_KEY}'.\")\n",
    "\n",
    "emb = pd.read_csv(EMB_PATH, usecols=usecols)\n",
    "\n",
    "if \"Level2_final\" not in emb.columns:\n",
    "    emb[\"Level2_final\"] = emb[LEVEL2_KEY].astype(\"object\").replace(level2_map).astype(str)\n",
    "\n",
    "def compactness(df):\n",
    "    x = df[[\"UMAP1_harmony\", \"UMAP2_harmony\"]].to_numpy(float)\n",
    "    c = x.mean(axis=0)\n",
    "    d = np.sqrt(((x - c) ** 2).sum(axis=1))\n",
    "    return pd.Series({\n",
    "        \"n_cells\": int(x.shape[0]),\n",
    "        \"mean_radius\": float(d.mean()),\n",
    "        \"median_radius\": float(np.median(d)),\n",
    "        \"p75_radius\": float(np.percentile(d, 75)),\n",
    "        \"p95_radius\": float(np.percentile(d, 95)),\n",
    "    })\n",
    "\n",
    "df_comp = emb.groupby(\"Level2_final\", sort=False).apply(compactness).reset_index()\n",
    "\n",
    "comp_path = OUT_DIR / \"QA_Level2final_umap_compactness.csv\"\n",
    "df_comp.to_csv(comp_path, index=False)\n",
    "print(\"Saved:\", comp_path)\n",
    "print(df_comp.sort_values(\"mean_radius\", ascending=False).head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f44d18-5e34-4034-9f92-3dd0b62dec91",
   "metadata": {},
   "source": [
    "### 5. Panel numérico HSCs vs resto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7c863f-33ed-4559-920b-ab7f376da6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-abrir backed para extraer expresión de pocos genes\n",
    "adata_b = sc.read_h5ad(OUT_FILTER, backed=\"r\")\n",
    "try:\n",
    "    if LEVEL2_KEY not in adata_b.obs.columns:\n",
    "        raise KeyError(f\"Falta obs['{LEVEL2_KEY}'] en OUT_FILTER.\")\n",
    "    if \"Level2_final\" not in adata_b.obs.columns:\n",
    "        # no persistimos Level2_final en objeto; la reconstruimos por obs\n",
    "        pass\n",
    "\n",
    "    # reconstruir labels Level2_final para máscaras sin convertir NaN->\"nan\" antes de mapear\n",
    "    l2_obj = adata_b.obs[LEVEL2_KEY].astype(\"object\")\n",
    "    labels = l2_obj.replace(level2_map).astype(\"object\").astype(str).to_numpy()\n",
    "\n",
    "    mask_hsc = (labels == \"HSCs\")\n",
    "    if int(mask_hsc.sum()) == 0:\n",
    "        print(\"[WARN] No hay HSCs -> se omite panel de marcadores HSCs.\")\n",
    "        raise SystemExit(0)\n",
    "\n",
    "    CANDIDATES = [\n",
    "        \"CD34\",\"KIT\",\n",
    "        \"SOX4\",\"SPINK2\",\"AVP\",\n",
    "        \"GATA2\",\"LMO2\",\"TAL1\",\"MEIS1\",\"MPL\",\"HOPX\",\n",
    "        \"HMGB2\",\"TMSB10\",\"TYMP\"\n",
    "    ]\n",
    "\n",
    "    def symbol_to_varname(adata, symbol):\n",
    "        if symbol in adata.var_names:\n",
    "            return symbol\n",
    "        if \"symbol\" in adata.var.columns:\n",
    "            sym = adata.var[\"symbol\"].astype(str).to_numpy()\n",
    "            hits = np.where(sym == symbol)[0]\n",
    "            if hits.size > 0:\n",
    "                return adata.var_names[hits[0]]\n",
    "        return None\n",
    "\n",
    "    varnames = []\n",
    "    sym_kept = []\n",
    "    for s in CANDIDATES:\n",
    "        v = symbol_to_varname(adata_b, s)\n",
    "        if v is not None:\n",
    "            varnames.append(v)\n",
    "            sym_kept.append(s)\n",
    "\n",
    "    print(\"HSC panel: símbolos encontrados =\", len(sym_kept), \"/\", len(CANDIDATES))\n",
    "    if len(sym_kept) == 0:\n",
    "        raise RuntimeError(\"No encontré ninguno de los genes candidatos en var_names/var['symbol'].\")\n",
    "\n",
    "    adata_small = adata_b[:, varnames].to_memory()\n",
    "\n",
    "finally:\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# matriz a usar\n",
    "X = adata_small.layers[LAYER] if LAYER in adata_small.layers.keys() else adata_small.X\n",
    "if not sp.issparse(X):\n",
    "    X = sp.csr_matrix(X)\n",
    "X = X.tocsr()\n",
    "\n",
    "mask_rest = ~mask_hsc\n",
    "\n",
    "def mean_and_frac(Xsub):\n",
    "    mean = np.asarray(Xsub.mean(axis=0)).ravel()\n",
    "    frac = np.asarray((Xsub > 0).mean(axis=0)).ravel()\n",
    "    return mean, frac\n",
    "\n",
    "mean_h, frac_h = mean_and_frac(X[mask_hsc])\n",
    "mean_r, frac_r = mean_and_frac(X[mask_rest])\n",
    "\n",
    "df_hsc_panel = pd.DataFrame({\n",
    "    \"marker\": sym_kept,\n",
    "    \"mean_log1p_HSCs\": mean_h,\n",
    "    \"frac_nonzero_HSCs\": frac_h,\n",
    "    \"mean_log1p_rest\": mean_r,\n",
    "    \"frac_nonzero_rest\": frac_r,\n",
    "})\n",
    "df_hsc_panel[\"delta_mean\"] = df_hsc_panel[\"mean_log1p_HSCs\"] - df_hsc_panel[\"mean_log1p_rest\"]\n",
    "df_hsc_panel[\"delta_frac\"] = df_hsc_panel[\"frac_nonzero_HSCs\"] - df_hsc_panel[\"frac_nonzero_rest\"]\n",
    "\n",
    "panel_path = OUT_DIR / \"QA_HSCs_marker_panel_vs_rest.csv\"\n",
    "df_hsc_panel.sort_values([\"mean_log1p_HSCs\", \"frac_nonzero_HSCs\"], ascending=False).to_csv(panel_path, index=False)\n",
    "\n",
    "print(\"Saved:\", panel_path)\n",
    "print(df_hsc_panel.sort_values([\"mean_log1p_HSCs\",\"frac_nonzero_HSCs\"], ascending=False).head(10).to_string(index=False))\n",
    "\n",
    "# recomendación automática: top2 por score = mean * frac (dentro de HSCs)\n",
    "df_hsc_panel[\"score\"] = df_hsc_panel[\"mean_log1p_HSCs\"] * df_hsc_panel[\"frac_nonzero_HSCs\"]\n",
    "top2 = df_hsc_panel.sort_values(\"score\", ascending=False).head(2)[\"marker\"].tolist()\n",
    "print(\"[RECOMENDACIÓN] Marcadores HSCs (top2 por score=mean*frac):\", top2)\n",
    "\n",
    "print(\"[OK] QA coherence + HSCs listo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

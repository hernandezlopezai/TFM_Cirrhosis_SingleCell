{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b51b2-be0a-4047-9f6c-1cbc203ddd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PSEUDOBULK (por paciente) + DE Healthy vs Cirrhosis + VOLCANO\n",
    "# (EXTENDIDO: permite DE por Level2_final para subpoblaciones seleccionadas)\n",
    "#\n",
    "# - Usa el objeto FILTRADO: TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad (RBC-out)\n",
    "# - Memory-safe: lee en backed=\"r\" y procesa genes por CHUNKS\n",
    "#\n",
    "# Modo recomendado para el paso \"7) DE a nivel Level2\":\n",
    "#   ANALYSIS_LEVEL = \"Level2_final\"\n",
    "#\n",
    "# Outputs (por cada grupo analizado):\n",
    "#   * summary_tables_final/pseudobulk_{ANALYSIS_LEVEL}_{tag}_mean_log1p_10k.csv\n",
    "#   * summary_tables_final/DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.csv\n",
    "#   * figures_final/Volcano_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.png\n",
    "#   * ..._FOR_FIGURE.csv + ..._FOR_FIGURE.png (plot con TODOS los genes + highlights + labels TOP20)\n",
    "#   * tablas top10 agregadas (FOR_FIGURE / FOR_REPORT / FOR_REPORT_LINFO_CLEAN)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# stats\n",
    "try:\n",
    "    from scipy.stats import ttest_ind\n",
    "    HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    HAVE_SCIPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encuentro 'data_processed' subiendo desde: {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "IN_PATH = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "\n",
    "OUT_SUMMARY = PROJECT_ROOT / \"summary_tables_final\"\n",
    "OUT_FIG     = PROJECT_ROOT / \"figures_final\"\n",
    "OUT_SUMMARY.mkdir(exist_ok=True)\n",
    "OUT_FIG.mkdir(exist_ok=True)\n",
    "\n",
    "# Mapa Level2_final (Conv_T_other -> CD4_Memory, etc.)\n",
    "MAP_PATH = OUT_SUMMARY / \"Level2_final_map.json\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"IN_PATH     :\", IN_PATH)\n",
    "print(\"OUT_SUMMARY :\", OUT_SUMMARY)\n",
    "print(\"OUT_FIG     :\", OUT_FIG)\n",
    "print(\"MAP_PATH    :\", MAP_PATH)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Parámetros\n",
    "# -----------------------------\n",
    "LAYER = \"log1p_10k\"\n",
    "\n",
    "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "# CAMBIO CLAVE (Paso 7): análisis por Level2_final\n",
    "#   - \"Level2_final\": corre DE por subtipos Level2_final seleccionados\n",
    "#   - \"Level1_refined\": modo legacy (si lo necesitas)\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "ANALYSIS_LEVEL = \"Level2_final\"   # \"Level2_final\" (recomendado) o \"Level1_refined\"\n",
    "\n",
    "# Targets a correr (si ANALYSIS_LEVEL == \"Level2_final\")\n",
    "LEVEL2_FINAL_TO_RUN = [\n",
    "    # B / Plasma\n",
    "    \"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"Plasma\",\n",
    "    # T\n",
    "    \"CD4_Naive\", \"CD4_Memory\", \"CD8_Naive\", \"CD8_Effector_Cytotoxic\", \"Treg\", \"MAIT\", \"GammaDelta_T\",\n",
    "    # NK\n",
    "    \"NK\",\n",
    "    # Mono / DC\n",
    "    \"Classical_Mono\", \"NonClassical_Mono\", \"ISG_Myeloid\",\n",
    "    \"cDC1\", \"cDC2\", \"DC4\", \"aDC\",\n",
    "    # pDC\n",
    "    \"pDC\",\n",
    "]\n",
    "\n",
    "# Targets legacy (si ANALYSIS_LEVEL == \"Level1_refined\")\n",
    "LEVEL1_TO_RUN = [\"T\", \"Mono\", \"NK\", \"B\", \"DC\"]\n",
    "\n",
    "# Genes\n",
    "GENE_MODE = \"HVG\"     # \"HVG\" recomendado\n",
    "MAX_GENES = 2000\n",
    "GENE_CHUNK = 200\n",
    "\n",
    "# Estadística / umbrales\n",
    "PSEUDOCOUNT = 1e-6\n",
    "ALPHA_FDR = 0.05\n",
    "\n",
    "# Filtrado pacientes por grupo (subtipo/celltype)\n",
    "MIN_CELLS_PER_PATIENT = 20\n",
    "MIN_PATIENTS_PER_GROUP = 4          # min pacientes por disease\n",
    "MIN_PATIENTS_PER_TARGET = 6         # min pacientes totales con suficientes células para ese target\n",
    "\n",
    "# RBC-out robusto (por si apareciera por accidente en obs)\n",
    "EXCLUDE_LEVEL1REFINED = {\"RBC\"}\n",
    "EXCLUDE_LEVEL2 = {\"RBC\"}\n",
    "\n",
    "# Volcano “FOR_FIGURE” (resaltado/etiquetas)\n",
    "MIN_ABS_LOG2FC = 0.5\n",
    "MIN_MEAN_LOG1P = 0.20\n",
    "MIN_FRAC_PATIENTS = 0.50\n",
    "\n",
    "TOP_N_LABEL = 20\n",
    "\n",
    "# Blacklist opcional para linfoides: SOLO afecta a lo que resaltas/etiquetas (no al fondo)\n",
    "AMBIENT_MYELOID = {\"S100A8\",\"S100A9\",\"S100A12\",\"LYZ\",\"LST1\",\"TREM1\",\"CXCL8\"}\n",
    "\n",
    "# Columna esperada de fold-change (para evitar KeyErrors por CSVs viejos)\n",
    "FC_COL = \"log2FC_Healthy_vs_Cirrhosis\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def bh_fdr(pvals: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Benjamini-Hochberg FDR, devuelve q-values\"\"\"\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    n = p.size\n",
    "    order = np.argsort(p)\n",
    "    ranked = p[order]\n",
    "    q = ranked * n / (np.arange(1, n + 1))\n",
    "    q = np.minimum.accumulate(q[::-1])[::-1]\n",
    "    out = np.empty_like(q)\n",
    "    out[order] = np.clip(q, 0, 1)\n",
    "    return out\n",
    "\n",
    "def safe_tag(name: str) -> str:\n",
    "    \"\"\"Tag seguro para nombres de archivo.\"\"\"\n",
    "    s = str(name).strip()\n",
    "    s = s.replace(\" \", \"_\")\n",
    "    s = re.sub(r\"[^A-Za-z0-9_\\-\\.]+\", \"_\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s)\n",
    "    return s\n",
    "\n",
    "def get_gene_list(adata_b) -> List[str]:\n",
    "    if GENE_MODE == \"HVG\" and \"highly_variable\" in adata_b.var.columns:\n",
    "        hv = adata_b.var[\"highly_variable\"].values.astype(bool)\n",
    "        genes = adata_b.var_names[hv].tolist()\n",
    "        if len(genes) == 0:\n",
    "            print(\"[WARN] highly_variable existe pero vacío; uso primeras MAX_GENES.\")\n",
    "            genes = adata_b.var_names[:MAX_GENES].tolist()\n",
    "        else:\n",
    "            genes = genes[:MAX_GENES]\n",
    "        return genes\n",
    "    return adata_b.var_names[:MAX_GENES].tolist()\n",
    "\n",
    "def ensure_fc_col(df: pd.DataFrame, where: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Garantiza que exista FC_COL en df.\n",
    "    - Si existe, ok.\n",
    "    - Si hay 1 alternativa típica, renombra.\n",
    "    - Si no, lanza KeyError con info.\n",
    "    \"\"\"\n",
    "    if FC_COL in df.columns:\n",
    "        return df\n",
    "\n",
    "    # alternativas típicas (por si CSV viejo)\n",
    "    candidates = []\n",
    "    for c in df.columns:\n",
    "        cl = str(c).lower()\n",
    "        if \"log2fc\" in cl or \"logfc\" in cl or (\"fold\" in cl and \"log\" in cl):\n",
    "            candidates.append(c)\n",
    "\n",
    "    if len(candidates) == 1:\n",
    "        print(f\"[WARN] {where}: renombrando columna '{candidates[0]}' -> '{FC_COL}'\")\n",
    "        return df.rename(columns={candidates[0]: FC_COL})\n",
    "\n",
    "    raise KeyError(f\"[{where}] No encuentro '{FC_COL}'. Columnas={df.columns.tolist()}\")\n",
    "\n",
    "def volcano_plot_base(df_de: pd.DataFrame, out_png: Path, title: str, alpha_fdr: float = 0.05):\n",
    "    \"\"\"Volcano base (rápido).\"\"\"\n",
    "    df_de = ensure_fc_col(df_de, where=f\"volcano_plot_base({out_png.name})\")\n",
    "\n",
    "    x = df_de[FC_COL].to_numpy(dtype=float)\n",
    "    q = df_de[\"FDR\"].to_numpy(dtype=float)\n",
    "    y = -np.log10(np.clip(q, 1e-300, 1.0))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
    "    ax.scatter(x, y, s=10, alpha=0.8)\n",
    "    ax.axhline(-np.log10(alpha_fdr), linestyle=\"--\", linewidth=1)\n",
    "    ax.axvline(0, linestyle=\":\", linewidth=1)\n",
    "    ax.set_xlabel(\"log2FC (Healthy vs Cirrhosis) [pseudobulk per patient]\")\n",
    "    ax.set_ylabel(\"-log10(FDR)\")\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def volcano_for_figure(\n",
    "    df_all: pd.DataFrame,\n",
    "    out_png: Path,\n",
    "    title: str,\n",
    "    alpha_fdr: float = 0.05,\n",
    "    highlight_mask: Optional[np.ndarray] = None,\n",
    "    genes_to_label: Optional[List[str]] = None,\n",
    "    abs_log2fc_line: Optional[float] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Volcano plot:\n",
    "      - plotea TODOS los genes (df_all)\n",
    "      - colorea por estado (sig up / sig down / no sig)\n",
    "      - resalta (opcional) un subconjunto highlight_mask\n",
    "      - etiqueta (opcional) genes_to_label\n",
    "    Requisitos de columnas: gene, FC_COL, FDR\n",
    "    \"\"\"\n",
    "    df_all = ensure_fc_col(df_all, where=f\"volcano_for_figure({out_png.name})\")\n",
    "\n",
    "    x = df_all[FC_COL].to_numpy(dtype=float)\n",
    "    q = df_all[\"FDR\"].to_numpy(dtype=float)\n",
    "    y = -np.log10(np.clip(q, 1e-300, 1.0))\n",
    "\n",
    "    sig = q < alpha_fdr\n",
    "    up = sig & (x > 0)\n",
    "    down = sig & (x < 0)\n",
    "    ns = ~sig\n",
    "\n",
    "    cycle = plt.rcParams[\"axes.prop_cycle\"].by_key().get(\"color\", [\"C0\",\"C1\",\"C2\",\"C3\"])\n",
    "    col_down = cycle[0 % len(cycle)]\n",
    "    col_up   = cycle[1 % len(cycle)]\n",
    "    col_ns   = \"0.75\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.8, 5.8))\n",
    "    ax.scatter(x[ns], y[ns], s=10, alpha=0.6, c=col_ns, edgecolors=\"none\", label=\"Not significant\")\n",
    "    ax.scatter(x[down], y[down], s=12, alpha=0.85, c=col_down, edgecolors=\"none\",\n",
    "               label=f\"FDR<{alpha_fdr} (Higher in Cirrhosis)\")\n",
    "    ax.scatter(x[up], y[up], s=12, alpha=0.85, c=col_up, edgecolors=\"none\",\n",
    "               label=f\"FDR<{alpha_fdr} (Higher in Healthy)\")\n",
    "\n",
    "    if highlight_mask is not None:\n",
    "        hm = np.asarray(highlight_mask, dtype=bool)\n",
    "        hm = hm & np.isfinite(x) & np.isfinite(y)\n",
    "        ax.scatter(\n",
    "            x[hm], y[hm],\n",
    "            s=26, alpha=0.95,\n",
    "            facecolors=\"none\", edgecolors=\"k\", linewidths=0.7,\n",
    "            label=\"Highlighted (filters)\"\n",
    "        )\n",
    "\n",
    "    ax.axhline(-np.log10(alpha_fdr), linestyle=\"--\", linewidth=1)\n",
    "    ax.axvline(0, linestyle=\":\", linewidth=1)\n",
    "    if abs_log2fc_line is not None and abs_log2fc_line > 0:\n",
    "        ax.axvline(+abs_log2fc_line, linestyle=\"--\", linewidth=0.8)\n",
    "        ax.axvline(-abs_log2fc_line, linestyle=\"--\", linewidth=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"log2FC (Healthy vs Cirrhosis) [pseudobulk per patient]\")\n",
    "    ax.set_ylabel(\"-log10(FDR)\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    if genes_to_label is not None and len(genes_to_label) > 0:\n",
    "        df_lab = df_all[df_all[\"gene\"].astype(str).isin([str(g) for g in genes_to_label])].copy()\n",
    "        df_lab = df_lab.sort_values(\"FDR\", ascending=True)\n",
    "\n",
    "        offsets = [(6, 6), (6, -10), (-18, 6), (-18, -10)]\n",
    "        for k, (_, r) in enumerate(df_lab.iterrows()):\n",
    "            gx = float(r[FC_COL])\n",
    "            gy = -np.log10(max(float(r[\"FDR\"]), 1e-300))\n",
    "            ox, oy = offsets[k % len(offsets)]\n",
    "            ax.annotate(\n",
    "                str(r[\"gene\"]),\n",
    "                (gx, gy),\n",
    "                textcoords=\"offset points\",\n",
    "                xytext=(ox, oy),\n",
    "                ha=\"left\",\n",
    "                fontsize=8,\n",
    "                arrowprops=dict(arrowstyle=\"-\", lw=0.4, alpha=0.6),\n",
    "            )\n",
    "\n",
    "    ax.legend(frameon=False, fontsize=8, loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 0) Cargar mapa Level2_final\n",
    "# ============================================================\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    if not MAP_PATH.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"No existe MAP_PATH:\\n{MAP_PATH}\\n\"\n",
    "            \"Este notebook requiere Level2_final_map.json (Conv_T_other -> CD4_Memory, etc.).\"\n",
    "        )\n",
    "    with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        level2_map = json.load(f)\n",
    "else:\n",
    "    level2_map = {}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Cargar objeto (backed) + checks + preparar obs/pacientes/genes\n",
    "# ============================================================\n",
    "adata_b = sc.read_h5ad(IN_PATH, backed=\"r\")\n",
    "\n",
    "required_obs = [\"patientID\", \"disease\", \"Level1_refined\"]\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    required_obs.append(\"Level2\")\n",
    "\n",
    "for col in required_obs:\n",
    "    if col not in adata_b.obs.columns:\n",
    "        adata_b.file.close()\n",
    "        raise KeyError(f\"Falta columna en obs: {col}\")\n",
    "\n",
    "if LAYER not in adata_b.layers.keys():\n",
    "    adata_b.file.close()\n",
    "    raise KeyError(f\"No existe layer '{LAYER}' en adata.layers. Layers: {list(adata_b.layers.keys())}\")\n",
    "\n",
    "obs_cols = list(dict.fromkeys(required_obs))\n",
    "obs = adata_b.obs[obs_cols].copy()\n",
    "\n",
    "obs[\"patientID\"] = obs[\"patientID\"].astype(str)\n",
    "obs[\"disease\"] = obs[\"disease\"].astype(str)\n",
    "obs[\"Level1_refined\"] = obs[\"Level1_refined\"].astype(str)\n",
    "\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    obs[\"Level2\"] = obs[\"Level2\"].astype(str)\n",
    "    obs[\"Level2_final\"] = obs[\"Level2\"].replace(level2_map).astype(str)\n",
    "\n",
    "# RBC-out robusto\n",
    "if (obs[\"Level1_refined\"].isin(EXCLUDE_LEVEL1REFINED)).any():\n",
    "    print(\"[WARN] Detectado Level1_refined=RBC en obs. Se excluirá del análisis (RBC-out).\")\n",
    "\n",
    "valid_mask_global = ~obs[\"Level1_refined\"].isin(EXCLUDE_LEVEL1REFINED)\n",
    "\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    if (obs[\"Level2_final\"].isin(EXCLUDE_LEVEL2)).any():\n",
    "        print(\"[WARN] Detectado Level2_final=RBC en obs. Se excluirá del análisis (RBC-out).\")\n",
    "    valid_mask_global = valid_mask_global & (~obs[\"Level2_final\"].isin(EXCLUDE_LEVEL2))\n",
    "\n",
    "# pacientes y grupos\n",
    "patient_meta = obs.loc[valid_mask_global].drop_duplicates([\"patientID\", \"disease\"]).set_index(\"patientID\")\n",
    "patients = patient_meta.index.tolist()\n",
    "\n",
    "print(\"\\nPacientes totales:\", len(patients))\n",
    "print(patient_meta[\"disease\"].value_counts())\n",
    "\n",
    "# genes\n",
    "genes = get_gene_list(adata_b)\n",
    "print(\"\\nGenes usados:\", len(genes), f\"(mode={GENE_MODE}, MAX_GENES={MAX_GENES})\")\n",
    "\n",
    "# targets a correr\n",
    "if ANALYSIS_LEVEL == \"Level2_final\":\n",
    "    targets = list(LEVEL2_FINAL_TO_RUN)\n",
    "    target_col = \"Level2_final\"\n",
    "else:\n",
    "    targets = list(LEVEL1_TO_RUN)\n",
    "    target_col = \"Level1_refined\"\n",
    "\n",
    "print(\"\\nANALYSIS_LEVEL:\", ANALYSIS_LEVEL)\n",
    "print(\"target_col    :\", target_col)\n",
    "print(\"n targets (raw):\", len(targets))\n",
    "\n",
    "# ============================================================\n",
    "# 1.05) Filtrar targets a los que realmente existen en el objeto\n",
    "# ============================================================\n",
    "present_targets = set(obs.loc[valid_mask_global, target_col].dropna().astype(str).unique().tolist())\n",
    "missing_targets = [t for t in targets if t not in present_targets]\n",
    "targets = [t for t in targets if t in present_targets]\n",
    "\n",
    "print(\"Targets presentes tras filtrar:\", len(targets))\n",
    "if missing_targets:\n",
    "    print(\"[INFO] Targets no presentes (se omiten):\", missing_targets)\n",
    "\n",
    "if len(targets) == 0:\n",
    "    adata_b.file.close()\n",
    "    raise RuntimeError(\"Tras filtrar, no queda ningún target presente. Revisa target list / columnas.\")\n",
    "\n",
    "# ============================================================\n",
    "# 1.1) (opcional) mapa para decidir blacklist en linfoides (solo si Level2_final)\n",
    "# ============================================================\n",
    "order_by_group = {\n",
    "    \"B\":     [\"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"B_Other\"],\n",
    "    \"Plasma\":[\"Plasma\"],\n",
    "    \"pDC\":   [\"pDC\"],\n",
    "    \"T\":     [\"CD4_Naive\",\"CD4_Memory\",\"CD8_Naive\",\"CD8_Effector_Cytotoxic\",\"Treg\",\"MAIT\",\"GammaDelta_T\",\"Proliferative_T\",\"Exhausted_T\"],\n",
    "    \"NK\":    [\"NK\"],\n",
    "    \"Mono\":  [\"Classical_Mono\",\"NonClassical_Mono\",\"ISG_Myeloid\",\"MonoDC_Other\"],\n",
    "    \"DC\":    [\"cDC1\",\"cDC2\",\"DC4\",\"aDC\"],\n",
    "    \"HSCs\":  [\"HSCs\"],\n",
    "}\n",
    "\n",
    "def group_of_l2(l2: str) -> str:\n",
    "    for g, l2_list in order_by_group.items():\n",
    "        if l2 in l2_list:\n",
    "            return g\n",
    "    return \"Other\"\n",
    "\n",
    "APPLY_BLACKLIST_FOR_GROUPS = {\"T\", \"NK\", \"B\"}  # linfoides\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Loop pseudobulk + DE + volcanos (base)\n",
    "# ============================================================\n",
    "results_summary: List[Tuple[str, int, str]] = []\n",
    "\n",
    "for target in targets:\n",
    "    print(\"\\n==============================\")\n",
    "    print(f\"{ANALYSIS_LEVEL} target:\", target)\n",
    "\n",
    "    mask_target = valid_mask_global & (obs[target_col].values == target)\n",
    "\n",
    "    idx_by_patient: Dict[str, np.ndarray] = {}\n",
    "    n_cells_by_patient: Dict[str, int] = {}\n",
    "    for pid in patients:\n",
    "        idx = np.where(mask_target & (obs[\"patientID\"].values == pid))[0]\n",
    "        idx_by_patient[pid] = idx\n",
    "        n_cells_by_patient[pid] = int(idx.size)\n",
    "\n",
    "    keep_pids = [pid for pid, n in n_cells_by_patient.items() if n >= MIN_CELLS_PER_PATIENT]\n",
    "    print(f\"Pacientes con >={MIN_CELLS_PER_PATIENT} células:\", len(keep_pids), \"/\", len(patients))\n",
    "\n",
    "    if len(keep_pids) < MIN_PATIENTS_PER_TARGET:\n",
    "        print(\"[SKIP] Muy pocos pacientes con suficientes células para este target.\")\n",
    "        results_summary.append((str(target), len(keep_pids), \"SKIP_low_n\"))\n",
    "        continue\n",
    "\n",
    "    pb = np.full((len(keep_pids), len(genes)), np.nan, dtype=np.float32)\n",
    "    diseases: List[str] = []\n",
    "\n",
    "    for i, pid in enumerate(keep_pids):\n",
    "        idx_cells = idx_by_patient[pid]\n",
    "        n = idx_cells.size\n",
    "        diseases.append(patient_meta.loc[pid, \"disease\"])\n",
    "\n",
    "        sums = np.zeros(len(genes), dtype=np.float64)\n",
    "\n",
    "        for start in range(0, len(genes), GENE_CHUNK):\n",
    "            gchunk = genes[start:start + GENE_CHUNK]\n",
    "            view = adata_b[idx_cells, gchunk]\n",
    "            X = view.layers[LAYER]\n",
    "\n",
    "            try:\n",
    "                chunk_sum = np.asarray(X.sum(axis=0)).ravel()\n",
    "            except Exception:\n",
    "                chunk_sum = np.sum(np.asarray(X), axis=0)\n",
    "\n",
    "            sums[start:start + len(gchunk)] = chunk_sum\n",
    "\n",
    "        pb[i, :] = (sums / float(n)).astype(np.float32)\n",
    "\n",
    "    diseases = np.array(diseases, dtype=str)\n",
    "    keep_pids = np.array(keep_pids, dtype=str)\n",
    "\n",
    "    # pseudobulk DF\n",
    "    df_pb = pd.DataFrame(pb, index=keep_pids, columns=genes)\n",
    "    df_pb.insert(0, \"disease\", diseases)\n",
    "\n",
    "    tag = safe_tag(target)\n",
    "    out_pb_csv = OUT_SUMMARY / f\"pseudobulk_{ANALYSIS_LEVEL}_{tag}_mean_{LAYER}.csv\"\n",
    "    df_pb.to_csv(out_pb_csv)\n",
    "    print(\"Saved pseudobulk:\", out_pb_csv)\n",
    "\n",
    "    # DE (paciente-level)\n",
    "    A = df_pb[\"disease\"].values == \"Cirrhosis\"\n",
    "    B = df_pb[\"disease\"].values == \"Healthy\"\n",
    "    nA, nB = int(A.sum()), int(B.sum())\n",
    "    print(\"n patients Cirrhosis:\", nA, \"| Healthy:\", nB)\n",
    "\n",
    "    if nA < MIN_PATIENTS_PER_GROUP or nB < MIN_PATIENTS_PER_GROUP:\n",
    "        print(\"[SKIP] Muy pocos pacientes por grupo para DE en este target.\")\n",
    "        results_summary.append((str(target), len(keep_pids), \"SKIP_group_n\"))\n",
    "        continue\n",
    "\n",
    "    # log2FC en escala lineal aproximada: expm1(mean log1p)\n",
    "    X_lin = np.expm1(df_pb[genes].values.astype(np.float64))\n",
    "    meanA = np.nanmean(X_lin[A, :], axis=0)  # Cirrhosis\n",
    "    meanB = np.nanmean(X_lin[B, :], axis=0)  # Healthy\n",
    "    log2fc = np.log2((meanB + PSEUDOCOUNT) / (meanA + PSEUDOCOUNT))  # Healthy vs Cirrhosis\n",
    "\n",
    "    # pvals: Welch t-test sobre valores pseudobulk en log1p (paciente-level)\n",
    "    X_log = df_pb[genes].values.astype(np.float64)\n",
    "    if HAVE_SCIPY:\n",
    "        _, pvals = ttest_ind(X_log[B, :], X_log[A, :], axis=0, equal_var=False, nan_policy=\"omit\")\n",
    "        pvals = np.nan_to_num(pvals, nan=1.0, posinf=1.0, neginf=1.0)\n",
    "    else:\n",
    "        pvals = np.ones_like(log2fc, dtype=float)\n",
    "\n",
    "    fdr = bh_fdr(pvals)\n",
    "\n",
    "    df_de = pd.DataFrame({\n",
    "        \"gene\": genes,\n",
    "        \"mean_lin_Cirrhosis\": meanA,\n",
    "        \"mean_lin_Healthy\": meanB,\n",
    "        FC_COL: log2fc,\n",
    "        \"pval\": pvals,\n",
    "        \"FDR\": fdr,\n",
    "    }).sort_values(\"FDR\", ascending=True)\n",
    "\n",
    "    out_de_csv = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.csv\"\n",
    "    df_de.to_csv(out_de_csv, index=False)\n",
    "    print(\"Saved DE:\", out_de_csv)\n",
    "\n",
    "    out_png = OUT_FIG / f\"Volcano_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.png\"\n",
    "    volcano_plot_base(\n",
    "        df_de,\n",
    "        out_png,\n",
    "        title=f\"{ANALYSIS_LEVEL}={target}: Healthy vs Cirrhosis (pseudobulk, per patient)\",\n",
    "        alpha_fdr=ALPHA_FDR\n",
    "    )\n",
    "    print(\"Saved volcano (base):\", out_png)\n",
    "\n",
    "    n_sig = int((df_de[\"FDR\"].values < ALPHA_FDR).sum())\n",
    "    results_summary.append((str(target), len(keep_pids), f\"OK_sigFDR<{ALPHA_FDR}:{n_sig}\"))\n",
    "\n",
    "# cerramos backed\n",
    "adata_b.file.close()\n",
    "\n",
    "print(\"\\n=== RESUMEN (base) ===\")\n",
    "for row in results_summary:\n",
    "    print(row)\n",
    "\n",
    "print(\"\\n[OK] Pseudobulk + DE + volcano (base) terminado.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Volcanos \"FOR_FIGURE\" + CSVs filtrados (desde los outputs base)\n",
    "#    - df_plot (filtrado) se guarda como CSV\n",
    "#    - el plot usa df_f COMPLETO (todos los genes)\n",
    "#    - etiqueta TOP 20 (balanceado up/down)\n",
    "# ============================================================\n",
    "print(\"\\n[SEC3] Generando volcanos FOR_FIGURE (all genes + highlights + TOP labels) ...\")\n",
    "\n",
    "sec3_summary: List[Tuple[str, int, int]] = []  # (target, n_highlight, n_labels)\n",
    "targets_for_figure_generated: List[str] = []   # <- SOLO los que generamos AHORA\n",
    "\n",
    "targets_for_figure_generated = []\n",
    "\n",
    "for target in targets:\n",
    "    tag = safe_tag(target)\n",
    "    de_path = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.csv\"\n",
    "    pb_path = OUT_SUMMARY / f\"pseudobulk_{ANALYSIS_LEVEL}_{tag}_mean_{LAYER}.csv\"\n",
    "\n",
    "    if not de_path.exists() or not pb_path.exists():\n",
    "        print(\"[SKIP] faltan archivos para\", target)\n",
    "        continue\n",
    "\n",
    "    df_de = pd.read_csv(de_path)\n",
    "    try:\n",
    "        df_de = ensure_fc_col(df_de, where=str(de_path))\n",
    "    except KeyError as e:\n",
    "        print(\"[WARN] CSV DE incompatible, salto target:\", target)\n",
    "        print(\" \", e)\n",
    "        continue\n",
    "\n",
    "    df_pb = pd.read_csv(pb_path, index_col=0)  # patientID índice\n",
    "\n",
    "    gene_cols = [c for c in df_pb.columns if c != \"disease\"]\n",
    "    X = df_pb[gene_cols].astype(float).values\n",
    "\n",
    "    mean_log1p = X.mean(axis=0)\n",
    "    frac_pat = (X > 0.1).mean(axis=0)\n",
    "\n",
    "    df_f = df_de.merge(\n",
    "        pd.DataFrame({\"gene\": gene_cols, \"mean_log1p\": mean_log1p, \"frac_patients\": frac_pat}),\n",
    "        on=\"gene\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # ensure fold-change column\n",
    "    df_f = ensure_fc_col(df_f, where=f\"merge(df_de, df_pb) target={target}\")\n",
    "\n",
    "    keep = (\n",
    "        (df_f[\"FDR\"] < ALPHA_FDR) &\n",
    "        (df_f[FC_COL].abs() >= MIN_ABS_LOG2FC) &\n",
    "        (df_f[\"mean_log1p\"] >= MIN_MEAN_LOG1P) &\n",
    "        (df_f[\"frac_patients\"] >= MIN_FRAC_PATIENTS)\n",
    "    )\n",
    "\n",
    "    df_plot = df_f.loc[keep].copy()\n",
    "\n",
    "    # blacklist SOLO afecta a lo que resaltas/etiquetas (no al fondo)\n",
    "    keep2 = keep.copy()\n",
    "    if ANALYSIS_LEVEL == \"Level1_refined\":\n",
    "        apply_blacklist = (str(target) in {\"T\", \"NK\", \"B\"})\n",
    "    else:\n",
    "        apply_blacklist = (group_of_l2(str(target)) in APPLY_BLACKLIST_FOR_GROUPS)\n",
    "\n",
    "    if apply_blacklist:\n",
    "        keep2 = keep2 & (~df_f[\"gene\"].isin(AMBIENT_MYELOID))\n",
    "        df_plot = df_plot[~df_plot[\"gene\"].isin(AMBIENT_MYELOID)].copy()\n",
    "\n",
    "    df_plot = df_plot.sort_values(\"FDR\", ascending=True)\n",
    "\n",
    "    out_csv = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis_FOR_FIGURE.csv\"\n",
    "    df_plot.to_csv(out_csv, index=False)\n",
    "    targets_for_figure_generated.append(target)\n",
    "\n",
    "\n",
    "    # -------- seleccionar genes a etiquetar (TOP 20) --------\n",
    "    cand = df_f.loc[keep2].copy().sort_values(\"FDR\", ascending=True)\n",
    "\n",
    "    n_each = TOP_N_LABEL // 2\n",
    "    cand_up = cand[cand[FC_COL] > 0].head(n_each)\n",
    "    cand_dn = cand[cand[FC_COL] < 0].head(n_each)\n",
    "\n",
    "    genes_to_label = pd.concat([cand_up, cand_dn], axis=0)[\"gene\"].astype(str).tolist()\n",
    "\n",
    "    if len(genes_to_label) < TOP_N_LABEL:\n",
    "        extra = cand[~cand[\"gene\"].astype(str).isin(genes_to_label)].head(TOP_N_LABEL - len(genes_to_label))\n",
    "        genes_to_label += extra[\"gene\"].astype(str).tolist()\n",
    "\n",
    "    out_png = OUT_FIG / f\"Volcano_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis_FOR_FIGURE.png\"\n",
    "    volcano_for_figure(\n",
    "        df_all=df_f,  # <- TODOS los genes\n",
    "        out_png=out_png,\n",
    "        title=f\"{ANALYSIS_LEVEL}={target}: Healthy vs Cirrhosis (pseudobulk) — volcano (all genes)\",\n",
    "        alpha_fdr=ALPHA_FDR,\n",
    "        highlight_mask=keep2.to_numpy(),\n",
    "        genes_to_label=genes_to_label,\n",
    "        abs_log2fc_line=MIN_ABS_LOG2FC,\n",
    "    )\n",
    "\n",
    "    n_high = int(np.sum(keep2))\n",
    "    sec3_summary.append((str(target), n_high, len(genes_to_label)))\n",
    "    targets_for_figure_generated.append(str(target))\n",
    "\n",
    "    print(f\"{target}: genes destacados (keep2)={n_high} | genes etiquetados={len(genes_to_label)}\")\n",
    "    print(\"  Saved:\", out_png)\n",
    "    print(\"  Saved:\", out_csv)\n",
    "\n",
    "print(\"\\n[OK] Volcanos 'FOR_FIGURE' generados.\")\n",
    "print(\"Targets generados en ESTA corrida (FOR_FIGURE):\", targets_for_figure_generated)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Tablas top10 (FOR_FIGURE y FOR_REPORT)\n",
    "#    - Por cada target, usa SU CSV_FOR_FIGURE (GENERADO EN ESTA CORRIDA)\n",
    "#    - Objetivo ahora: DIAGNÓSTICO del KeyError (encontrar qué CSV está mal)\n",
    "# ============================================================\n",
    "print(\"\\n[SEC4] Generando tablas top10 agregadas ...\")\n",
    "\n",
    "FC_COL = \"log2FC_Healthy_vs_Cirrhosis\"\n",
    "\n",
    "HOUSEKEEPING = {\n",
    "    \"GAPDH\",\"ACTB\",\"ACTG1\",\"B2M\",\"MALAT1\",\"EEF1A1\",\"RPLP0\",\"RPSA\",\"TMSB10\",\"FTH1\",\"FTL\"\n",
    "}\n",
    "def is_bad_gene(g: str) -> bool:\n",
    "    g = str(g)\n",
    "    if g in HOUSEKEEPING: return True\n",
    "    if g.startswith(\"MT-\"): return True\n",
    "    if g.startswith(\"RPL\") or g.startswith(\"RPS\"): return True\n",
    "    return False\n",
    "\n",
    "rows_fig: List[List[object]] = []\n",
    "rows_rep: List[List[object]] = []\n",
    "rows_rep_linfo: List[List[object]] = []\n",
    "\n",
    "# USAR SOLO CSVs generados en SEC3 (si existe la lista)\n",
    "try:\n",
    "    targets_iter = targets_for_figure_generated\n",
    "    print(\"[SEC4] usando targets_for_figure_generated:\", len(targets_iter))\n",
    "except NameError:\n",
    "    targets_iter = targets\n",
    "    print(\"[SEC4][WARN] targets_for_figure_generated NO existe -> usando targets:\", len(targets_iter))\n",
    "\n",
    "for target in targets_iter:\n",
    "    tag = safe_tag(target)\n",
    "    path = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis_FOR_FIGURE.csv\"\n",
    "\n",
    "    print(\"\\n[SEC4] target =\", target)\n",
    "    print(\"[SEC4] path   =\", path)\n",
    "\n",
    "    if not path.exists():\n",
    "        print(\"[SEC4][MISSING] No existe el FOR_FIGURE CSV -> skip\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    if df.shape[0] == 0:\n",
    "        print(\"[WARN] FOR_FIGURE CSV vacío (0 genes). Lo salto:\", target)\n",
    "        continue\n",
    "\n",
    "    print(\"[SEC4] columns =\", df.columns.tolist())\n",
    "    print(\"[SEC4] columns_repr =\", [repr(c) for c in df.columns])\n",
    "    print(df.head(2))\n",
    "\n",
    "    # ---- DIAGNÓSTICO CLAVE ----\n",
    "    if FC_COL not in df.columns:\n",
    "        print(f\"\\n[SEC4][ERROR REAL] Este CSV NO tiene la columna {FC_COL}. ESTE ES EL CULPABLE.\")\n",
    "        print(\"CSV culpable:\", path)\n",
    "\n",
    "        base_path = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.csv\"\n",
    "        print(\"DE base esperado:\", base_path)\n",
    "        if base_path.exists():\n",
    "            df_base = pd.read_csv(base_path, nrows=2)\n",
    "            print(\"[SEC4] base DE columns =\", df_base.columns.tolist())\n",
    "        else:\n",
    "            print(\"[SEC4] base DE NO existe.\")\n",
    "\n",
    "        # cortamos aquí a propósito\n",
    "        raise KeyError(f\"Falta {FC_COL} en {path}\")\n",
    "\n",
    "    # a partir de aquí ya es el SEC4 normal (solo si el CSV está bien)\n",
    "    df = df.sort_values(\"FDR\", ascending=True)\n",
    "    df[\"gene\"] = df[\"gene\"].astype(str)\n",
    "\n",
    "    # FOR_FIGURE top10\n",
    "    top_healthy = df[df[FC_COL] > 0].head(10)\n",
    "    top_cirr    = df[df[FC_COL] < 0].head(10)\n",
    "\n",
    "    for _, r in top_healthy.iterrows():\n",
    "        rows_fig.append([str(target), \"Higher_in_Healthy\", r[\"gene\"], r[FC_COL], r[\"FDR\"]])\n",
    "    for _, r in top_cirr.iterrows():\n",
    "        rows_fig.append([str(target), \"Higher_in_Cirrhosis\", r[\"gene\"], r[FC_COL], r[\"FDR\"]])\n",
    "\n",
    "    # FOR_REPORT top10 (quita housekeeping/ribo/MT)\n",
    "    mask_keep = ~df[\"gene\"].map(is_bad_gene).astype(bool)\n",
    "    df_rep = df.loc[mask_keep].copy()\n",
    "\n",
    "    top_healthy_r = df_rep[df_rep[FC_COL] > 0].head(10)\n",
    "    top_cirr_r    = df_rep[df_rep[FC_COL] < 0].head(10)\n",
    "\n",
    "    for _, r in top_healthy_r.iterrows():\n",
    "        rows_rep.append([str(target), \"Higher_in_Healthy\", r[\"gene\"], r[FC_COL], r[\"FDR\"]])\n",
    "    for _, r in top_cirr_r.iterrows():\n",
    "        rows_rep.append([str(target), \"Higher_in_Cirrhosis\", r[\"gene\"], r[FC_COL], r[\"FDR\"]])\n",
    "\n",
    "    # FOR_REPORT_LINFO_CLEAN (extra: quitar “ambient myeloid” en linfoides)\n",
    "    df_rep_l = df_rep.copy()\n",
    "    if ANALYSIS_LEVEL == \"Level1_refined\":\n",
    "        apply_blacklist = (str(target) in {\"T\", \"NK\", \"B\"})\n",
    "    else:\n",
    "        apply_blacklist = (group_of_l2(str(target)) in APPLY_BLACKLIST_FOR_GROUPS)\n",
    "\n",
    "    if apply_blacklist:\n",
    "        df_rep_l = df_rep_l[~df_rep_l[\"gene\"].isin(AMBIENT_MYELOID)].copy()\n",
    "\n",
    "    top_healthy_l = df_rep_l[df_rep_l[FC_COL] > 0].head(10)\n",
    "    top_cirr_l    = df_rep_l[df_rep_l[FC_COL] < 0].head(10)\n",
    "\n",
    "    for _, r in top_healthy_l.iterrows():\n",
    "        rows_rep_linfo.append([str(target), \"Higher_in_Healthy\", r[\"gene\"], r[FC_COL], r[\"FDR\"]])\n",
    "    for _, r in top_cirr_l.iterrows():\n",
    "        rows_rep_linfo.append([str(target), \"Higher_in_Cirrhosis\", r[\"gene\"], r[FC_COL], r[\"FDR\"]])\n",
    "\n",
    "df_fig = pd.DataFrame(rows_fig, columns=[ANALYSIS_LEVEL, \"direction\", \"gene\", FC_COL, \"FDR\"])\n",
    "df_rep = pd.DataFrame(rows_rep, columns=[ANALYSIS_LEVEL, \"direction\", \"gene\", FC_COL, \"FDR\"])\n",
    "df_rep_l = pd.DataFrame(rows_rep_linfo, columns=[ANALYSIS_LEVEL, \"direction\", \"gene\", FC_COL, \"FDR\"])\n",
    "\n",
    "out_fig = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_FOR_FIGURE_top10_by_target.csv\"\n",
    "out_rep = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_FOR_REPORT_top10_by_target.csv\"\n",
    "out_rep_l = OUT_SUMMARY / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_FOR_REPORT_LINFO_CLEAN_top10_by_target.csv\"\n",
    "\n",
    "df_fig.to_csv(out_fig, index=False)\n",
    "df_rep.to_csv(out_rep, index=False)\n",
    "df_rep_l.to_csv(out_rep_l, index=False)\n",
    "\n",
    "print(\"\\nSaved:\", out_fig)\n",
    "print(\"Saved:\", out_rep)\n",
    "print(\"Saved:\", out_rep_l)\n",
    "print(\"\\n[OK] Tablas top10 generadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7f5eb-441e-4ff7-8637-ba4a529c1951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = pd.read_csv(de_path, nrows=5)\n",
    "print(\"DE columns:\", df_de.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6facd4e-a81c-44d6-b543-1cd4643c5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PSEUDOBULK (por paciente) + DE Healthy vs Cirrhosis + VOLCANO\n",
    "# (EXTENDIDO: permite DE por Level2_final para subpoblaciones seleccionadas)\n",
    "#\n",
    "# - Usa el objeto FILTRADO: TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad (RBC-out)\n",
    "# - Memory-safe: lee en backed=\"r\" y procesa genes por CHUNKS\n",
    "#\n",
    "# Modo recomendado para el paso \"7) DE a nivel Level2\":\n",
    "#   ANALYSIS_LEVEL = \"Level2_final\"\n",
    "#\n",
    "# Outputs (por cada grupo analizado):\n",
    "#   * summary_tables_final/pseudobulk_{ANALYSIS_LEVEL}_{tag}_mean_log1p_10k.csv\n",
    "#   * summary_tables_final/DE_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.csv\n",
    "#   * figures_final/Volcano_pseudobulk_{ANALYSIS_LEVEL}_{tag}_Healthy_vs_Cirrhosis.png\n",
    "#   * ..._FOR_FIGURE.csv + ..._FOR_FIGURE.png (plot con TODOS los genes + highlights + labels TOP20)\n",
    "#   * tablas top10 agregadas (FOR_FIGURE / FOR_REPORT / FOR_REPORT_LINFO_CLEAN)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# stats\n",
    "try:\n",
    "    from scipy.stats import ttest_ind\n",
    "    HAVE_SCIPY = True\n",
    "except Exception:\n",
    "    HAVE_SCIPY = False\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encuentro 'data_processed' subiendo desde: {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "IN_PATH = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "\n",
    "OUT_SUMMARY = PROJECT_ROOT / \"summary_tables_final\"\n",
    "OUT_FIG     = PROJECT_ROOT / \"figures_final\"\n",
    "OUT_SUMMARY.mkdir(exist_ok=True)\n",
    "OUT_FIG.mkdir(exist_ok=True)\n",
    "\n",
    "# Mapa Level2_final (Conv_T_other -> CD4_Memory, etc.)\n",
    "MAP_PATH = OUT_SUMMARY / \"Level2_final_map.json\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"IN_PATH     :\", IN_PATH)\n",
    "print(\"OUT_SUMMARY :\", OUT_SUMMARY)\n",
    "print(\"OUT_FIG     :\", OUT_FIG)\n",
    "print(\"MAP_PATH    :\", MAP_PATH)\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "\n",
    "print(\"CWD:\", Path.cwd())\n",
    "\n",
    "# Reutiliza tus variables si ya existen\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"OUT_FIG     :\", OUT_FIG)\n",
    "\n",
    "# Lista TODOS los volcanos en ese OUT_FIG\n",
    "vols = sorted(OUT_FIG.glob(\"Volcano_pseudobulk_Level2_final_*_FOR_FIGURE.png\"))\n",
    "print(\"\\n[OUT_FIG] N volcanos FOR_FIGURE:\", len(vols))\n",
    "for p in vols[:30]:\n",
    "    t = dt.datetime.fromtimestamp(p.stat().st_mtime)\n",
    "    print(t.strftime(\"%Y-%m-%d %H:%M:%S\"), \"-\", p.name)\n",
    "\n",
    "# Busca también si existen en Documents (root “equivocado” típico)\n",
    "docs = Path(r\"D:\\Users\\Coni\\Documents\")\n",
    "vols_docs = sorted(docs.glob(\"figures_final/Volcano_pseudobulk_Level2_final_*_FOR_FIGURE.png\"))\n",
    "print(\"\\n[Documents/figures_final] N volcanos FOR_FIGURE:\", len(vols_docs))\n",
    "for p in vols_docs[:30]:\n",
    "    t = dt.datetime.fromtimestamp(p.stat().st_mtime)\n",
    "    print(t.strftime(\"%Y-%m-%d %H:%M:%S\"), \"-\", p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70df88f-cdc9-4b53-847b-4ccac57ae8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MINI-SUMMARY para Results 3.3 (DE pseudobulk) — ligero y “pegable”\n",
    "# - Lee CSVs DE completos si existen; si no, cae a *_FOR_FIGURE.csv\n",
    "# - Saca: #DE genes (FDR<0.05), top genes por dirección, presencia de “stress genes”\n",
    "# - Genera un TXT/MD compacto en summary_tables_final/\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- localiza PROJECT_ROOT ---\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "if not (PROJECT_ROOT / \"summary_tables_final\").exists():\n",
    "    if (PROJECT_ROOT.parent / \"summary_tables_final\").exists():\n",
    "        PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "SUM_DIR = PROJECT_ROOT / \"summary_tables_final\"\n",
    "OUT_TXT = SUM_DIR / \"Fig3_DE_Level2final_compact_summary.txt\"\n",
    "\n",
    "ANALYSIS_LEVEL = \"Level2_final\"\n",
    "FC_COL = \"log2FC_Healthy_vs_Cirrhosis\"\n",
    "FDR_COL = \"FDR\"\n",
    "\n",
    "# >>> Elige aquí tus 6 paneles <<<\n",
    "TARGETS = [\n",
    "    \"Classical_Mono\",\n",
    "    \"NK\",\n",
    "    \"CD4_Memory\",\n",
    "    \"CD4_Naive\",\n",
    "    \"CD8_Naive\",\n",
    "    \"B_Naive\",\n",
    "]\n",
    "\n",
    "# Genes “recurrent activation/stress” del texto legacy (ajusta si quieres)\n",
    "KEY_GENES = [\n",
    "    \"JUN\",\"DUSP1\",\"TNFAIP3\",\"KLF6\",\"CD69\",\n",
    "    \"CXCL8\",\"NFKB1\",\"NAMPT\",\"VIM\",\"SRGN\",\n",
    "    \"CSF1R\",\"CD86\",\"ENTPD1\"\n",
    "]\n",
    "\n",
    "FDR_THR = 0.05\n",
    "TOP_N = 10   # top genes por dirección (por FDR)\n",
    "ROUND_FC = 3\n",
    "ROUND_FDR = 3\n",
    "\n",
    "def _to_num(s):\n",
    "    # robusto a coma decimal (si algún CSV lo trae así)\n",
    "    return pd.to_numeric(s.astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "\n",
    "def load_de(target: str):\n",
    "    full = SUM_DIR / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{target}_Healthy_vs_Cirrhosis.csv\"\n",
    "    fig  = SUM_DIR / f\"DE_pseudobulk_{ANALYSIS_LEVEL}_{target}_Healthy_vs_Cirrhosis_FOR_FIGURE.csv\"\n",
    "    if full.exists():\n",
    "        path = full\n",
    "        mode = \"FULL\"\n",
    "    elif fig.exists():\n",
    "        path = fig\n",
    "        mode = \"FOR_FIGURE_FALLBACK\"\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "    # leer solo columnas mínimas\n",
    "    usecols = None\n",
    "    df = pd.read_csv(path)\n",
    "    # normaliza columnas mínimas\n",
    "    need = {\"gene\", FC_COL, FDR_COL}\n",
    "    missing = need - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"{path.name}: faltan columnas {missing}. Cols={df.columns.tolist()}\")\n",
    "\n",
    "    df = df[[\"gene\", FC_COL, FDR_COL] + ([c for c in [\"pval\"] if c in df.columns])].copy()\n",
    "    df[\"gene\"] = df[\"gene\"].astype(str)\n",
    "\n",
    "    df[FC_COL] = _to_num(df[FC_COL])\n",
    "    df[FDR_COL] = _to_num(df[FDR_COL])\n",
    "\n",
    "    df = df.dropna(subset=[FC_COL, FDR_COL])\n",
    "    return df, path.name, mode\n",
    "\n",
    "def top_table(df, direction: str, n=TOP_N):\n",
    "    # direction: \"Higher_in_Cirrhosis\" => log2FC (Healthy vs Cirrhosis) NEGATIVO\n",
    "    if direction == \"Higher_in_Cirrhosis\":\n",
    "        sub = df[df[FC_COL] < 0].copy()\n",
    "    else:\n",
    "        sub = df[df[FC_COL] > 0].copy()\n",
    "\n",
    "    sub = sub.sort_values(FDR_COL, ascending=True).head(n)\n",
    "    if sub.shape[0] == 0:\n",
    "        return []\n",
    "    out = []\n",
    "    for _, r in sub.iterrows():\n",
    "        out.append(f\"{r['gene']}({r[FC_COL]:.{ROUND_FC}f},FDR={r[FDR_COL]:.{ROUND_FDR}g})\")\n",
    "    return out\n",
    "\n",
    "lines = []\n",
    "lines.append(\"FIG3 — DE pseudobulk Level2_final (Healthy vs Cirrhosis)\")\n",
    "lines.append(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "lines.append(f\"SUM_DIR     : {SUM_DIR}\")\n",
    "lines.append(f\"Targets     : {', '.join(TARGETS)}\")\n",
    "lines.append(f\"Key genes   : {', '.join(KEY_GENES)}\")\n",
    "lines.append(\"\")\n",
    "\n",
    "# acumula para “recurrent genes”\n",
    "freq_cirr = {}\n",
    "freq_heal = {}\n",
    "\n",
    "for t in TARGETS:\n",
    "    df, fname, mode = load_de(t)\n",
    "    if df is None:\n",
    "        lines.append(f\"[MISSING] {t}: no encuentro CSV FULL ni FOR_FIGURE\")\n",
    "        lines.append(\"\")\n",
    "        continue\n",
    "\n",
    "    sig = df[df[FDR_COL] < FDR_THR]\n",
    "    n_sig = int(sig.shape[0])\n",
    "    n_sig_cirr = int((sig[FC_COL] < 0).sum())\n",
    "    n_sig_heal = int((sig[FC_COL] > 0).sum())\n",
    "\n",
    "    top_cirr = top_table(df, \"Higher_in_Cirrhosis\", TOP_N)\n",
    "    top_heal = top_table(df, \"Higher_in_Healthy\", TOP_N)\n",
    "\n",
    "    # freq (solo top list para “recurrent” rápido)\n",
    "    for g in [x.split(\"(\")[0] for x in top_cirr]:\n",
    "        freq_cirr[g] = freq_cirr.get(g, 0) + 1\n",
    "    for g in [x.split(\"(\")[0] for x in top_heal]:\n",
    "        freq_heal[g] = freq_heal.get(g, 0) + 1\n",
    "\n",
    "    present_keys = [g for g in KEY_GENES if (df[\"gene\"] == g).any()]\n",
    "    # separa keys por dirección (mirando signo del FC)\n",
    "    key_dir = []\n",
    "    for g in present_keys:\n",
    "        rmin = df.loc[df[\"gene\"] == g].sort_values(FDR_COL).head(1)\n",
    "        if rmin.shape[0] == 1:\n",
    "            fc = float(rmin[FC_COL].iloc[0])\n",
    "            dd = \"Cirrhosis↑\" if fc < 0 else \"Healthy↑\"\n",
    "            key_dir.append(f\"{g}:{dd}\")\n",
    "\n",
    "    lines.append(f\"=== {t} ===\")\n",
    "    lines.append(f\"source: {fname} ({mode})\")\n",
    "    lines.append(f\"sig(FDR<{FDR_THR}): {n_sig}  | Cirrhosis↑: {n_sig_cirr}  | Healthy↑: {n_sig_heal}\")\n",
    "    lines.append(f\"top Cirrhosis↑ (log2FC<0): \" + (\", \".join(top_cirr[:10]) if top_cirr else \"NA\"))\n",
    "    lines.append(f\"top Healthy↑   (log2FC>0): \" + (\", \".join(top_heal[:10]) if top_heal else \"NA\"))\n",
    "    lines.append(f\"key genes hit: \" + (\", \".join(key_dir) if key_dir else \"none\"))\n",
    "    lines.append(\"\")\n",
    "\n",
    "# recurrent summary\n",
    "def top_freq(d, k=15):\n",
    "    items = sorted(d.items(), key=lambda x: (-x[1], x[0]))\n",
    "    return items[:k]\n",
    "\n",
    "lines.append(\"=== Recurrent genes across the 6 panels (from TOP lists) ===\")\n",
    "lines.append(\"Cirrhosis↑ most frequent: \" + \", \".join([f\"{g}×{n}\" for g, n in top_freq(freq_cirr)]))\n",
    "lines.append(\"Healthy↑ most frequent  : \" + \", \".join([f\"{g}×{n}\" for g, n in top_freq(freq_heal)]))\n",
    "lines.append(\"\")\n",
    "\n",
    "OUT_TXT.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(\"\\n\".join(lines[:80]))  # imprime solo el inicio en pantalla (ligero)\n",
    "print(\"\\n[OK] Guardado resumen compacto en:\", OUT_TXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1830650-a708-4763-960e-d0631517362d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfm_scRNA)",
   "language": "python",
   "name": "tfm_scrna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

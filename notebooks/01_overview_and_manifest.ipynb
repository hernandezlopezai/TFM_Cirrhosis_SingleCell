{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d7a89f3-0589-437a-9fc0-c515b5f95419",
   "metadata": {},
   "source": [
    "# 01 – Visión general del proyecto y lectura del MANIFEST\n",
    "\n",
    "Notebook de entrada del TFM de scRNA-seq en cirrosis.  \n",
    "Sirve como ficha técnica del proyecto y del objeto `.h5ad` de entrada.  \n",
    "No modifica datos biológicos; solo configura rutas, lee el MANIFEST y describe el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7b262-2e3a-4013-9965-d931cfbaaa00",
   "metadata": {},
   "source": [
    "## 1. Tipo de datos con los que trabajaremos\n",
    "\n",
    "- Objeto principal: `TFM_CIRRHOSIS_merged.h5ad` (AnnData, scRNA-seq: células × genes).\n",
    "- Archivos auxiliares en `AI_Package/`:\n",
    "  - Scripts del pipeline (`scripts/*_min.py`).\n",
    "  - Contexto y documentación (markers, atlas, equivalencias, etc.).\n",
    "- En los siguientes notebooks se hará QC, integración y anotación; aquí solo se documenta el punto de partida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3928d5a-57a7-4168-844e-78a148859b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanpy: scanpy\n",
      "AnnData: anndata\n"
     ]
    }
   ],
   "source": [
    "# Importamos las bibliotecas básicas que usaremos en este notebook.\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "print(\"Scanpy:\", sc.__name__)\n",
    "print(\"AnnData:\", ad.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408b537-05ed-4887-b5b4-dee8541791d2",
   "metadata": {},
   "source": [
    "## 2. Organización provisional de carpetas del proyecto\n",
    "\n",
    "- Se asume que este notebook está en `notebooks/`.\n",
    "- A partir de ahí se definen:\n",
    "  - `PROJECT_ROOT` = carpeta raíz del proyecto.\n",
    "  - `AI_PACKAGE_DIR` = `PROJECT_ROOT / \"AI_Package\"`.\n",
    "  - `DATA_RAW_DIR`   = `PROJECT_ROOT / \"data_raw\"`.\n",
    "- Se comprueba en pantalla si existen `AI_Package/` y `data_raw/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a61370-12c7-4ace-ac5f-d30635a951d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio del notebook: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\notebooks\n",
      "Raíz del proyecto: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\n",
      "Carpeta AI_Package: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\AI_Package\n",
      "Carpeta data_raw: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\data_raw\n",
      "\n",
      "¿Existe AI_Package?: True\n",
      "¿Existe data_raw?:    True\n"
     ]
    }
   ],
   "source": [
    "# Detectamos la carpeta raíz del proyecto asumiendo que este notebook está en \"notebooks/\"\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "AI_PACKAGE_DIR = PROJECT_ROOT / \"AI_Package\"\n",
    "DATA_RAW_DIR   = PROJECT_ROOT / \"data_raw\"  # carpeta recomendada para datos pesados\n",
    "\n",
    "print(\"Directorio del notebook:\", NOTEBOOK_DIR)\n",
    "print(\"Raíz del proyecto:\", PROJECT_ROOT)\n",
    "print(\"Carpeta AI_Package:\", AI_PACKAGE_DIR)\n",
    "print(\"Carpeta data_raw:\", DATA_RAW_DIR)\n",
    "\n",
    "print(\"\\n¿Existe AI_Package?:\", AI_PACKAGE_DIR.exists())\n",
    "print(\"¿Existe data_raw?:   \", DATA_RAW_DIR.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59dfb5-d716-42cb-9704-5b24046784a4",
   "metadata": {},
   "source": [
    "## 3. Lectura del MANIFEST del proyecto\n",
    "\n",
    "- Se carga `AI_Package/MANIFEST.json` y se inspeccionan las claves principales:\n",
    "  - `scripts`, `data_files`, `context_files`, `keys`.\n",
    "- Se listan los scripts declarados con su ruta relativa dentro de `AI_Package/`.\n",
    "- Se comprueba que todas las rutas de `scripts`, `data_files` y `context_files`\n",
    "  existen realmente bajo `AI_Package/`; si faltara algo, se reportaría en pantalla.\n",
    "- De la sección `keys` se obtienen los nombres estándar de embeddings y vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24211bb5-0e74-4e90-8b9d-d7227df45198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['project_name', 'version', 'keys', 'entrypoints', 'package_role', 'external_dependencies', 'dependencies_min', 'scripts', 'pipelines', 'exclusions', 'context_files', 'data_files', 'expects', 'notes'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest_path = AI_PACKAGE_DIR / \"MANIFEST.json\"\n",
    "\n",
    "if not manifest_path.exists():\n",
    "    raise FileNotFoundError(f\"No se encuentra MANIFEST.json en {manifest_path}\")\n",
    "\n",
    "with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "# Mostramos las claves de primer nivel para hacernos una idea de la estructura\n",
    "manifest.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30f57d2d-8312-477f-aa4a-ef9cddfa2bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Secciones principales del MANIFEST ===\n",
      "- scripts: dict (12 entradas)\n",
      "- data_files: dict (4 entradas)\n",
      "- context_files: list (6 elementos)\n",
      "- keys: dict (3 entradas)\n",
      "\n",
      "=== Claves estándar (keys) ===\n",
      "EMB_KEY: X_pca_harmony\n",
      "NBR_KEY: harmony\n",
      "UMAP_KEY: X_umap_harmony\n",
      "\n",
      "=== Scripts declarados ===\n",
      "- build_harmony: scripts/00_harmony_embedding/00_build_harmony_embedding.py\n",
      "- global_clustering: scripts/02_lineages_l1/11_lineages_clustering_min.py\n",
      "- annotate_lineages_l1: scripts/02_lineages_l1/12_lineages_annotation_min.py\n",
      "- split_by_lineage: scripts/02_lineages_l1/13_lineages_split_min.py\n",
      "- per_lineage_qc_umap_leiden: scripts/03_celltypes_l2/21_per_lineage_qc_hvg_umap_leiden_min.py\n",
      "- per_lineage_markers: scripts/03_celltypes_l2/22_per_lineage_markers_min.py\n",
      "- build_main_annotated: scripts/04_main_assembly_plots/31_build_main_annotated_min.py\n",
      "- plots_main_annotation: scripts/04_main_assembly_plots/32_plots_main_annotation_min.py\n",
      "- dotplots: scripts/05_characterization_markers_validation/41_dotplots_min.py\n",
      "- markers_level1: scripts/05_characterization_markers_validation/42_markers_level1_min.py\n",
      "- markers_level2: scripts/05_characterization_markers_validation/43_markers_level2_min.py\n",
      "- compare_external: scripts/05_characterization_markers_validation/44_compare_external_min.py\n"
     ]
    }
   ],
   "source": [
    "# Mostramos secciones importantes del MANIFEST de forma resumida\n",
    "\n",
    "print(\"=== Secciones principales del MANIFEST ===\")\n",
    "for key in [\"scripts\", \"data_files\", \"context_files\", \"keys\"]:\n",
    "    if key in manifest:\n",
    "        value = manifest[key]\n",
    "        if isinstance(value, dict):\n",
    "            type_str = f\"dict ({len(value)} entradas)\"\n",
    "        elif isinstance(value, list):\n",
    "            type_str = f\"list ({len(value)} elementos)\"\n",
    "        else:\n",
    "            type_str = type(value).__name__\n",
    "        print(f\"- {key}: {type_str}\")\n",
    "\n",
    "print(\"\\n=== Claves estándar (keys) ===\")\n",
    "for k, v in manifest.get(\"keys\", {}).items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\n=== Scripts declarados ===\")\n",
    "scripts_section = manifest.get(\"scripts\", {})\n",
    "\n",
    "if isinstance(scripts_section, dict):\n",
    "    # Caso: scripts = { \"nombre_script\": { \"path\": \"...\", ... }, ... }\n",
    "    for name, entry in scripts_section.items():\n",
    "        if isinstance(entry, dict):\n",
    "            path = entry.get(\"path\", \"<sin path>\")\n",
    "            desc = entry.get(\"description\", \"\")\n",
    "        else:\n",
    "            path = str(entry)\n",
    "            desc = \"\"\n",
    "        if desc:\n",
    "            print(f\"- {name}: {path}  ({desc})\")\n",
    "        else:\n",
    "            print(f\"- {name}: {path}\")\n",
    "elif isinstance(scripts_section, list):\n",
    "    # Caso alternativo: scripts = [ { \"name\": \"...\", \"path\": \"...\" }, ... ]\n",
    "    for entry in scripts_section:\n",
    "        if isinstance(entry, dict):\n",
    "            name = entry.get(\"name\", \"<sin nombre>\")\n",
    "            path = entry.get(\"path\", \"<sin path>\")\n",
    "            desc = entry.get(\"description\", \"\")\n",
    "            if desc:\n",
    "                print(f\"- {name}: {path}  ({desc})\")\n",
    "            else:\n",
    "                print(f\"- {name}: {path}\")\n",
    "        else:\n",
    "            print(f\"- <entrada no dict>: {entry}\")\n",
    "else:\n",
    "    print(f\"[AVISO] Formato inesperado para 'scripts': {type(scripts_section).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39b7d70-4b63-46e2-9dd7-0af6f9f0de6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rutas declaradas en MANIFEST y no encontradas en AI_Package/:\n",
      "- Ninguna: todo lo declarado está presente.\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos qué archivos declarados en el MANIFEST existen realmente en AI_Package/\n",
    "missing_paths = []\n",
    "\n",
    "def _check_relative_path(rel_path: str):\n",
    "    path = AI_PACKAGE_DIR / rel_path\n",
    "    if not path.exists():\n",
    "        missing_paths.append(rel_path)\n",
    "\n",
    "def _scan_section_entries(section_name: str):\n",
    "    \"\"\"\n",
    "    Dado un nombre de sección del MANIFEST ('scripts', 'data_files', 'context_files'),\n",
    "    extrae todos los paths relativos que aparezcan ahí y los pasa a _check_relative_path.\n",
    "    Soporta formatos:\n",
    "      - dict: {name: { \"path\": \"...\" }} o {name: \"ruta\"}\n",
    "      - list: [\"ruta1\", \"ruta2\"] o [ { \"path\": \"...\" }, ... ]\n",
    "      - str: camino directo\n",
    "    \"\"\"\n",
    "    entries = manifest.get(section_name, {})\n",
    "\n",
    "    # Caso dict\n",
    "    if isinstance(entries, dict):\n",
    "        for name, entry in entries.items():\n",
    "            if isinstance(entry, dict):\n",
    "                rel = entry.get(\"path\")\n",
    "                if rel:\n",
    "                    _check_relative_path(rel)\n",
    "            elif isinstance(entry, str):\n",
    "                _check_relative_path(entry)\n",
    "\n",
    "    # Caso lista\n",
    "    elif isinstance(entries, list):\n",
    "        for entry in entries:\n",
    "            if isinstance(entry, dict):\n",
    "                rel = entry.get(\"path\")\n",
    "                if rel:\n",
    "                    _check_relative_path(rel)\n",
    "            elif isinstance(entry, str):\n",
    "                _check_relative_path(entry)\n",
    "\n",
    "    # Caso string directo\n",
    "    elif isinstance(entries, str):\n",
    "        _check_relative_path(entries)\n",
    "\n",
    "    else:\n",
    "        print(f\"[AVISO] Formato inesperado para sección '{section_name}': {type(entries).__name__}\")\n",
    "\n",
    "# Revisamos scripts, data_files y context_files\n",
    "for section in [\"scripts\", \"data_files\", \"context_files\"]:\n",
    "    _scan_section_entries(section)\n",
    "\n",
    "print(\"Rutas declaradas en MANIFEST y no encontradas en AI_Package/:\")\n",
    "if not missing_paths:\n",
    "    print(\"- Ninguna: todo lo declarado está presente.\")\n",
    "else:\n",
    "    for rel in missing_paths:\n",
    "        print(f\"- {rel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9605da0-8cc7-4fef-bcc0-1b1534d2c8a1",
   "metadata": {},
   "source": [
    "## 4. Configuración del archivo de datos principal (`.h5ad`)\n",
    "\n",
    "- Se define la ruta esperada del archivo principal:\n",
    "  - `RAW_H5AD_PATH = DATA_RAW_DIR / \"TFM_CIRRHOSIS_merged.h5ad\"`.\n",
    "- Se imprime la ruta y se comprueba si el archivo existe.\n",
    "- Aquí solo se fija la ruta; la lectura del objeto se hace más adelante en el notebook.\n",
    "- No se aplica ningún preprocesamiento en este punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52239cef-4e52-4c77-b572-f9b8c77f20cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo esperado .h5ad principal:\n",
      "D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\data_raw\\TFM_CIRRHOSIS_merged.h5ad\n",
      "¿Existe?: True\n"
     ]
    }
   ],
   "source": [
    "# Ruta esperada del archivo principal .h5ad\n",
    "# Modifica esto si tu archivo está en otra localización o tiene otro nombre.\n",
    "RAW_H5AD_PATH = DATA_RAW_DIR / \"TFM_CIRRHOSIS_merged.h5ad\"\n",
    "\n",
    "print(\"Archivo esperado .h5ad principal:\")\n",
    "print(RAW_H5AD_PATH)\n",
    "print(\"¿Existe?:\", RAW_H5AD_PATH.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e80ae50-7fc2-4daa-b045-3787fde2e76f",
   "metadata": {},
   "source": [
    "(En este notebook no cargamos aún el .h5ad para no consumir memoria de forma innecesaria.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c906c-6bfb-4980-bc85-37b9e4d8931c",
   "metadata": {},
   "source": [
    "## 5. Constantes de configuración para el pipeline\n",
    "\n",
    "- Se crea un diccionario `CONFIG` con:\n",
    "  - Rutas básicas: `PROJECT_ROOT`, `AI_PACKAGE_DIR`, `DATA_RAW_DIR`, `RAW_H5AD_PATH`.\n",
    "  - Claves estándar tomadas de `MANIFEST.json` (con valores por defecto si faltan):\n",
    "    - `EMB_KEY` (embedding Harmony, p.ej. `\"X_pca_harmony\"`).\n",
    "    - `NBR_KEY` (grafo de vecinos, p.ej. `\"harmony\"`).\n",
    "    - `UMAP_KEY` (UMAP armonizado, p.ej. `\"X_umap_harmony\"`).\n",
    "- Esta celda se puede reutilizar en el resto de notebooks para mantener nombres coherentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40fb622a-c815-4738-bdac-292148ca761a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PROJECT_ROOT': WindowsPath('D:/Users/Coni/Documents/TFM_CirrhosIS'),\n",
       " 'AI_PACKAGE_DIR': WindowsPath('D:/Users/Coni/Documents/TFM_CirrhosIS/AI_Package'),\n",
       " 'DATA_RAW_DIR': WindowsPath('D:/Users/Coni/Documents/TFM_CirrhosIS/data_raw'),\n",
       " 'RAW_H5AD_PATH': WindowsPath('D:/Users/Coni/Documents/TFM_CirrhosIS/data_raw/TFM_CIRRHOSIS_merged.h5ad'),\n",
       " 'EMB_KEY': 'X_pca_harmony',\n",
       " 'NBR_KEY': 'harmony',\n",
       " 'UMAP_KEY': 'X_umap_harmony'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    \"PROJECT_ROOT\": PROJECT_ROOT,\n",
    "    \"AI_PACKAGE_DIR\": AI_PACKAGE_DIR,\n",
    "    \"DATA_RAW_DIR\": DATA_RAW_DIR,\n",
    "    \"RAW_H5AD_PATH\": RAW_H5AD_PATH,\n",
    "    # Claves estándar tal y como figuran en MANIFEST.json\n",
    "    \"EMB_KEY\": manifest.get(\"keys\", {}).get(\"EMB_KEY\", \"X_pca_harmony\"),\n",
    "    \"NBR_KEY\": manifest.get(\"keys\", {}).get(\"NBR_KEY\", \"harmony\"),\n",
    "    \"UMAP_KEY\": manifest.get(\"keys\", {}).get(\"UMAP_KEY\", \"X_umap_harmony\"),\n",
    "}\n",
    "\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce16a9ac-5b82-4cbb-ab9f-19eea7dfa851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo objeto bruto desde: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\data_raw\\TFM_CIRRHOSIS_merged.h5ad\n",
      "AnnData object with n_obs × n_vars = 231953 × 38606 backed at 'D:\\\\Users\\\\Coni\\\\Documents\\\\TFM_CirrhosIS\\\\data_raw\\\\TFM_CIRRHOSIS_merged.h5ad'\n",
      "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'gem_id', 'patientID', 'age', 'sex', 'diagnostic', 'disease', 'disease_classification', 'disease_status', 'disease_grade', 'alternative_classification', 'comorbidity', 'sample_collection', 'scrublet_doublet_scores', 'scrublet_predicted_doublet'\n",
      "    var: 'features'\n",
      "\n",
      "Columnas en adata_raw.obs:\n",
      "['orig.ident', 'nCount_RNA', 'nFeature_RNA', 'gem_id', 'patientID', 'age', 'sex', 'diagnostic', 'disease', 'disease_classification', 'disease_status', 'disease_grade', 'alternative_classification', 'comorbidity', 'sample_collection', 'scrublet_doublet_scores', 'scrublet_predicted_doublet']\n",
      "\n",
      "Columnas en adata_raw.var:\n",
      "['features']\n",
      "\n",
      "Resumen de posibles columnas de muestra:\n",
      "\n",
      "Distribución de gem_id:\n",
      "gem_id\n",
      "ee31rg5x_hsm6kstq    40319\n",
      "eoogcieu_var4q976    39263\n",
      "w1oxhhll_d4comu1j    38172\n",
      "hner8v5o_m8skafb5    36220\n",
      "glol8w2k_5hkzluhi    23971\n",
      "pizamr6y_jgzygjwf    21548\n",
      "ul6ge419_oxt3y11v    19743\n",
      "kbdmjydj_hyfxxft5    12717\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Resumen de posibles columnas de condición:\n",
      "\n",
      "Distribución de disease:\n",
      "disease\n",
      "Cirrhosis    153974\n",
      "Healthy       77979\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el objeto bruto en modo \"backed\" (lectura en disco, sin cargar toda la matriz en RAM)\n",
    "raw_path = CONFIG[\"RAW_H5AD_PATH\"]\n",
    "print(\"Leyendo objeto bruto desde:\", raw_path)\n",
    "\n",
    "adata_raw = sc.read_h5ad(raw_path, backed=\"r\")\n",
    "print(adata_raw)\n",
    "\n",
    "# Resumen de columnas en obs y var\n",
    "print(\"\\nColumnas en adata_raw.obs:\")\n",
    "print(list(adata_raw.obs.columns))\n",
    "\n",
    "print(\"\\nColumnas en adata_raw.var:\")\n",
    "print(list(adata_raw.var.columns))\n",
    "\n",
    "# Algunos metadatos básicos si existen\n",
    "# Incluimos 'gem_id' porque en el pipeline se usa como batch técnico principal\n",
    "candidate_sample_cols = [\"sample\", \"sample_id\", \"libraryID\", \"gem_id\", \"batch\"]\n",
    "candidate_condition_cols = [\"disease\", \"condition\", \"group\", \"status\"]\n",
    "\n",
    "print(\"\\nResumen de posibles columnas de muestra:\")\n",
    "for col in candidate_sample_cols:\n",
    "    if col in adata_raw.obs.columns:\n",
    "        print(f\"\\nDistribución de {col}:\")\n",
    "        print(adata_raw.obs[col].value_counts())\n",
    "\n",
    "print(\"\\nResumen de posibles columnas de condición:\")\n",
    "for col in candidate_condition_cols:\n",
    "    if col in adata_raw.obs.columns:\n",
    "        print(f\"\\nDistribución de {col}:\")\n",
    "        print(adata_raw.obs[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0b7cc6-2e09-49d3-acb2-b5fcb0d3a3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 10 var_names (índice de adata_raw.var):\n",
      "['DDX11L2', 'MIR1302-2HG', 'FAM138A', 'ENSG00000290826', 'OR4F5', 'ENSG00000238009', 'ENSG00000239945', 'ENSG00000239906', 'ENSG00000241860', 'ENSG00000241599']\n",
      "\n",
      "Primeros 10 valores de var['features']:\n",
      "['DDX11L2', 'MIR1302-2HG', 'FAM138A', 'ENSG00000290826', 'OR4F5', 'ENSG00000238009', 'ENSG00000239945', 'ENSG00000239906', 'ENSG00000241860', 'ENSG00000241599']\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionamos cómo están guardados los genes\n",
    "print(\"Primeros 10 var_names (índice de adata_raw.var):\")\n",
    "print(list(adata_raw.var_names[:10]))\n",
    "\n",
    "if \"features\" in adata_raw.var.columns:\n",
    "    print(\"\\nPrimeros 10 valores de var['features']:\")\n",
    "    print(list(adata_raw.var[\"features\"][:10]))\n",
    "else:\n",
    "    print(\"\\nNo existe la columna 'features' en adata_raw.var.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657064f8-97ab-47a8-966e-4d9c463c1483",
   "metadata": {},
   "source": [
    "Dejamos el notebook 01 ya con una mini descripción del dataset para la memoria.\n",
    "\n",
    "Esto no modifica datos, solo describe; deja el notebook 01 como una ficha técnica del .h5ad de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efa7ef0b-8699-4779-a0af-9d678cbf1d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de pacientes únicos: 16\n",
      "\n",
      "Distribución de patientID (top 10):\n",
      "patientID\n",
      "CNAG_118    38172\n",
      "CNAG_117    36220\n",
      "CNAG_121    19747\n",
      "CNAG_123    12832\n",
      "IJC_01      12803\n",
      "CNAG_143    12565\n",
      "CNAG_126    12202\n",
      "IJC_03      12115\n",
      "CNAG_124    11398\n",
      "CNAG_125    10838\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribución de scrublet_predicted_doublet:\n",
      "scrublet_predicted_doublet\n",
      "False    149621\n",
      "NA        74392\n",
      "True       7940\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Nota: aquí SOLO resumimos scrublet_predicted_doublet, no filtramos por doublets.\n",
    "# Resumen de pacientes\n",
    "if \"patientID\" in adata_raw.obs.columns:\n",
    "    print(\"Número de pacientes únicos:\", adata_raw.obs[\"patientID\"].nunique())\n",
    "    print(\"\\nDistribución de patientID (top 10):\")\n",
    "    print(adata_raw.obs[\"patientID\"].value_counts().head(10))\n",
    "\n",
    "# Resumen de scrublet\n",
    "if \"scrublet_predicted_doublet\" in adata_raw.obs.columns:\n",
    "    print(\"\\nDistribución de scrublet_predicted_doublet:\")\n",
    "    print(adata_raw.obs[\"scrublet_predicted_doublet\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ce008-2d01-4e6d-a25b-c969243fcd8f",
   "metadata": {},
   "source": [
    "## 5. Resumen del objeto de entrada (`TFM_CIRRHOSIS_merged.h5ad`)\n",
    "\n",
    "- Se carga el archivo con `sc.read_h5ad(..., backed=\"r\")`:\n",
    "  - ~231 953 células × 38 606 genes (lectura en disco, sin cargar toda la matriz en RAM).\n",
    "- Metadatos celulares (`adata_raw.obs`, ejemplos):\n",
    "  - Calidad / técnica: `orig.ident`, `nCount_RNA`, `nFeature_RNA`, `gem_id`.\n",
    "  - Clínicos: `patientID`, `age`, `sex`, `diagnostic`, `disease`,\n",
    "    `disease_classification`, `disease_status`, `disease_grade`,\n",
    "    `alternative_classification`, `comorbidity`, `sample_collection`.\n",
    "  - Scrublet: `scrublet_doublet_scores`, `scrublet_predicted_doublet`.\n",
    "- Metadatos de genes (`adata_raw.var`):\n",
    "  - Columna `features`; los primeros valores coinciden con `var_names`\n",
    "    y se usan como nombres de genes.\n",
    "- Resúmenes básicos:\n",
    "  - Pacientes: 16 `patientID` con números de células desiguales.\n",
    "  - `disease`:\n",
    "    - Cirrhosis: 153 974 células.\n",
    "    - Healthy: 77 979 células.\n",
    "  - `scrublet_predicted_doublet`:\n",
    "    - True: 7 940 células.\n",
    "    - False: 149 621 células.\n",
    "    - NA: 74 392 células.\n",
    "- En este notebook solo se describen estos campos; **no se filtran doublets ni se modifican los datos**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f09919-d07d-4663-874d-a40efd4b2d10",
   "metadata": {},
   "source": [
    "## 6. Resumen de este notebook\n",
    "\n",
    "- Define la estructura de carpetas del proyecto y comprueba la existencia de `AI_Package/` y `data_raw/`.\n",
    "- Lee `MANIFEST.json`, lista sus secciones principales y valida las rutas de scripts y datos.\n",
    "- Construye `CONFIG` con rutas y claves estándar (`EMB_KEY`, `NBR_KEY`, `UMAP_KEY`).\n",
    "- Localiza y carga `TFM_CIRRHOSIS_merged.h5ad` en modo `backed=\"r\"` y resume:\n",
    "  dimensiones, metadatos clave, pacientes, condición clínica y Scrublet.\n",
    "- Deja documentado el objeto de entrada y el “contrato” técnico del pipeline,\n",
    "  sin aplicar todavía QC, normalización ni anotaciones biológicas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

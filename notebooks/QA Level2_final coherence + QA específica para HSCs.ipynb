{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e834c03-f317-40be-aeb0-0021c99350f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\n",
      "OUT_FILTER : D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\data_processed\\TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\n",
      "MAP_PATH   : D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\summary_tables_final\\Level2_final_map.json\n",
      "EMB_PATH   : D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\summary_tables_final\\UMAP_Harmony_embeddings.csv\n",
      "[OK] Usando grafo: obsp['harmony_connectivities'] -> (220637, 220637)\n",
      "K (n_neighbors): 15\n",
      "\n",
      "Saved: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\summary_tables_final\\QA_Level2final_neighbor_purity.csv\n",
      "Level2_final  n_cells  mean_sameLabel_inNeighbors  median_sameLabel_inNeighbors  p25_sameLabel_inNeighbors  p75_sameLabel_inNeighbors  na_cells\n",
      "     B_Other      799                    0.635924                      0.785714                   0.266667                   1.000000         0\n",
      " B_Activated      598                    0.664103                      0.857143                   0.400000                   0.933333         0\n",
      "        MAIT     1576                    0.695265                      0.800000                   0.466667                   1.000000         0\n",
      "        cDC1      135                    0.720000                      0.933333                   0.533333                   1.000000         0\n",
      "  B_Atypical     1125                    0.739374                      0.866667                   0.533333                   1.000000         0\n",
      " ISG_Myeloid     4246                    0.789578                      0.933333                   0.666667                   1.000000         0\n",
      "  CD4_Memory    23832                    0.804531                      0.928571                   0.714286                   1.000000         0\n",
      "        cDC2     2800                    0.808802                      0.933333                   0.733333                   1.000000         0\n",
      "        Treg     4645                    0.809532                      0.933333                   0.714286                   1.000000         0\n",
      "         DC4     1215                    0.811624                      0.933333                   0.690476                   1.000000         0\n",
      "\n",
      "Saved: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\summary_tables_final\\QA_HSCs_neighbor_label_distribution.csv\n",
      "neighbor_label  n_edges    share\n",
      "          HSCs      567 0.994737\n",
      "    CD4_Memory        3 0.005263\n",
      "\n",
      "Saved: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\summary_tables_final\\QA_Level2final_umap_compactness.csv\n",
      "          Level2_final  n_cells  mean_radius  median_radius  p75_radius  p95_radius\n",
      "          MonoDC_Other   8651.0     4.075723       3.219381    4.751400   12.048849\n",
      "                   DC3    543.0     3.910583       2.428608    3.168129   11.201792\n",
      "            CD4_Memory  23832.0     2.900487       2.700479    3.552628    5.648170\n",
      "     NonClassical_Mono  16942.0     2.401670       2.130991    2.991544    5.817944\n",
      "        Classical_Mono  54370.0     2.397828       2.396562    3.158471    4.011191\n",
      "           ISG_Myeloid   4246.0     2.337853       2.269493    2.994565    4.248924\n",
      "                    NK  25529.0     2.267279       2.070651    2.910305    4.589509\n",
      "             CD4_Naive  36685.0     2.174006       2.132204    2.804948    3.829305\n",
      "                  Treg   4645.0     1.833858       1.588765    2.280190    4.233866\n",
      "CD8_Effector_Cytotoxic  16229.0     1.763998       1.436001    2.106871    4.383045\n",
      "\n",
      "HSC panel: símbolos encontrados = 14 / 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Coni\\AppData\\Local\\Temp\\ipykernel_13932\\26730910.py:210: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_comp = emb.groupby(\"Level2_final\", sort=False).apply(compactness).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: D:\\Users\\Coni\\Documents\\TFM_CirrhosIS\\summary_tables_final\\QA_HSCs_marker_panel_vs_rest.csv\n",
      "marker  mean_log1p_HSCs  frac_nonzero_HSCs  mean_log1p_rest  frac_nonzero_rest  delta_mean  delta_frac\n",
      "TMSB10         2.364775           0.974359         3.300970           0.965594   -0.936195    0.008765\n",
      " HMGB2         0.181501           0.307692         0.488691           0.425580   -0.307190   -0.117887\n",
      "  HOPX         0.124490           0.128205         0.227922           0.145495   -0.103432   -0.017290\n",
      "  SOX4         0.094076           0.102564         0.118649           0.120835   -0.024573   -0.018271\n",
      "  TYMP         0.075565           0.102564         0.224821           0.222300   -0.149256   -0.119736\n",
      "   KIT         0.071109           0.051282         0.003657           0.003622    0.067453    0.047660\n",
      "  TAL1         0.059300           0.076923         0.000529           0.000598    0.058770    0.076325\n",
      " GATA2         0.012471           0.025641         0.000729           0.000553    0.011742    0.025088\n",
      "  LMO2         0.008582           0.025641         0.140808           0.157649   -0.132226   -0.132008\n",
      "  CD34         0.000000           0.000000         0.000563           0.000617   -0.000563   -0.000617\n",
      "\n",
      "[RECOMENDACIÓN] Marcadores HSCs (top2 por score=mean*frac): ['TMSB10', 'HMGB2']\n",
      "\n",
      "[OK] QA coherence + HSCs listo.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# QA Level2_final coherence + QA específica para HSCs\n",
    "# Salidas (summary_tables_final/):\n",
    "#  1) QA_Level2final_neighbor_purity.csv\n",
    "#  2) QA_HSCs_neighbor_label_distribution.csv\n",
    "#  3) QA_Level2final_umap_compactness.csv\n",
    "#  4) QA_HSCs_marker_panel_vs_rest.csv   (+ recomendación automática de 2 marcadores)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encuentro 'data_processed' subiendo desde: {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "OUT_SUM = PROJECT_ROOT / \"summary_tables_final\"\n",
    "OUT_SUM.mkdir(exist_ok=True)\n",
    "\n",
    "OUT_FILTER = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "MAP_PATH = OUT_SUM / \"Level2_final_map.json\"\n",
    "EMB_PATH = OUT_SUM / \"UMAP_Harmony_embeddings.csv\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"OUT_FILTER :\", OUT_FILTER)\n",
    "print(\"MAP_PATH   :\", MAP_PATH)\n",
    "print(\"EMB_PATH   :\", EMB_PATH)\n",
    "\n",
    "if not OUT_FILTER.exists():\n",
    "    raise FileNotFoundError(f\"No existe OUT_FILTER: {OUT_FILTER}\")\n",
    "if not MAP_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe Level2_final_map.json: {MAP_PATH}\")\n",
    "if not EMB_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe UMAP_Harmony_embeddings.csv: {EMB_PATH}\")\n",
    "\n",
    "with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    level2_map = json.load(f)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Coherencia Level2_final vía pureza de vecinos (grafo Harmony)\n",
    "# -----------------------------\n",
    "adata_b = sc.read_h5ad(OUT_FILTER, backed=\"r\")\n",
    "\n",
    "need = [\"patientID\", \"disease\", \"Level1_refined\", \"Level2\"]\n",
    "missing = [c for c in need if c not in adata_b.obs.columns]\n",
    "if missing:\n",
    "    adata_b.file.close()\n",
    "    raise KeyError(f\"Faltan columnas obs: {missing}\")\n",
    "\n",
    "obs = adata_b.obs[need].copy()\n",
    "\n",
    "# IMPORTANT: NO convertir Level2 a str antes de mapear (para no convertir NaN -> \"nan\")\n",
    "l2_obj = obs[\"Level2\"].astype(\"object\")\n",
    "obs[\"Level2_final\"] = l2_obj.replace(level2_map)\n",
    "obs[\"Level2_final\"] = obs[\"Level2_final\"].astype(\"object\")\n",
    "\n",
    "# Elegir conectividades: preferir harmony_connectivities si existe\n",
    "if \"harmony_connectivities\" in adata_b.obsp.keys():\n",
    "    C = adata_b.obsp[\"harmony_connectivities\"]\n",
    "    graph_name = \"harmony_connectivities\"\n",
    "elif \"connectivities\" in adata_b.obsp.keys():\n",
    "    C = adata_b.obsp[\"connectivities\"]\n",
    "    graph_name = \"connectivities\"\n",
    "else:\n",
    "    adata_b.file.close()\n",
    "    raise KeyError(\"No encuentro connectivities ni harmony_connectivities en obsp.\")\n",
    "\n",
    "print(f\"[OK] Usando grafo: obsp['{graph_name}'] -> {C.shape}\")\n",
    "\n",
    "# K: si está disponible en uns['neighbors'], usarlo; si no, fallback a 15\n",
    "K = 15\n",
    "try:\n",
    "    K = int(adata_b.uns.get(\"neighbors\", {}).get(\"params\", {}).get(\"n_neighbors\", 15))\n",
    "except Exception:\n",
    "    K = 15\n",
    "print(\"K (n_neighbors):\", K)\n",
    "\n",
    "def topk_neighbors_from_connectivities(C, k=15):\n",
    "    if not sp.issparse(C):\n",
    "        C = sp.csr_matrix(C)\n",
    "    C = C.tocsr()\n",
    "    n = C.shape[0]\n",
    "    neigh_idx = []\n",
    "\n",
    "    for i in range(n):\n",
    "        start, end = C.indptr[i], C.indptr[i + 1]\n",
    "        cols = C.indices[start:end]\n",
    "        data = C.data[start:end]\n",
    "\n",
    "        # quitar self\n",
    "        m = cols != i\n",
    "        cols = cols[m]\n",
    "        data = data[m]\n",
    "\n",
    "        if cols.size == 0:\n",
    "            neigh_idx.append(np.array([], dtype=int))\n",
    "            continue\n",
    "\n",
    "        # limitar a top-k por peso\n",
    "        if cols.size > k:\n",
    "            sel = np.argpartition(-data, k - 1)[:k]\n",
    "            cols = cols[sel]\n",
    "            data = data[sel]\n",
    "            ord2 = np.argsort(-data)\n",
    "            cols = cols[ord2]\n",
    "\n",
    "        neigh_idx.append(cols.astype(int))\n",
    "\n",
    "    return neigh_idx\n",
    "\n",
    "neigh_idx = topk_neighbors_from_connectivities(C, k=K)\n",
    "\n",
    "labels = obs[\"Level2_final\"].astype(str).to_numpy()\n",
    "all_levels = pd.Index(sorted(pd.unique(labels)))\n",
    "\n",
    "# per-cell same-label fraction\n",
    "same_frac = np.full(labels.shape[0], np.nan, dtype=float)\n",
    "for i in range(labels.shape[0]):\n",
    "    nb = neigh_idx[i]\n",
    "    if nb.size == 0:\n",
    "        continue\n",
    "    same_frac[i] = np.mean(labels[nb] == labels[i])\n",
    "\n",
    "df_purity = []\n",
    "for lvl in all_levels:\n",
    "    m = labels == lvl\n",
    "    v = same_frac[m]\n",
    "    df_purity.append({\n",
    "        \"Level2_final\": lvl,\n",
    "        \"n_cells\": int(m.sum()),\n",
    "        \"mean_sameLabel_inNeighbors\": float(np.nanmean(v)),\n",
    "        \"median_sameLabel_inNeighbors\": float(np.nanmedian(v)),\n",
    "        \"p25_sameLabel_inNeighbors\": float(np.nanpercentile(v, 25)),\n",
    "        \"p75_sameLabel_inNeighbors\": float(np.nanpercentile(v, 75)),\n",
    "        \"na_cells\": int(np.isnan(v).sum()),\n",
    "    })\n",
    "\n",
    "df_purity = pd.DataFrame(df_purity).sort_values(\n",
    "    [\"mean_sameLabel_inNeighbors\", \"n_cells\"], ascending=[True, False]\n",
    ")\n",
    "\n",
    "purity_path = OUT_SUM / \"QA_Level2final_neighbor_purity.csv\"\n",
    "df_purity.to_csv(purity_path, index=False)\n",
    "print(\"\\nSaved:\", purity_path)\n",
    "print(df_purity.head(10).to_string(index=False))\n",
    "\n",
    "# distribución de etiquetas vecinas para HSCs (¿con quién se “pega”?)\n",
    "hsc_mask = labels == \"HSCs\"\n",
    "if int(hsc_mask.sum()) > 0:\n",
    "    counts = {}\n",
    "    idx_hsc = np.where(hsc_mask)[0]\n",
    "    for i in idx_hsc:\n",
    "        for j in neigh_idx[i]:\n",
    "            lab = labels[j]\n",
    "            counts[lab] = counts.get(lab, 0) + 1\n",
    "\n",
    "    df_hsc_nb = (\n",
    "        pd.DataFrame({\"neighbor_label\": list(counts.keys()), \"n_edges\": list(counts.values())})\n",
    "          .sort_values(\"n_edges\", ascending=False)\n",
    "    )\n",
    "    df_hsc_nb[\"share\"] = df_hsc_nb[\"n_edges\"] / df_hsc_nb[\"n_edges\"].sum()\n",
    "\n",
    "    hsc_nb_path = OUT_SUM / \"QA_HSCs_neighbor_label_distribution.csv\"\n",
    "    df_hsc_nb.to_csv(hsc_nb_path, index=False)\n",
    "    print(\"\\nSaved:\", hsc_nb_path)\n",
    "    print(df_hsc_nb.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n[WARN] No hay HSCs en Level2_final (n=0). Se omite QA_HSCs_neighbor_label_distribution.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Compactación en UMAP (sin colores): radio medio a centroide\n",
    "# -----------------------------\n",
    "# Si por cualquier razón el CSV no tuviera Level2_final, lo reconstruimos\n",
    "emb_cols = pd.read_csv(EMB_PATH, nrows=1).columns.tolist()\n",
    "usecols = [\"UMAP1_harmony\", \"UMAP2_harmony\"]\n",
    "if \"Level2_final\" in emb_cols:\n",
    "    usecols = [\"Level2_final\"] + usecols\n",
    "elif \"Level2\" in emb_cols:\n",
    "    usecols = [\"Level2\"] + usecols\n",
    "else:\n",
    "    raise KeyError(\"UMAP_Harmony_embeddings.csv no contiene ni Level2_final ni Level2.\")\n",
    "\n",
    "emb = pd.read_csv(EMB_PATH, usecols=usecols)\n",
    "\n",
    "if \"Level2_final\" not in emb.columns:\n",
    "    emb[\"Level2_final\"] = emb[\"Level2\"].astype(\"object\").replace(level2_map).astype(str)\n",
    "\n",
    "def compactness(df):\n",
    "    x = df[[\"UMAP1_harmony\", \"UMAP2_harmony\"]].to_numpy(float)\n",
    "    c = x.mean(axis=0)\n",
    "    d = np.sqrt(((x - c) ** 2).sum(axis=1))\n",
    "    return pd.Series({\n",
    "        \"n_cells\": int(x.shape[0]),\n",
    "        \"mean_radius\": float(d.mean()),\n",
    "        \"median_radius\": float(np.median(d)),\n",
    "        \"p75_radius\": float(np.percentile(d, 75)),\n",
    "        \"p95_radius\": float(np.percentile(d, 95)),\n",
    "    })\n",
    "\n",
    "df_comp = emb.groupby(\"Level2_final\", sort=False).apply(compactness).reset_index()\n",
    "comp_path = OUT_SUM / \"QA_Level2final_umap_compactness.csv\"\n",
    "df_comp.to_csv(comp_path, index=False)\n",
    "print(\"\\nSaved:\", comp_path)\n",
    "print(df_comp.sort_values(\"mean_radius\", ascending=False).head(10).to_string(index=False))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Panel numérico para HSCs: marcadores alternativos vs resto\n",
    "#    (y recomendación automática de 2 genes para sustituir CD34/KIT si salen mal)\n",
    "# -----------------------------\n",
    "if int(hsc_mask.sum()) == 0:\n",
    "    print(\"\\n[WARN] No hay HSCs -> se omite panel de marcadores HSCs.\")\n",
    "    adata_b.file.close()\n",
    "    raise SystemExit(0)\n",
    "\n",
    "CANDIDATES = [\n",
    "    \"CD34\",\"KIT\",\n",
    "    \"SOX4\",\"SPINK2\",\"AVP\",\n",
    "    \"GATA2\",\"LMO2\",\"TAL1\",\"MEIS1\",\"MPL\",\"HOPX\",\n",
    "    \"HMGB2\",\"TMSB10\",\"TYMP\"\n",
    "]\n",
    "\n",
    "def symbol_to_varname(adata, symbol):\n",
    "    if symbol in adata.var_names:\n",
    "        return symbol\n",
    "    if \"symbol\" in adata.var.columns:\n",
    "        sym = adata.var[\"symbol\"].astype(str).to_numpy()\n",
    "        hits = np.where(sym == symbol)[0]\n",
    "        if hits.size > 0:\n",
    "            return adata.var_names[hits[0]]\n",
    "    return None\n",
    "\n",
    "varnames = []\n",
    "sym_kept = []\n",
    "for s in CANDIDATES:\n",
    "    v = symbol_to_varname(adata_b, s)\n",
    "    if v is not None:\n",
    "        varnames.append(v)\n",
    "        sym_kept.append(s)\n",
    "\n",
    "print(\"\\nHSC panel: símbolos encontrados =\", len(sym_kept), \"/\", len(CANDIDATES))\n",
    "if len(sym_kept) == 0:\n",
    "    adata_b.file.close()\n",
    "    raise RuntimeError(\"No encontré ninguno de los genes candidatos en var_names/var['symbol'].\")\n",
    "\n",
    "adata_small = adata_b[:, varnames].to_memory()\n",
    "adata_b.file.close()\n",
    "\n",
    "# elegir matriz a usar\n",
    "X = adata_small.layers[\"log1p_10k\"] if \"log1p_10k\" in adata_small.layers.keys() else adata_small.X\n",
    "if not sp.issparse(X):\n",
    "    X = sp.csr_matrix(X)\n",
    "X = X.tocsr()\n",
    "\n",
    "mask_hsc = (labels == \"HSCs\")\n",
    "mask_rest = ~mask_hsc\n",
    "\n",
    "def mean_and_frac(Xsub):\n",
    "    mean = np.asarray(Xsub.mean(axis=0)).ravel()\n",
    "    frac = np.asarray((Xsub > 0).mean(axis=0)).ravel()\n",
    "    return mean, frac\n",
    "\n",
    "mean_h, frac_h = mean_and_frac(X[mask_hsc])\n",
    "mean_r, frac_r = mean_and_frac(X[mask_rest])\n",
    "\n",
    "df_hsc_panel = pd.DataFrame({\n",
    "    \"marker\": sym_kept,\n",
    "    \"mean_log1p_HSCs\": mean_h,\n",
    "    \"frac_nonzero_HSCs\": frac_h,\n",
    "    \"mean_log1p_rest\": mean_r,\n",
    "    \"frac_nonzero_rest\": frac_r,\n",
    "})\n",
    "df_hsc_panel[\"delta_mean\"] = df_hsc_panel[\"mean_log1p_HSCs\"] - df_hsc_panel[\"mean_log1p_rest\"]\n",
    "df_hsc_panel[\"delta_frac\"] = df_hsc_panel[\"frac_nonzero_HSCs\"] - df_hsc_panel[\"frac_nonzero_rest\"]\n",
    "\n",
    "panel_path = OUT_SUM / \"QA_HSCs_marker_panel_vs_rest.csv\"\n",
    "df_hsc_panel.sort_values([\"mean_log1p_HSCs\", \"frac_nonzero_HSCs\"], ascending=False).to_csv(panel_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\", panel_path)\n",
    "print(df_hsc_panel.sort_values([\"mean_log1p_HSCs\",\"frac_nonzero_HSCs\"], ascending=False).head(10).to_string(index=False))\n",
    "\n",
    "# recomendación automática: top2 por \"señal\" dentro de HSCs (media * frac)\n",
    "df_hsc_panel[\"score\"] = df_hsc_panel[\"mean_log1p_HSCs\"] * df_hsc_panel[\"frac_nonzero_HSCs\"]\n",
    "top2 = df_hsc_panel.sort_values(\"score\", ascending=False).head(2)[\"marker\"].tolist()\n",
    "print(\"\\n[RECOMENDACIÓN] Marcadores HSCs (top2 por score=mean*frac):\", top2)\n",
    "\n",
    "print(\"\\n[OK] QA coherence + HSCs listo.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfm_scRNA)",
   "language": "python",
   "name": "tfm_scrna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac03fca-0038-4cbc-a347-0de26cd2ad73",
   "metadata": {},
   "source": [
    "### 1. Imports + paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bbb22-3797-4d73-a807-8ce56261ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from src.paths import project_paths\n",
    "\n",
    "print(\"Scanpy:\", sc.__version__)\n",
    "\n",
    "P = project_paths(Path.cwd())\n",
    "PROJECT_ROOT = P[\"PROJECT_ROOT\"]\n",
    "CONFIG_DIR   = P[\"CONFIG_DIR\"]\n",
    "DATA_DIR     = P[\"DATA_DIR\"]\n",
    "RESULTS_DIR  = P[\"RESULTS_DIR\"]\n",
    "FIGURES_DIR  = P[\"FIGURES_DIR\"]\n",
    "\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Outputs\n",
    "FIG_DIR = FIGURES_DIR / \"dotplots\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_SUMMARY = RESULTS_DIR / \"summary_tables\" / \"dotplot_global_level2_final\"\n",
    "OUT_SUMMARY.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CONFIG_DIR  :\", CONFIG_DIR)\n",
    "print(\"DATA_DIR    :\", DATA_DIR)\n",
    "print(\"RESULTS_DIR :\", RESULTS_DIR)\n",
    "print(\"FIG_DIR     :\", FIG_DIR)\n",
    "print(\"OUT_SUMMARY :\", OUT_SUMMARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d33af-c613-41cf-a323-a8cfefc3971c",
   "metadata": {},
   "source": [
    "### 2. Leer config + resolver rutas de input + Level2_final_map.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b29999-2a91-40f9-bb61-9850ed039479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simple_yaml(path: Path) -> dict:\n",
    "    cfg = {}\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\":\", 1)\n",
    "        cfg[k.strip()] = v.strip().strip('\"').strip(\"'\")\n",
    "    return cfg\n",
    "\n",
    "cfg_path = CONFIG_DIR / \"config.yaml\"\n",
    "if not cfg_path.exists():\n",
    "    raise FileNotFoundError(f\"Falta {cfg_path}\")\n",
    "CFG = load_simple_yaml(cfg_path)\n",
    "\n",
    "# Input principal: salida del NB10 (RBC-out)\n",
    "OUT_FILTER_NAME = CFG.get(\"main_filtered_for_analysis_h5ad_filename\", \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\")\n",
    "OUT_FILTER = RESULTS_DIR / OUT_FILTER_NAME\n",
    "\n",
    "# Keys (por si cambian)\n",
    "LEVEL2_KEY = CFG.get(\"level2_key\", \"Level2\")\n",
    "LEVEL1_KEY = CFG.get(\"level1_key\", \"Level1\")\n",
    "LEVEL1_REFINED_KEY = CFG.get(\"level1_refined_key\", \"Level1_refined\")\n",
    "\n",
    "# Layer\n",
    "LAYER = CFG.get(\"analysis_layer\", \"log1p_10k\")\n",
    "\n",
    "print(\"OUT_FILTER        :\", OUT_FILTER)\n",
    "print(\"LEVEL2_KEY        :\", LEVEL2_KEY)\n",
    "print(\"LEVEL1_KEY        :\", LEVEL1_KEY)\n",
    "print(\"LEVEL1_REFINED_KEY:\", LEVEL1_REFINED_KEY)\n",
    "print(\"LAYER             :\", LAYER)\n",
    "\n",
    "if not OUT_FILTER.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"No existe OUT_FILTER:\\n{OUT_FILTER}\\n¿Has ejecutado el notebook de limpieza (NB10) y guardado el objeto filtrado?\"\n",
    "    )\n",
    "\n",
    "# Level2_final_map.json (Conv_T_other -> CD4_Memory), con búsqueda robusta dentro del repo\n",
    "candidate_maps = [\n",
    "    RESULTS_DIR / \"summary_tables\" / \"conv_t_other_cleanup\" / \"Level2_final_map.json\",\n",
    "    RESULTS_DIR / \"summary_tables\" / \"Level2_final_map.json\",\n",
    "    RESULTS_DIR / \"summary_tables\" / \"Conv_T_other_cleanup\" / \"Level2_final_map.json\",\n",
    "]\n",
    "\n",
    "MAP_PATH = None\n",
    "for p in candidate_maps:\n",
    "    if p.exists():\n",
    "        MAP_PATH = p\n",
    "        break\n",
    "\n",
    "if MAP_PATH is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"No encuentro Level2_final_map.json en ubicaciones esperadas dentro de results/summary_tables/.\\n\"\n",
    "        \"Probé:\\n\" + \"\\n\".join([f\"- {x}\" for x in candidate_maps])\n",
    "    )\n",
    "\n",
    "with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    level2_map = json.load(f)\n",
    "\n",
    "print(\"MAP_PATH:\", MAP_PATH)\n",
    "print(\"Level2_final_map.json loaded:\")\n",
    "print(level2_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23041eb-af16-4cc7-a31c-f2b1967b72d9",
   "metadata": {},
   "source": [
    "### 3. Abrir OUT_FILTER en backed + checks mínimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21fdc27-3088-4587-9f69-e0e74543f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_b = sc.read_h5ad(OUT_FILTER, backed=\"r\")\n",
    "print(\"Loaded OUT_FILTER (backed):\", adata_b)\n",
    "\n",
    "# checks mínimos\n",
    "for col in [LEVEL2_KEY, LEVEL1_KEY, LEVEL1_REFINED_KEY]:\n",
    "    if col not in adata_b.obs.columns:\n",
    "        try:\n",
    "            adata_b.file.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "        raise KeyError(f\"Falta columna requerida en obs: '{col}'\")\n",
    "\n",
    "if LAYER not in adata_b.layers.keys():\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise KeyError(f\"No existe layer '{LAYER}' en el objeto. layers={list(adata_b.layers.keys())}\")\n",
    "\n",
    "if \"doublet_like\" in adata_b.obs.columns:\n",
    "    print(\"doublet_like True (debería ser 0):\", int(adata_b.obs[\"doublet_like\"].sum()))\n",
    "\n",
    "# RBC-out sanity (informativo; debería ser 0)\n",
    "rbc_l2  = int((adata_b.obs[LEVEL2_KEY].astype(str) == \"RBC\").sum())\n",
    "rbc_l1  = int((adata_b.obs[LEVEL1_KEY].astype(str) == \"RBC\").sum())\n",
    "rbc_l1r = int((adata_b.obs[LEVEL1_REFINED_KEY].astype(str) == \"RBC\").sum())\n",
    "print(\"RBC counts (Level2/Level1/Level1_refined) deberían ser 0:\", (rbc_l2, rbc_l1, rbc_l1r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3112ff-97a6-4fea-a3a8-17f71b6ae5c4",
   "metadata": {},
   "source": [
    "### 4. Import markers + construir dict Level2 + overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becc4407-5b0c-4a03-9143-2f3e92d38730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import markers as mk\n",
    "\n",
    "geneMarkers_level2 = getattr(mk, \"geneMarkers_level2\", {})\n",
    "if not geneMarkers_level2:\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(\"src/markers.py no expone geneMarkers_level2 (vacío/no definido).\")\n",
    "\n",
    "# base: dict Level2 -> lista genes (agregando sobre linajes)\n",
    "lvl2_to_symbols = {}\n",
    "for _l1, subdict in geneMarkers_level2.items():\n",
    "    if not isinstance(subdict, dict):\n",
    "        continue\n",
    "    for _l2, genes in subdict.items():\n",
    "        if genes:\n",
    "            lvl2_to_symbols[_l2] = list(genes)\n",
    "\n",
    "# overrides mínimos para poblaciones problemáticas / nuevas por Level2_final_map\n",
    "# (SIN RBC)\n",
    "OVERRIDE_2MARKERS = {\n",
    "    \"B_Other\":      [\"MS4A1\", \"CD74\"],\n",
    "    \"CD4_Memory\":   [\"IL7R\", \"CCR7\"],     # <- clave tras Conv_T_other -> CD4_Memory\n",
    "    \"ISG_Myeloid\":  [\"ISG15\", \"IFIT3\"],\n",
    "    \"MonoDC_Other\": [\"LYZ\", \"FCER1G\"],\n",
    "    \"DC3\":          [\"CD1C\", \"S100A8\"],   # <- asegurar DC3\n",
    "    \"DC4\":          [\"FCGR3A\", \"LST1\"],   # <- fallback\n",
    "    \"HSCs\":         [\"CD34\", \"KIT\"],\n",
    "    \"Plasma\":       [\"MZB1\", \"JCHAIN\"],\n",
    "    \"pDC\":          [\"IL3RA\", \"IRF7\"],\n",
    "}\n",
    "\n",
    "for l2, genes2 in OVERRIDE_2MARKERS.items():\n",
    "    if (l2 not in lvl2_to_symbols) or (len([g for g in lvl2_to_symbols.get(l2, []) if g]) < 2):\n",
    "        lvl2_to_symbols[l2] = genes2\n",
    "\n",
    "print(\"Markers dict construido. N Level2 con panel:\", len(lvl2_to_symbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60159bad-e993-45e4-8664-f5b80e6213fc",
   "metadata": {},
   "source": [
    "### 5. Preparar obs + Level2_final + orden por bloques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875406f-5517-470a-9c63-d5cec2de3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = adata_b.obs.copy()\n",
    "\n",
    "obs[\"Level2_final\"] = obs[LEVEL2_KEY].astype(str).replace(level2_map).astype(str)\n",
    "obs[\"Level2_final\"] = pd.Categorical(obs[\"Level2_final\"])\n",
    "\n",
    "print(\"[CHECK] Conv_T_other remaining en Level2_final (debe ser 0):\",\n",
    "      int((obs[\"Level2_final\"].astype(str) == \"Conv_T_other\").sum()))\n",
    "print(\"[CHECK] CD4_Memory count en Level2_final:\",\n",
    "      int((obs[\"Level2_final\"].astype(str) == \"CD4_Memory\").sum()))\n",
    "\n",
    "# Orden por bloques (SIN RBC) usando Level2_final\n",
    "order_by_group = {\n",
    "    \"B\":     [\"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"B_Other\"],\n",
    "    \"Plasma\":[\"Plasma\"],\n",
    "    \"pDC\":   [\"pDC\"],\n",
    "    \"T\":     [\"CD4_Naive\",\"CD4_Memory\",\"CD8_Naive\",\"CD8_Effector_Cytotoxic\",\"Treg\",\"MAIT\",\"GammaDelta_T\",\"Proliferative_T\",\"Exhausted_T\"],\n",
    "    \"NK\":    [\"NK\"],\n",
    "    \"Mono\":  [\"Classical_Mono\",\"NonClassical_Mono\",\"ISG_Myeloid\",\"MonoDC_Other\"],\n",
    "    \"DC\":    [\"cDC1\",\"cDC2\",\"DC3\",\"DC4\",\"aDC\"],  # <- DC3 incluido\n",
    "    \"HSCs\":  [\"HSCs\"],\n",
    "}\n",
    "\n",
    "present_l2 = sorted(set(obs[\"Level2_final\"].astype(str).dropna().unique()))\n",
    "\n",
    "level2_order = []\n",
    "for g, l2_list in order_by_group.items():\n",
    "    for l2 in l2_list:\n",
    "        if l2 in present_l2:\n",
    "            level2_order.append(l2)\n",
    "\n",
    "extras = [x for x in present_l2 if x not in level2_order]\n",
    "level2_order = level2_order + sorted(extras)\n",
    "\n",
    "def group_of_l2(l2: str) -> str:\n",
    "    for g, l2_list in order_by_group.items():\n",
    "        if l2 in l2_list:\n",
    "            return g\n",
    "    return \"Other\"\n",
    "\n",
    "# Label final para plot: \"Grupo | Level2_final\"\n",
    "obs[\"Level2_plot\"] = obs[\"Level2_final\"].astype(str).map(lambda l2: f\"{group_of_l2(l2)} | {l2}\")\n",
    "level2_plot_order = [f\"{group_of_l2(l2)} | {l2}\" for l2 in level2_order]\n",
    "obs[\"Level2_plot\"] = pd.Categorical(obs[\"Level2_plot\"], categories=level2_plot_order, ordered=True)\n",
    "\n",
    "print(\"[CHECK] Level2_final presentes:\", len(present_l2))\n",
    "print(\"[CHECK] Primeros 30:\", present_l2[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04186cb-7473-4515-869d-131dea20e0c2",
   "metadata": {},
   "source": [
    "### 6. Lista final de genes + symbols -> varnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db288a01-fb13-486b-86d4-3f92d380fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista final de genes (2 por Level2_final)\n",
    "gene_symbols = []\n",
    "for l2 in level2_order:\n",
    "    gene_symbols.extend(lvl2_to_symbols.get(l2, [])[:2])\n",
    "\n",
    "# dedup manteniendo orden\n",
    "seen = set()\n",
    "gene_symbols = [g for g in gene_symbols if not (g in seen or seen.add(g))]\n",
    "\n",
    "# mapear symbols->varnames usando helper del repo\n",
    "gene_varnames = mk.symbols_to_varnames(adata_b, gene_symbols)\n",
    "\n",
    "missing = [s for s, v in zip(gene_symbols, gene_varnames) if v is None]\n",
    "gene_varnames = [v for v in gene_varnames if v is not None]\n",
    "\n",
    "print(\"Markers symbols total:\", len(gene_symbols))\n",
    "print(\"Markers genes found :\", len(gene_varnames))\n",
    "if missing:\n",
    "    print(\"[WARN] Símbolos no encontrados (omitidos):\", missing)\n",
    "\n",
    "if len(gene_varnames) == 0:\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(\"No se encontró ningún gen marcador en adata.var_names. Revisa var_names / var['symbol'].\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec19c535-6f7a-4ae6-8742-2e607d8e0e03",
   "metadata": {},
   "source": [
    "### 7. Cargar SOLO esos genes a RAM + dotplot FINAL (figura en figures/dotplots/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dd1b98-9675-434f-9fba-82f0fa303eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar SOLO genes del dotplot a RAM\n",
    "adata_plot = adata_b[:, gene_varnames].to_memory()\n",
    "\n",
    "# cerrar el backed\n",
    "try:\n",
    "    adata_b.file.close()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# añadir Level2_plot al objeto pequeño\n",
    "adata_plot.obs[\"Level2_plot\"] = obs.loc[adata_plot.obs_names, \"Level2_plot\"].values\n",
    "adata_plot.obs[\"Level2_plot\"] = pd.Categorical(\n",
    "    adata_plot.obs[\"Level2_plot\"], categories=level2_plot_order, ordered=True\n",
    ")\n",
    "\n",
    "sc.settings.autoshow = False\n",
    "\n",
    "dp = sc.pl.dotplot(\n",
    "    adata_plot,\n",
    "    var_names=gene_varnames,\n",
    "    groupby=\"Level2_plot\",\n",
    "    layer=LAYER,\n",
    "    use_raw=False,\n",
    "    dendrogram=False,\n",
    "    standard_scale=\"var\",\n",
    "    show=False,\n",
    ")\n",
    "\n",
    "dp = dp.add_totals().style(dot_edge_color=\"black\", dot_edge_lw=0.5)\n",
    "\n",
    "out_png = FIG_DIR / \"Fig1C_Dotplot_Global_Level2_clean_FINAL.png\"\n",
    "dp.savefig(out_png, dpi=300)\n",
    "print(\"Saved:\", out_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a84c9f-d82d-4540-b889-09162160f8fd",
   "metadata": {},
   "source": [
    "### 8. Guardar tablas auxiliares: totales + marcadores usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6265629-8005-458c-af2e-9f47f2d89827",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = (\n",
    "    obs[\"Level2_plot\"].value_counts()\n",
    "    .reindex(level2_plot_order)\n",
    "    .dropna()\n",
    "    .astype(int)\n",
    "    .reset_index()\n",
    ")\n",
    "totals.columns = [\"Level2_plot\", \"n_cells\"]\n",
    "totals[\"group\"] = totals[\"Level2_plot\"].str.split(\" \\\\| \").str[0]\n",
    "totals[\"Level2_final\"] = totals[\"Level2_plot\"].str.split(\" \\\\| \").str[1]\n",
    "\n",
    "totals_path = OUT_SUMMARY / \"QA_dotplot_totals_by_Level2_plot_noRBC.csv\"\n",
    "totals.to_csv(totals_path, index=False)\n",
    "print(\"Saved:\", totals_path)\n",
    "\n",
    "marker_rows = []\n",
    "for l2 in level2_order:\n",
    "    genes = lvl2_to_symbols.get(l2, [])\n",
    "    m1 = genes[0] if len(genes) > 0 else None\n",
    "    m2 = genes[1] if len(genes) > 1 else None\n",
    "    marker_rows.append({\"Level2_final\": l2, \"group\": group_of_l2(l2), \"marker1\": m1, \"marker2\": m2})\n",
    "\n",
    "markers_df = pd.DataFrame(marker_rows)\n",
    "markers_df[\"Level2_plot\"] = markers_df.apply(lambda r: f\"{r['group']} | {r['Level2_final']}\", axis=1)\n",
    "\n",
    "markers_path = OUT_SUMMARY / \"QA_dotplot_markers_2perLevel2_noRBC.csv\"\n",
    "markers_df.to_csv(markers_path, index=False)\n",
    "print(\"Saved:\", markers_path)\n",
    "\n",
    "print(\"[OK] Dotplot global + tablas QA guardadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831109f0-783c-4134-9d6e-a975b856ef02",
   "metadata": {},
   "source": [
    "### 9. QA “Dotplot en números”: mean_log1p + frac_nonzero por Level2_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82abd1-c986-4efd-9a00-1d85ed862e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "# genes usados = los del dotplot\n",
    "genes_used = list(gene_varnames)\n",
    "\n",
    "# (seguridad) filtrar a genes presentes\n",
    "# aquí adata_plot ya está en memoria, pero genes_used se valida igual\n",
    "genes_used = [g for g in genes_used if g in adata_plot.var_names]\n",
    "if len(genes_used) == 0:\n",
    "    raise RuntimeError(\"genes_used quedó vacío. Revisa gene_varnames vs var_names.\")\n",
    "\n",
    "# reconstruir Level2_final en el objeto pequeño\n",
    "# (obs original está en RAM y gene_varnames se definió con el backed)\n",
    "lvl2_final_small = obs.loc[adata_plot.obs_names, \"Level2_final\"].astype(str).values\n",
    "adata_plot.obs[\"Level2_final\"] = lvl2_final_small\n",
    "\n",
    "# seleccionar matriz desde layer\n",
    "X = adata_plot.layers[LAYER] if LAYER in adata_plot.layers.keys() else adata_plot.X\n",
    "if sp.issparse(X):\n",
    "    X = X.tocsr()\n",
    "\n",
    "groups = pd.Series(adata_plot.obs[\"Level2_final\"].astype(str).values, index=adata_plot.obs_names)\n",
    "uniq = sorted(groups.unique())\n",
    "\n",
    "rows = []\n",
    "for g in uniq:\n",
    "    idx = np.where(groups.values == g)[0]\n",
    "    n = int(idx.size)\n",
    "    if n == 0:\n",
    "        continue\n",
    "\n",
    "    Xg = X[idx, :]\n",
    "\n",
    "    if sp.issparse(Xg):\n",
    "        mean = np.asarray(Xg.mean(axis=0)).ravel()\n",
    "        nnz = np.asarray((Xg > 0).mean(axis=0)).ravel()\n",
    "    else:\n",
    "        Xg = np.asarray(Xg)\n",
    "        mean = np.mean(Xg, axis=0)\n",
    "        nnz = np.mean((Xg > 0), axis=0)\n",
    "\n",
    "    row = {\"Level2_final\": g, \"n_cells\": n}\n",
    "    for j, gene in enumerate(genes_used):\n",
    "        row[f\"{gene}__mean_log1p\"] = float(mean[j])\n",
    "        row[f\"{gene}__frac_nonzero\"] = float(nnz[j])\n",
    "    rows.append(row)\n",
    "\n",
    "df_num = pd.DataFrame(rows).sort_values(\"n_cells\", ascending=False)\n",
    "\n",
    "out_path = OUT_SUMMARY / \"QA_dotplot_numeric_matrix_Level2final.csv\"\n",
    "df_num.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"Shape:\", df_num.shape)\n",
    "print(df_num.head(8).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

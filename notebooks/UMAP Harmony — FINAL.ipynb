{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddc088-14ef-48d0-ac62-4b7bf762ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UMAP Harmony — FINAL (con Level2_final: Conv_T_other -> CD4_Memory)\n",
    "# - NO lee X ni layers (evita MemoryError de /layers/log1p_10k)\n",
    "# - Lee SOLO: obs + obsm['X_pca'] desde el .h5ad vía h5py\n",
    "# - Ejecuta Harmony con key='patientID'\n",
    "# - Calcula neighbors + UMAP sobre X_pca_harmony\n",
    "# - Guarda UMAPs: Level1_refined, Level2_final, disease, patientID en figures_final/\n",
    "# - QA numérico usa Level2_final (no Level2 legacy)\n",
    "# ============================================================\n",
    "\n",
    "# ---------------------------\n",
    "# CELL 1 — imports + paths + lectura mínima (obs + X_pca) + Level2_final\n",
    "# ---------------------------\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "def _read_elem(h5obj):\n",
    "    \"\"\"\n",
    "    Lee un elemento AnnData desde h5py sin materializar /layers.\n",
    "    Funciona en anndata>=0.8 (rutas pueden variar).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from anndata.experimental import read_elem as _re\n",
    "        return _re(h5obj)\n",
    "    except Exception:\n",
    "        try:\n",
    "            from anndata._io.specs import read_elem as _re\n",
    "            return _re(h5obj)\n",
    "        except Exception as e:\n",
    "            raise ImportError(\n",
    "                \"No puedo importar read_elem (anndata.experimental.read_elem / anndata._io.specs.read_elem). \"\n",
    "                \"Necesitas anndata con soporte de lectura de elementos.\"\n",
    "            ) from e\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encuentro 'data_processed' subiendo desde: {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "\n",
    "IN_PATH = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "\n",
    "OUT_FIG = PROJECT_ROOT / \"figures_final\"\n",
    "OUT_SUM = PROJECT_ROOT / \"summary_tables_final\"\n",
    "OUT_FIG.mkdir(exist_ok=True)\n",
    "OUT_SUM.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Scanpy:\", getattr(sc, \"__version__\", \"unknown\"))\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"IN_PATH     :\", IN_PATH)\n",
    "print(\"OUT_FIG     :\", OUT_FIG)\n",
    "print(\"OUT_SUM     :\", OUT_SUM)\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe IN_PATH:\\n{IN_PATH}\")\n",
    "\n",
    "# --- cargar mapa Level2_final (ya lo generaste) ---\n",
    "MAP_PATH = OUT_SUM / \"Level2_final_map.json\"\n",
    "print(\"MAP_PATH    :\", MAP_PATH)\n",
    "if not MAP_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"No existe MAP_PATH:\\n{MAP_PATH}\\n\"\n",
    "        \"Este notebook requiere el mapa Level2_final_map.json (Conv_T_other -> CD4_Memory).\"\n",
    "    )\n",
    "\n",
    "with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    level2_map = json.load(f)\n",
    "\n",
    "needed_obs = [\"patientID\", \"disease\", \"Level1_refined\", \"Level2\"]\n",
    "\n",
    "with h5py.File(IN_PATH, \"r\") as f:\n",
    "    # obs (DataFrame)\n",
    "    if \"obs\" not in f:\n",
    "        raise KeyError(\"No existe grupo /obs en el .h5ad (archivo corrupto o no estándar).\")\n",
    "\n",
    "    obs_full = _read_elem(f[\"obs\"])\n",
    "    if not isinstance(obs_full, pd.DataFrame):\n",
    "        raise TypeError(f\"read_elem(/obs) no devolvió DataFrame. Tipo: {type(obs_full)}\")\n",
    "\n",
    "    missing = [c for c in needed_obs if c not in obs_full.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Faltan columnas en obs: {missing}\")\n",
    "\n",
    "    obs_full = obs_full.copy()\n",
    "    obs_full[\"patientID\"] = obs_full[\"patientID\"].astype(str)\n",
    "    obs_full[\"disease\"] = obs_full[\"disease\"].astype(str)\n",
    "    obs_full[\"Level1_refined\"] = obs_full[\"Level1_refined\"].astype(str)\n",
    "\n",
    "    # Mantener Level2 como object (sin convertir NaN->\"nan\")\n",
    "    l2_obj = obs_full[\"Level2\"].astype(\"object\")\n",
    "\n",
    "    # Level2_final (mapping Conv_T_other -> CD4_Memory)\n",
    "    l2_final = l2_obj.replace(level2_map)\n",
    "    obs_full[\"Level2_final\"] = pd.Categorical(l2_final)\n",
    "\n",
    "    print(\"\\n[CHECK] Conv_T_other remaining en Level2_final (debe ser 0):\",\n",
    "          int((obs_full[\"Level2_final\"].astype(str) == \"Conv_T_other\").sum()))\n",
    "    print(\"[CHECK] CD4_Memory count en Level2_final:\",\n",
    "          int((obs_full[\"Level2_final\"].astype(str) == \"CD4_Memory\").sum()))\n",
    "\n",
    "    # RBC-out sanity (si aparece, se excluye SOLO para UMAP)\n",
    "    keep = ~(\n",
    "        (obs_full[\"Level1_refined\"].astype(str) == \"RBC\") |\n",
    "        (l2_obj.astype(str) == \"RBC\") |\n",
    "        (obs_full[\"Level2_final\"].astype(str) == \"RBC\")\n",
    "    )\n",
    "    n_rbc = int((~keep).sum())\n",
    "    if n_rbc > 0:\n",
    "        print(f\"[WARN] Aún hay RBC en el objeto ({n_rbc} células). Para UMAP Harmony se excluirán.\")\n",
    "\n",
    "    idx_keep = np.flatnonzero(keep.to_numpy(dtype=bool))\n",
    "    obs_keep = obs_full.iloc[idx_keep].copy()\n",
    "\n",
    "    # X_pca\n",
    "    if \"obsm\" not in f or \"X_pca\" not in f[\"obsm\"]:\n",
    "        raise KeyError(\"No existe /obsm/X_pca en el .h5ad. Necesitas PCA calculado antes.\")\n",
    "\n",
    "    X_pca_ds = f[\"obsm\"][\"X_pca\"]\n",
    "    X_pca = np.asarray(X_pca_ds[idx_keep, :], dtype=np.float32)\n",
    "\n",
    "print(\"\\nX_pca shape:\", X_pca.shape)\n",
    "print(\"n_obs total :\", obs_full.shape[0])\n",
    "print(\"n_obs keep  :\", obs_keep.shape[0])\n",
    "\n",
    "# Construir AnnData mínimo (NO trae X/layers)\n",
    "adata_umap = ad.AnnData(\n",
    "    X=np.zeros((obs_keep.shape[0], 1), dtype=np.float32),\n",
    "    obs=obs_keep\n",
    ")\n",
    "\n",
    "# --- fijar nº PCs a usar y recortar X_pca para que Harmony sea consistente ---\n",
    "N_PCS = min(50, X_pca.shape[1])\n",
    "adata_umap.obsm[\"X_pca\"] = X_pca[:, :N_PCS].astype(np.float32, copy=False)\n",
    "\n",
    "print(\"\\nAnnData mínimo para Harmony:\", adata_umap)\n",
    "print(\"obs columns:\", adata_umap.obs.columns.tolist())\n",
    "print(\"X_pca used shape:\", adata_umap.obsm[\"X_pca\"].shape)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# CELL 2 — Harmony sobre X_pca (batch=patientID) + neighbors + UMAP\n",
    "# ---------------------------\n",
    "try:\n",
    "    import scanpy.external as sce\n",
    "    HAVE_SCE = True\n",
    "except Exception:\n",
    "    HAVE_SCE = False\n",
    "\n",
    "try:\n",
    "    import harmonypy as hm\n",
    "    HAVE_HM = True\n",
    "except Exception:\n",
    "    HAVE_HM = False\n",
    "\n",
    "if not HAVE_SCE and not HAVE_HM:\n",
    "    raise ModuleNotFoundError(\n",
    "        \"No encuentro ni scanpy.external (harmony_integrate) ni harmonypy.\\n\"\n",
    "        \"Instala harmonypy:\\n\"\n",
    "        \"  conda install -c conda-forge harmonypy\\n\"\n",
    "        \"o:\\n\"\n",
    "        \"  python -m pip install -U harmonypy\"\n",
    "    )\n",
    "\n",
    "BATCH_KEY = \"patientID\"\n",
    "N_NEIGHBORS = 15\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "print(\"\\nParams:\")\n",
    "print(\"BATCH_KEY   :\", BATCH_KEY)\n",
    "print(\"N_PCS       :\", N_PCS)\n",
    "print(\"N_NEIGHBORS :\", N_NEIGHBORS)\n",
    "\n",
    "adata_umap.obs[BATCH_KEY] = adata_umap.obs[BATCH_KEY].astype(\"category\")\n",
    "\n",
    "if HAVE_SCE and hasattr(sce.pp, \"harmony_integrate\"):\n",
    "    print(\"\\n[Harmony] usando scanpy.external.pp.harmony_integrate ...\")\n",
    "    sce.pp.harmony_integrate(\n",
    "        adata_umap,\n",
    "        key=BATCH_KEY,\n",
    "        basis=\"X_pca\",\n",
    "        adjusted_basis=\"X_pca_harmony\",\n",
    "        max_iter_harmony=20,\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n[Harmony] usando harmonypy.run_harmony (fallback) ...\")\n",
    "    Z = adata_umap.obsm[\"X_pca\"].T  # (pcs x cells)\n",
    "    meta = adata_umap.obs[[BATCH_KEY]].copy()\n",
    "    ho = hm.run_harmony(Z, meta, vars_use=[BATCH_KEY])\n",
    "    adata_umap.obsm[\"X_pca_harmony\"] = ho.Z_corr.T.astype(np.float32, copy=False)\n",
    "\n",
    "print(\"X_pca_harmony shape:\", adata_umap.obsm[\"X_pca_harmony\"].shape)\n",
    "\n",
    "sc.pp.neighbors(\n",
    "    adata_umap,\n",
    "    n_neighbors=N_NEIGHBORS,\n",
    "    n_pcs=N_PCS,\n",
    "    use_rep=\"X_pca_harmony\",\n",
    ")\n",
    "sc.tl.umap(adata_umap, random_state=RANDOM_STATE)\n",
    "\n",
    "adata_umap.obsm[\"X_umap_harmony\"] = adata_umap.obsm.pop(\"X_umap\")\n",
    "print(\"[OK] Harmony + neighbors + UMAP listo.\")\n",
    "print(\"obsm keys:\", list(adata_umap.obsm.keys()))\n",
    "\n",
    "# Guardar coords para downstream (QA coherence / compactness)\n",
    "emb = pd.DataFrame(\n",
    "    adata_umap.obsm[\"X_umap_harmony\"],\n",
    "    index=adata_umap.obs_names,\n",
    "    columns=[\"UMAP1_harmony\", \"UMAP2_harmony\"]\n",
    ")\n",
    "\n",
    "emb_out = pd.concat(\n",
    "    [\n",
    "        adata_umap.obs[[\"patientID\", \"disease\", \"Level1_refined\", \"Level2\", \"Level2_final\"]],\n",
    "        emb\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "emb_path = OUT_SUM / \"UMAP_Harmony_embeddings.csv\"\n",
    "emb_out.to_csv(emb_path, index=True)\n",
    "print(\"Saved embeddings:\", emb_path)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# CELL 3 — plots (Level1_refined, Level2_final, disease, patientID)\n",
    "# ---------------------------\n",
    "sc.settings.autoshow = False\n",
    "\n",
    "def save_umap(color, out_name, title=None, legend_loc=\"right margin\", legend_fontsize=7):\n",
    "    ax = sc.pl.embedding(\n",
    "        adata_umap,\n",
    "        basis=\"umap_harmony\",\n",
    "        color=color,\n",
    "        show=False,\n",
    "        frameon=False,\n",
    "        legend_loc=legend_loc,\n",
    "        legend_fontsize=legend_fontsize,\n",
    "        title=title,\n",
    "    )\n",
    "    fig = ax.figure\n",
    "    out_path = OUT_FIG / out_name\n",
    "    fig.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", out_path)\n",
    "\n",
    "save_umap(\n",
    "    color=\"Level1_refined\",\n",
    "    out_name=\"UMAP_Harmony_Level1_refined.png\",\n",
    "    title=\"UMAP (Harmony; batch=patientID) — Level1_refined\",\n",
    "    legend_loc=\"right margin\",\n",
    "    legend_fontsize=7,\n",
    ")\n",
    "\n",
    "save_umap(\n",
    "    color=\"Level2_final\",\n",
    "    out_name=\"UMAP_Harmony_Level2.png\",\n",
    "    title=\"UMAP (Harmony; batch=patientID) — Level2_final\",\n",
    "    legend_loc=\"right margin\",\n",
    "    legend_fontsize=6,\n",
    ")\n",
    "\n",
    "save_umap(\n",
    "    color=\"disease\",\n",
    "    out_name=\"UMAP_Harmony_disease.png\",\n",
    "    title=\"UMAP (Harmony; batch=patientID) — disease\",\n",
    "    legend_loc=\"right margin\",\n",
    "    legend_fontsize=8,\n",
    ")\n",
    "\n",
    "# patientID: sin leyenda (si no, la figura explota)\n",
    "save_umap(\n",
    "    color=\"patientID\",\n",
    "    out_name=\"UMAP_Harmony_patientID.png\",\n",
    "    title=\"UMAP (Harmony; batch=patientID) — patientID\",\n",
    "    legend_loc=\"none\",\n",
    "    legend_fontsize=6,\n",
    ")\n",
    "\n",
    "print(\"\\n[OK] UMAPs Harmony guardados en figures_final/.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CELL X — QA numérico de UMAP/vecinos (usa Level2_final)\n",
    "# ============================================================\n",
    "import scipy.sparse as sp\n",
    "\n",
    "QA_DIR = OUT_SUM\n",
    "QA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def _topk_neighbors_from_connectivities(C, k=15):\n",
    "    if not sp.issparse(C):\n",
    "        C = sp.csr_matrix(C)\n",
    "    C = C.tocsr()\n",
    "    n = C.shape[0]\n",
    "    neigh_idx = []\n",
    "    for i in range(n):\n",
    "        start, end = C.indptr[i], C.indptr[i+1]\n",
    "        cols = C.indices[start:end]\n",
    "        data = C.data[start:end]\n",
    "        m = cols != i\n",
    "        cols = cols[m]\n",
    "        data = data[m]\n",
    "        if cols.size == 0:\n",
    "            neigh_idx.append(np.array([], dtype=int))\n",
    "            continue\n",
    "        if cols.size > k:\n",
    "            sel = np.argpartition(-data, k-1)[:k]\n",
    "            cols = cols[sel]\n",
    "            data = data[sel]\n",
    "            ord2 = np.argsort(-data)\n",
    "            cols = cols[ord2]\n",
    "        neigh_idx.append(cols.astype(int))\n",
    "    return neigh_idx\n",
    "\n",
    "def neighbor_mixing_stats(labels: np.ndarray, neigh_idx, k_expected=15):\n",
    "    labels = labels.astype(str)\n",
    "    n = len(labels)\n",
    "    fracs = np.full(n, np.nan, dtype=float)\n",
    "    for i in range(n):\n",
    "        nb = neigh_idx[i]\n",
    "        if nb.size == 0:\n",
    "            continue\n",
    "        fracs[i] = np.mean(labels[nb] == labels[i])\n",
    "    return {\n",
    "        \"n_cells\": int(n),\n",
    "        \"k_expected\": int(k_expected),\n",
    "        \"mean_same\": float(np.nanmean(fracs)),\n",
    "        \"median_same\": float(np.nanmedian(fracs)),\n",
    "        \"p25_same\": float(np.nanpercentile(fracs, 25)),\n",
    "        \"p75_same\": float(np.nanpercentile(fracs, 75)),\n",
    "        \"na_cells\": int(np.isnan(fracs).sum()),\n",
    "    }\n",
    "\n",
    "def neighbor_entropy(labels: np.ndarray, neigh_idx):\n",
    "    labels = labels.astype(str)\n",
    "    uniq = np.unique(labels)\n",
    "    L = len(uniq)\n",
    "    if L <= 1:\n",
    "        return {\"mean_entropy_norm\": 0.0, \"L\": int(L)}\n",
    "    ent = []\n",
    "    for nb in neigh_idx:\n",
    "        if nb.size == 0:\n",
    "            continue\n",
    "        vals = labels[nb]\n",
    "        _, cts = np.unique(vals, return_counts=True)\n",
    "        p = cts / cts.sum()\n",
    "        h = -np.sum(p * np.log(p + 1e-12))\n",
    "        ent.append(h / np.log(L))\n",
    "    return {\"mean_entropy_norm\": float(np.mean(ent)) if len(ent) else np.nan, \"L\": int(L)}\n",
    "\n",
    "if \"connectivities\" not in adata_umap.obsp:\n",
    "    raise KeyError(\"No encuentro adata_umap.obsp['connectivities']. ¿Has corrido sc.pp.neighbors(...) antes?\")\n",
    "\n",
    "C = adata_umap.obsp[\"connectivities\"]\n",
    "k_expected = int(adata_umap.uns[\"neighbors\"][\"params\"].get(\"n_neighbors\", 15))\n",
    "neigh_idx = _topk_neighbors_from_connectivities(C, k=k_expected)\n",
    "\n",
    "qa_rows = []\n",
    "for col in [\"patientID\", \"disease\", \"Level1_refined\", \"Level2_final\"]:\n",
    "    lab = adata_umap.obs[col].astype(str).to_numpy()\n",
    "    st = neighbor_mixing_stats(lab, neigh_idx, k_expected=k_expected)\n",
    "    ent = neighbor_entropy(lab, neigh_idx)\n",
    "    qa_rows.append({\"label\": col, **st, **ent})\n",
    "\n",
    "qa = pd.DataFrame(qa_rows)\n",
    "qa_path = QA_DIR / \"QA_UMAP_Harmony_neighbor_mixing.csv\"\n",
    "qa.to_csv(qa_path, index=False)\n",
    "\n",
    "print(\"\\nSaved:\", qa_path)\n",
    "print(qa.to_string(index=False))\n",
    "\n",
    "# Matriz paciente->paciente\n",
    "patients = adata_umap.obs[\"patientID\"].astype(str).to_numpy()\n",
    "uniq_p = np.unique(patients)\n",
    "p_to_i = {p: i for i, p in enumerate(uniq_p)}\n",
    "M = np.zeros((len(uniq_p), len(uniq_p)), dtype=np.float64)\n",
    "\n",
    "for i in range(adata_umap.n_obs):\n",
    "    p_i = p_to_i[patients[i]]\n",
    "    nb = neigh_idx[i]\n",
    "    if nb.size == 0:\n",
    "        continue\n",
    "    for j in nb:\n",
    "        p_j = p_to_i[patients[j]]\n",
    "        M[p_i, p_j] += 1.0\n",
    "\n",
    "row_sums = M.sum(axis=1, keepdims=True)\n",
    "M_norm = np.divide(M, np.maximum(row_sums, 1.0))\n",
    "\n",
    "mix_mat = pd.DataFrame(M_norm, index=uniq_p, columns=uniq_p)\n",
    "mix_path = QA_DIR / \"QA_UMAP_Harmony_patient_neighbor_mixing_matrix.csv\"\n",
    "mix_mat.to_csv(mix_path)\n",
    "print(\"\\nSaved:\", mix_path)\n",
    "\n",
    "# Dominancia por Level2_final\n",
    "tmp = adata_umap.obs[[\"patientID\", \"disease\", \"Level2_final\", \"Level1_refined\"]].copy()\n",
    "tmp[\"patientID\"] = tmp[\"patientID\"].astype(str)\n",
    "tmp[\"Level2_final\"] = tmp[\"Level2_final\"].astype(str)\n",
    "\n",
    "ct = (tmp.groupby([\"Level2_final\", \"patientID\"]).size()\n",
    "      .reset_index(name=\"n_cells\"))\n",
    "\n",
    "def _gini(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    if np.all(x == 0):\n",
    "        return 0.0\n",
    "    x = np.sort(x)\n",
    "    n = x.size\n",
    "    cumx = np.cumsum(x)\n",
    "    g = (n + 1 - 2 * np.sum(cumx) / cumx[-1]) / n\n",
    "    return float(g)\n",
    "\n",
    "lvl2_stats = []\n",
    "for lvl2, sub in ct.groupby(\"Level2_final\"):\n",
    "    counts = sub[\"n_cells\"].to_numpy()\n",
    "    lvl2_stats.append({\n",
    "        \"Level2_final\": lvl2,\n",
    "        \"n_patients_with_cells\": int((counts > 0).sum()),\n",
    "        \"total_cells\": int(counts.sum()),\n",
    "        \"max_patient_share\": float(counts.max() / counts.sum()) if counts.sum() > 0 else np.nan,\n",
    "        \"gini_patient_counts\": _gini(counts),\n",
    "    })\n",
    "\n",
    "lvl2_stats = pd.DataFrame(lvl2_stats).sort_values(\n",
    "    [\"max_patient_share\", \"gini_patient_counts\"], ascending=False\n",
    ")\n",
    "\n",
    "lvl2_path = QA_DIR / \"QA_Level2_final_patient_dominance.csv\"\n",
    "lvl2_stats.to_csv(lvl2_path, index=False)\n",
    "\n",
    "lvl2_path_legacy = QA_DIR / \"QA_Level2_patient_dominance.csv\"\n",
    "lvl2_stats.rename(columns={\"Level2_final\": \"Level2\"}).to_csv(lvl2_path_legacy, index=False)\n",
    "\n",
    "print(\"\\nSaved:\", lvl2_path)\n",
    "print(\"Saved (legacy alias):\", lvl2_path_legacy)\n",
    "print(\"\\n[OK] QA numérico Harmony completado.\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# CELL Z — verificación de PNGs + RBC-out real (SIN sc.read_h5ad)\n",
    "# ---------------------------\n",
    "FIG_DIR = OUT_FIG\n",
    "expected = [\n",
    "    \"UMAP_Harmony_Level1_refined.png\",\n",
    "    \"UMAP_Harmony_Level2.png\",\n",
    "    \"UMAP_Harmony_disease.png\",\n",
    "    \"UMAP_Harmony_patientID.png\",\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for fn in expected:\n",
    "    p = FIG_DIR / fn\n",
    "    ok = p.exists()\n",
    "    size_mb = (p.stat().st_size / 1e6) if ok else 0\n",
    "    print(f\"{fn:40s} exists={ok} sizeMB={size_mb:.2f}\")\n",
    "    if not ok:\n",
    "        missing.append(fn)\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(\"FALTAN PNGs UMAP Harmony: \" + \", \".join(missing))\n",
    "\n",
    "# RBC-out check leyendo SOLO obs vía h5py (sin tocar /layers)\n",
    "with h5py.File(IN_PATH, \"r\") as f:\n",
    "    obs_z = _read_elem(f[\"obs\"])\n",
    "    l1r = set(obs_z[\"Level1_refined\"].astype(str).unique()) if \"Level1_refined\" in obs_z.columns else set()\n",
    "    l2  = set(obs_z[\"Level2\"].astype(str).unique()) if \"Level2\" in obs_z.columns else set()\n",
    "\n",
    "if \"RBC\" in l1r or \"RBC\" in l2:\n",
    "    raise RuntimeError(\n",
    "        f\"RBC sigue presente en OUT_FILTER \"\n",
    "        f\"(Level1_refined has RBC? {'RBC' in l1r} | Level2 has RBC? {'RBC' in l2})\"\n",
    "    )\n",
    "\n",
    "print(\"[OK] UMAP Harmony: PNGs presentes + RBC-out verificado (sin cargar layers).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4430d27c-47a5-4e29-87c3-3bfa80ea7b61",
   "metadata": {},
   "source": [
    "“Algunas subpoblaciones (p.ej. ISG_Myeloid, aDC…) muestran fuerte dominancia por paciente (max_patient_share alto), por lo que su interpretación debe hacerse con cautela y priorizando análisis a nivel de paciente (composición scCODA/pseudobulk).”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfm_scRNA)",
   "language": "python",
   "name": "tfm_scrna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

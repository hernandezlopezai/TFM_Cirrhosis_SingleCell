{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c5eb8-c974-4d51-be5c-46d02176a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Conv_T_other_cleanup.ipynb  (ACTUALIZADO post-NBXX)\n",
    "# Conv_T_other — caracterización + renombrado automático (Level2_final_map)\n",
    "# - NO re-etiqueta todo el Level2: solo resuelve Conv_T_other\n",
    "# - Memory-safe: abre backed=\"r\" y solo carga T-cells x panel genes a RAM\n",
    "# - ROBUSTO a var_names != símbolos: usa adata.var['symbol'] si existe\n",
    "# - Salidas: QA tables + JSON mapping para usar en figuras/Downstream\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encuentro 'data_processed' subiendo desde: {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "IN_PATH = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "\n",
    "OUT_SUMMARY = PROJECT_ROOT / \"summary_tables_final\"\n",
    "OUT_SUMMARY.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"IN_PATH     :\", IN_PATH)\n",
    "print(\"OUT_SUMMARY :\", OUT_SUMMARY)\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe IN_PATH:\\n{IN_PATH}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: mapping símbolo -> varname\n",
    "# -----------------------------\n",
    "def symbol_to_varname(adata, symbol: str):\n",
    "    # 1) si var_names ya son símbolos\n",
    "    if symbol in adata.var_names:\n",
    "        return symbol\n",
    "    # 2) si hay columna var['symbol']\n",
    "    if \"symbol\" in adata.var.columns:\n",
    "        sym = adata.var[\"symbol\"].astype(str).to_numpy()\n",
    "        hits = np.where(sym == symbol)[0]\n",
    "        if hits.size > 0:\n",
    "            return adata.var_names[hits[0]]\n",
    "    return None\n",
    "\n",
    "def symbols_to_varnames(adata, symbols):\n",
    "    out = []\n",
    "    for s in symbols:\n",
    "        out.append(symbol_to_varname(adata, s))\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Cargar en backed\n",
    "# -----------------------------\n",
    "adata_b = sc.read_h5ad(IN_PATH, backed=\"r\")\n",
    "\n",
    "try:\n",
    "    # checks\n",
    "    needed = [\"patientID\", \"Level1_refined\", \"Level2\"]\n",
    "    missing = [c for c in needed if c not in adata_b.obs.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Faltan columnas en obs: {missing}\")\n",
    "\n",
    "    # RBC-out sanity (informativo)\n",
    "    rbc_n = int((adata_b.obs[\"Level2\"].astype(str) == \"RBC\").sum())\n",
    "    print(\"RBC cells (should be 0):\", rbc_n)\n",
    "\n",
    "    obs = adata_b.obs[[\"patientID\", \"Level1_refined\", \"Level2\"]].copy()\n",
    "    obs[\"patientID\"] = obs[\"patientID\"].astype(str)\n",
    "    obs[\"Level1_refined\"] = obs[\"Level1_refined\"].astype(str)\n",
    "    obs[\"Level2\"] = obs[\"Level2\"].astype(str)\n",
    "\n",
    "    # Subset: SOLO T (Level1_refined == T)\n",
    "    mask_T = (obs[\"Level1_refined\"].values == \"T\")\n",
    "    nT = int(mask_T.sum())\n",
    "    print(\"T cells:\", nT)\n",
    "    if nT == 0:\n",
    "        raise ValueError(\"No hay células T en Level1_refined; esto no debería pasar.\")\n",
    "\n",
    "    # ¿Existe Conv_T_other?\n",
    "    n_conv = int((obs.loc[mask_T, \"Level2\"].values == \"Conv_T_other\").sum())\n",
    "    print(\"Conv_T_other in T:\", n_conv)\n",
    "    if n_conv == 0:\n",
    "        raise ValueError(\"No hay Conv_T_other en el objeto. Si ya lo eliminaste/renombraste, este notebook no aplica.\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Panel de genes (firmas) para decidir qué es Conv_T_other\n",
    "    # -----------------------------\n",
    "    signatures = {\n",
    "        \"Naive_Memory_like\": [\"IL7R\",\"CCR7\",\"LTB\",\"TCF7\",\"LEF1\",\"MALAT1\"],\n",
    "        \"Cytotoxic_like\":    [\"NKG7\",\"GNLY\",\"PRF1\",\"GZMB\",\"FGFBP2\"],\n",
    "        \"Treg_like\":         [\"FOXP3\",\"IL2RA\",\"CTLA4\",\"IKZF2\",\"TNFRSF18\"],\n",
    "        \"Exhausted_like\":    [\"PDCD1\",\"LAG3\",\"TIGIT\",\"TOX\",\"HAVCR2\"],\n",
    "        \"Proliferative_like\":[\"MKI67\",\"TOP2A\",\"STMN1\",\"HMGB2\",\"TYMS\"],\n",
    "        \"ISG_like\":          [\"ISG15\",\"IFIT1\",\"IFIT3\",\"MX1\",\"OAS1\"],\n",
    "    }\n",
    "\n",
    "    markers_extra = [\n",
    "        \"TRAC\",\"TRBC1\",\"TRBC2\",\"CD3D\",\"CD3E\",\n",
    "        \"CD4\",\"CD8A\",\"CD8B\",\n",
    "        \"KLRD1\",\"FCGR3A\",\n",
    "        \"JUN\",\"FOS\",\"IL32\",\"HLA-DRA\"\n",
    "    ]\n",
    "\n",
    "    panel_symbols = []\n",
    "    for _, genes in signatures.items():\n",
    "        panel_symbols += genes\n",
    "    panel_symbols += markers_extra\n",
    "    panel_symbols = list(dict.fromkeys(panel_symbols))  # dedup manteniendo orden\n",
    "\n",
    "    # map symbol -> varname (robusto a Ensembl)\n",
    "    panel_varnames = symbols_to_varnames(adata_b, panel_symbols)\n",
    "    kept = [(s, v) for s, v in zip(panel_symbols, panel_varnames) if v is not None]\n",
    "    missing_genes = [s for s, v in zip(panel_symbols, panel_varnames) if v is None]\n",
    "\n",
    "    if len(kept) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No se pudo mapear ningún gen del panel a var_names (ni por var['symbol']). \"\n",
    "            \"Revisa adata.var_names / adata.var['symbol'].\"\n",
    "        )\n",
    "\n",
    "    present_symbols = [s for s, _ in kept]\n",
    "    present_varnames = [v for _, v in kept]\n",
    "    varname_to_symbol = {v: s for s, v in kept}\n",
    "\n",
    "    print(\"Panel genes mapped:\", len(present_symbols), \"| missing:\", len(missing_genes))\n",
    "    if missing_genes:\n",
    "        print(\"[INFO] Missing genes (ok):\", missing_genes)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Cargar a memoria SOLO T cells x panel genes\n",
    "    # -----------------------------\n",
    "    idx_T = np.where(mask_T)[0]\n",
    "    adata_small = adata_b[idx_T, present_varnames].to_memory()\n",
    "\n",
    "finally:\n",
    "    # cerrar backed siempre\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Layer preferida\n",
    "LAYER = \"log1p_10k\"\n",
    "if LAYER not in adata_small.layers.keys():\n",
    "    raise KeyError(f\"No existe layer {LAYER} en el objeto; layers={list(adata_small.layers.keys())}\")\n",
    "\n",
    "# tabla expresión por célula (panel) usando varnames, luego renombrar a símbolos\n",
    "df_expr = sc.get.obs_df(adata_small, keys=present_varnames, layer=LAYER, use_raw=False)\n",
    "df_expr = df_expr.rename(columns=varname_to_symbol)\n",
    "\n",
    "df_expr[\"Level2\"] = adata_small.obs[\"Level2\"].astype(str).values\n",
    "df_expr[\"patientID\"] = adata_small.obs[\"patientID\"].astype(str).values\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Medias por Level2 (dentro de T) para marcadores del panel\n",
    "# -----------------------------\n",
    "means_by_l2 = df_expr.groupby(\"Level2\")[present_symbols].mean()\n",
    "\n",
    "top_rows = []\n",
    "for l2 in means_by_l2.index:\n",
    "    s = means_by_l2.loc[l2].sort_values(ascending=False).head(25)\n",
    "    for g, v in s.items():\n",
    "        top_rows.append([l2, g, float(v)])\n",
    "\n",
    "top_df = pd.DataFrame(top_rows, columns=[\"Level2\", \"gene\", \"mean_log1p\"])\n",
    "out_top = OUT_SUMMARY / \"QA_ConvT_other_topmarkers_meanlog1p.csv\"\n",
    "top_df.to_csv(out_top, index=False)\n",
    "print(\"Saved:\", out_top)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Scores de firmas por Level2 (media de genes de cada firma)\n",
    "# -----------------------------\n",
    "score_rows = []\n",
    "for l2 in means_by_l2.index:\n",
    "    for sig, genes in signatures.items():\n",
    "        genes_ok = [g for g in genes if g in means_by_l2.columns]\n",
    "        if len(genes_ok) == 0:\n",
    "            score = np.nan\n",
    "        else:\n",
    "            score = float(means_by_l2.loc[l2, genes_ok].mean())\n",
    "        score_rows.append([l2, sig, score, len(genes_ok)])\n",
    "\n",
    "scores = pd.DataFrame(score_rows, columns=[\"Level2\",\"signature\",\"score_meanlog1p\",\"n_genes_used\"])\n",
    "scores_pivot = scores.pivot(index=\"Level2\", columns=\"signature\", values=\"score_meanlog1p\")\n",
    "\n",
    "out_scores = OUT_SUMMARY / \"QA_ConvT_other_signature_scores.csv\"\n",
    "scores_pivot.to_csv(out_scores)\n",
    "print(\"Saved:\", out_scores)\n",
    "\n",
    "print(\"\\n=== Signature scores (Conv_T_other row) ===\")\n",
    "if \"Conv_T_other\" in scores_pivot.index:\n",
    "    print(scores_pivot.loc[[\"Conv_T_other\"]])\n",
    "else:\n",
    "    raise RuntimeError(\"No se encontró fila 'Conv_T_other' en scores_pivot (esto no debería pasar).\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Decisión automática (reproducible) de qué hacer con Conv_T_other\n",
    "# -----------------------------\n",
    "conv_scores = scores_pivot.loc[\"Conv_T_other\"].dropna()\n",
    "if conv_scores.empty:\n",
    "    raise RuntimeError(\"Conv_T_other tiene todos los scores NaN; no se puede decidir mapping.\")\n",
    "\n",
    "best_sig = conv_scores.sort_values(ascending=False).index[0]\n",
    "best_val = float(conv_scores.loc[best_sig])\n",
    "\n",
    "# mapping final SOLO para Conv_T_other\n",
    "if best_sig == \"Naive_Memory_like\":\n",
    "    new_label = \"CD4_Memory\"\n",
    "elif best_sig == \"Cytotoxic_like\":\n",
    "    new_label = \"CD8_Effector_Cytotoxic\"     # merge\n",
    "elif best_sig == \"Treg_like\":\n",
    "    new_label = \"Treg\"                       # merge\n",
    "elif best_sig == \"Exhausted_like\":\n",
    "    new_label = \"Exhausted_T\"                # merge\n",
    "elif best_sig == \"Proliferative_like\":\n",
    "    new_label = \"Proliferative_T\"            # merge\n",
    "elif best_sig == \"ISG_like\":\n",
    "    new_label = \"ISG_T\"\n",
    "else:\n",
    "    new_label = \"T_Other\"\n",
    "\n",
    "level2_map = {\"Conv_T_other\": new_label}\n",
    "\n",
    "# Guardar mapping\n",
    "out_map = OUT_SUMMARY / \"Level2_final_map.json\"\n",
    "with open(out_map, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(level2_map, f, indent=2)\n",
    "\n",
    "# Guardar decisión en TXT\n",
    "out_dec = OUT_SUMMARY / \"ConvT_other_decision.txt\"\n",
    "with open(out_dec, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Conv_T_other decision\\n\")\n",
    "    f.write(f\"- best_signature: {best_sig}\\n\")\n",
    "    f.write(f\"- best_score_meanlog1p: {best_val:.6f}\\n\")\n",
    "    f.write(f\"- new_label: {new_label}\\n\")\n",
    "    f.write(f\"- n_cells_Conv_T_other (in T): {n_conv}\\n\")\n",
    "\n",
    "print(\"\\n=== DECISIÓN FINAL ===\")\n",
    "print(\"best_signature:\", best_sig)\n",
    "print(\"best_score_meanlog1p:\", best_val)\n",
    "print(\"Conv_T_other ->\", new_label)\n",
    "print(\"Saved:\", out_map)\n",
    "print(\"Saved:\", out_dec)\n",
    "\n",
    "print(\"\\n[OK] Conv_T_other caracterizado + mapping final generado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfm_scRNA)",
   "language": "python",
   "name": "tfm_scrna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

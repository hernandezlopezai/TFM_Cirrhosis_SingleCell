{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a3ec0c-45d2-4900-99c1-23cff01835b7",
   "metadata": {},
   "source": [
    "### 1. Imports + paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7efc4-61f2-47a9-9b6d-eb76ab3fa23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from src.paths import project_paths\n",
    "\n",
    "print(\"Scanpy:\", sc.__version__)\n",
    "\n",
    "P = project_paths(Path.cwd())\n",
    "PROJECT_ROOT = P[\"PROJECT_ROOT\"]\n",
    "CONFIG_DIR   = P[\"CONFIG_DIR\"]\n",
    "DATA_DIR     = P[\"DATA_DIR\"]\n",
    "RESULTS_DIR  = P[\"RESULTS_DIR\"]\n",
    "FIGURES_DIR  = P[\"FIGURES_DIR\"]\n",
    "\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Outputs (solo results/)\n",
    "OUT_DIR = RESULTS_DIR / \"summary_tables\" / \"conv_t_other_cleanup\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"CONFIG_DIR  :\", CONFIG_DIR)\n",
    "print(\"DATA_DIR    :\", DATA_DIR)\n",
    "print(\"RESULTS_DIR :\", RESULTS_DIR)\n",
    "print(\"OUT_DIR     :\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bcc609-7596-4ceb-b16c-44d129a13825",
   "metadata": {},
   "source": [
    "### 2. Leer config + parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195ccf9-d721-4891-bc4d-a639ea0ee1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simple_yaml(path: Path) -> dict:\n",
    "    cfg = {}\n",
    "    for line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \":\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\":\", 1)\n",
    "        cfg[k.strip()] = v.strip().strip('\"').strip(\"'\")\n",
    "    return cfg\n",
    "\n",
    "cfg_path = CONFIG_DIR / \"config.yaml\"\n",
    "if not cfg_path.exists():\n",
    "    raise FileNotFoundError(f\"Falta {cfg_path}\")\n",
    "\n",
    "CFG = load_simple_yaml(cfg_path)\n",
    "\n",
    "# Input: salida del NB10 (main_filtered_for_analysis)\n",
    "IN_NAME = CFG.get(\"main_filtered_for_analysis_h5ad_filename\", \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\")\n",
    "IN_PATH = RESULTS_DIR / IN_NAME\n",
    "\n",
    "# Keys esperadas\n",
    "LEVEL1_REFINED_KEY = CFG.get(\"level1_refined_key\", \"Level1_refined\")\n",
    "LEVEL2_KEY         = CFG.get(\"level2_key\", \"Level2\")\n",
    "PATIENT_KEY        = CFG.get(\"patient_id_key\", \"patientID\")\n",
    "\n",
    "# Layer (mantiene default histórico)\n",
    "LAYER = CFG.get(\"analysis_layer\", \"log1p_10k\")\n",
    "\n",
    "print(\"IN_PATH            :\", IN_PATH)\n",
    "print(\"LEVEL1_REFINED_KEY :\", LEVEL1_REFINED_KEY)\n",
    "print(\"LEVEL2_KEY         :\", LEVEL2_KEY)\n",
    "print(\"PATIENT_KEY        :\", PATIENT_KEY)\n",
    "print(\"LAYER              :\", LAYER)\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe IN_PATH:\\n{IN_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f18560-1dab-42b3-8824-55594e698e77",
   "metadata": {},
   "source": [
    "### 3. Helpers: mapping símbolo -> varname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f015c-67bd-4746-96cd-bbd4e3a81a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbol_to_varname(adata, symbol: str):\n",
    "    # 1) si var_names ya son símbolos\n",
    "    if symbol in adata.var_names:\n",
    "        return symbol\n",
    "    # 2) si hay columna var['symbol']\n",
    "    if \"symbol\" in adata.var.columns:\n",
    "        sym = adata.var[\"symbol\"].astype(str).to_numpy()\n",
    "        hits = np.where(sym == symbol)[0]\n",
    "        if hits.size > 0:\n",
    "            return adata.var_names[hits[0]]\n",
    "    return None\n",
    "\n",
    "def symbols_to_varnames(adata, symbols):\n",
    "    out = []\n",
    "    for s in symbols:\n",
    "        out.append(symbol_to_varname(adata, s))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a0e94-0933-4680-b01d-a0cb9569c4d0",
   "metadata": {},
   "source": [
    "### 4. Cargar T cells × panel genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b2b495-caa6-451b-83ba-eb8fb73034cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel de genes (firmas) para decidir qué es Conv_T_other\n",
    "signatures = {\n",
    "    \"Naive_Memory_like\": [\"IL7R\",\"CCR7\",\"LTB\",\"TCF7\",\"LEF1\",\"MALAT1\"],\n",
    "    \"Cytotoxic_like\":    [\"NKG7\",\"GNLY\",\"PRF1\",\"GZMB\",\"FGFBP2\"],\n",
    "    \"Treg_like\":         [\"FOXP3\",\"IL2RA\",\"CTLA4\",\"IKZF2\",\"TNFRSF18\"],\n",
    "    \"Exhausted_like\":    [\"PDCD1\",\"LAG3\",\"TIGIT\",\"TOX\",\"HAVCR2\"],\n",
    "    \"Proliferative_like\":[\"MKI67\",\"TOP2A\",\"STMN1\",\"HMGB2\",\"TYMS\"],\n",
    "    \"ISG_like\":          [\"ISG15\",\"IFIT1\",\"IFIT3\",\"MX1\",\"OAS1\"],\n",
    "}\n",
    "\n",
    "markers_extra = [\n",
    "    \"TRAC\",\"TRBC1\",\"TRBC2\",\"CD3D\",\"CD3E\",\n",
    "    \"CD4\",\"CD8A\",\"CD8B\",\n",
    "    \"KLRD1\",\"FCGR3A\",\n",
    "    \"JUN\",\"FOS\",\"IL32\",\"HLA-DRA\"\n",
    "]\n",
    "\n",
    "panel_symbols = []\n",
    "for _, genes in signatures.items():\n",
    "    panel_symbols += genes\n",
    "panel_symbols += markers_extra\n",
    "panel_symbols = list(dict.fromkeys(panel_symbols))  # dedup manteniendo orden\n",
    "\n",
    "adata_b = sc.read_h5ad(IN_PATH, backed=\"r\")\n",
    "\n",
    "try:\n",
    "    needed = [PATIENT_KEY, LEVEL1_REFINED_KEY, LEVEL2_KEY]\n",
    "    missing = [c for c in needed if c not in adata_b.obs.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Faltan columnas en obs: {missing}\")\n",
    "\n",
    "    # RBC-out sanity (informativo)\n",
    "    rbc_n = int((adata_b.obs[LEVEL2_KEY].astype(str) == \"RBC\").sum())\n",
    "    print(\"RBC cells (should be 0):\", rbc_n)\n",
    "\n",
    "    obs = adata_b.obs[[PATIENT_KEY, LEVEL1_REFINED_KEY, LEVEL2_KEY]].copy()\n",
    "    obs[PATIENT_KEY]        = obs[PATIENT_KEY].astype(str)\n",
    "    obs[LEVEL1_REFINED_KEY] = obs[LEVEL1_REFINED_KEY].astype(str)\n",
    "    obs[LEVEL2_KEY]         = obs[LEVEL2_KEY].astype(str)\n",
    "\n",
    "    # Subset: SOLO T (Level1_refined == T)\n",
    "    mask_T = (obs[LEVEL1_REFINED_KEY].values == \"T\")\n",
    "    nT = int(mask_T.sum())\n",
    "    print(\"T cells:\", nT)\n",
    "    if nT == 0:\n",
    "        raise ValueError(\"No hay células T en Level1_refined; esto no debería pasar.\")\n",
    "\n",
    "    # ¿Existe Conv_T_other?\n",
    "    n_conv = int((obs.loc[mask_T, LEVEL2_KEY].values == \"Conv_T_other\").sum())\n",
    "    print(\"Conv_T_other in T:\", n_conv)\n",
    "    if n_conv == 0:\n",
    "        raise ValueError(\n",
    "            \"No hay Conv_T_other en el objeto. Si ya lo eliminaste/renombraste, este notebook no aplica.\"\n",
    "        )\n",
    "\n",
    "    # map symbol -> varname (robusto a Ensembl)\n",
    "    panel_varnames = symbols_to_varnames(adata_b, panel_symbols)\n",
    "    kept = [(s, v) for s, v in zip(panel_symbols, panel_varnames) if v is not None]\n",
    "    missing_genes = [s for s, v in zip(panel_symbols, panel_varnames) if v is None]\n",
    "\n",
    "    if len(kept) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No se pudo mapear ningún gen del panel a var_names (ni por var['symbol']). \"\n",
    "            \"Revisa adata.var_names / adata.var['symbol'].\"\n",
    "        )\n",
    "\n",
    "    present_symbols = [s for s, _ in kept]\n",
    "    present_varnames = [v for _, v in kept]\n",
    "    varname_to_symbol = {v: s for s, v in kept}\n",
    "\n",
    "    print(\"Panel genes mapped:\", len(present_symbols), \"| missing:\", len(missing_genes))\n",
    "    if missing_genes:\n",
    "        print(\"[INFO] Missing genes (ok):\", missing_genes)\n",
    "\n",
    "    # Cargar a memoria SOLO T cells x panel genes\n",
    "    idx_T = np.where(mask_T)[0]\n",
    "    adata_small = adata_b[idx_T, present_varnames].to_memory()\n",
    "\n",
    "finally:\n",
    "    # cerrar backed siempre\n",
    "    try:\n",
    "        adata_b.file.close()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Layer preferida\n",
    "if LAYER not in adata_small.layers.keys():\n",
    "    raise KeyError(f\"No existe layer {LAYER} en el objeto; layers={list(adata_small.layers.keys())}\")\n",
    "\n",
    "print(\"adata_small:\", adata_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f787d4-c6cc-425d-bcea-79d86f0a6ec3",
   "metadata": {},
   "source": [
    "### 5. Tabla de expresión + medias por Level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3186c-9184-460c-975a-b739985fa241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tabla expresión por célula (panel) usando varnames, luego renombrar a símbolos\n",
    "df_expr = sc.get.obs_df(adata_small, keys=present_varnames, layer=LAYER, use_raw=False)\n",
    "df_expr = df_expr.rename(columns=varname_to_symbol)\n",
    "\n",
    "df_expr[LEVEL2_KEY] = adata_small.obs[LEVEL2_KEY].astype(str).values\n",
    "df_expr[PATIENT_KEY] = adata_small.obs[PATIENT_KEY].astype(str).values\n",
    "\n",
    "# Medias por Level2 (dentro de T) para marcadores del panel\n",
    "means_by_l2 = df_expr.groupby(LEVEL2_KEY)[present_symbols].mean()\n",
    "\n",
    "top_rows = []\n",
    "for l2 in means_by_l2.index:\n",
    "    s = means_by_l2.loc[l2].sort_values(ascending=False).head(25)\n",
    "    for g, v in s.items():\n",
    "        top_rows.append([l2, g, float(v)])\n",
    "\n",
    "top_df = pd.DataFrame(top_rows, columns=[LEVEL2_KEY, \"gene\", \"mean_log1p\"])\n",
    "out_top = OUT_DIR / \"QA_ConvT_other_topmarkers_meanlog1p.csv\"\n",
    "top_df.to_csv(out_top, index=False)\n",
    "print(\"Saved:\", out_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0334b-805c-480d-a10d-74eedf345b44",
   "metadata": {},
   "source": [
    "### 6. Scores de firmas por Level2 + guardado CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2797b40-7be3-4257-8719-c6780a270df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_rows = []\n",
    "for l2 in means_by_l2.index:\n",
    "    for sig, genes in signatures.items():\n",
    "        genes_ok = [g for g in genes if g in means_by_l2.columns]\n",
    "        if len(genes_ok) == 0:\n",
    "            score = np.nan\n",
    "        else:\n",
    "            score = float(means_by_l2.loc[l2, genes_ok].mean())\n",
    "        score_rows.append([l2, sig, score, len(genes_ok)])\n",
    "\n",
    "scores = pd.DataFrame(score_rows, columns=[LEVEL2_KEY, \"signature\", \"score_meanlog1p\", \"n_genes_used\"])\n",
    "scores_pivot = scores.pivot(index=LEVEL2_KEY, columns=\"signature\", values=\"score_meanlog1p\")\n",
    "\n",
    "out_scores = OUT_DIR / \"QA_ConvT_other_signature_scores.csv\"\n",
    "scores_pivot.to_csv(out_scores)\n",
    "print(\"Saved:\", out_scores)\n",
    "\n",
    "print(\"\\n=== Signature scores (Conv_T_other row) ===\")\n",
    "if \"Conv_T_other\" in scores_pivot.index:\n",
    "    print(scores_pivot.loc[[\"Conv_T_other\"]])\n",
    "else:\n",
    "    raise RuntimeError(\"No se encontró fila 'Conv_T_other' en scores_pivot (esto no debería pasar).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72053604-0af3-4571-9be6-23027265a130",
   "metadata": {},
   "source": [
    "### 7. Decisión automática reproducible + guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794f3fb-5b77-4621-8ccb-c32282fcf067",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_scores = scores_pivot.loc[\"Conv_T_other\"].dropna()\n",
    "if conv_scores.empty:\n",
    "    raise RuntimeError(\"Conv_T_other tiene todos los scores NaN; no se puede decidir mapping.\")\n",
    "\n",
    "best_sig = conv_scores.sort_values(ascending=False).index[0]\n",
    "best_val = float(conv_scores.loc[best_sig])\n",
    "\n",
    "# mapping final SOLO para Conv_T_other\n",
    "if best_sig == \"Naive_Memory_like\":\n",
    "    new_label = \"CD4_Memory\"\n",
    "elif best_sig == \"Cytotoxic_like\":\n",
    "    new_label = \"CD8_Effector_Cytotoxic\"     # merge\n",
    "elif best_sig == \"Treg_like\":\n",
    "    new_label = \"Treg\"                       # merge\n",
    "elif best_sig == \"Exhausted_like\":\n",
    "    new_label = \"Exhausted_T\"                # merge\n",
    "elif best_sig == \"Proliferative_like\":\n",
    "    new_label = \"Proliferative_T\"            # merge\n",
    "elif best_sig == \"ISG_like\":\n",
    "    new_label = \"ISG_T\"\n",
    "else:\n",
    "    new_label = \"T_Other\"\n",
    "\n",
    "level2_map = {\"Conv_T_other\": new_label}\n",
    "\n",
    "# Guardar mapping\n",
    "out_map = OUT_DIR / \"Level2_final_map.json\"\n",
    "with open(out_map, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(level2_map, f, indent=2)\n",
    "\n",
    "# Guardar decisión en TXT\n",
    "out_dec = OUT_DIR / \"ConvT_other_decision.txt\"\n",
    "with open(out_dec, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Conv_T_other decision\\n\")\n",
    "    f.write(f\"- best_signature: {best_sig}\\n\")\n",
    "    f.write(f\"- best_score_meanlog1p: {best_val:.6f}\\n\")\n",
    "    f.write(f\"- new_label: {new_label}\\n\")\n",
    "    f.write(f\"- n_cells_Conv_T_other (in T): {n_conv}\\n\")\n",
    "\n",
    "print(\"\\n=== DECISIÓN FINAL ===\")\n",
    "print(\"best_signature:\", best_sig)\n",
    "print(\"best_score_meanlog1p:\", best_val)\n",
    "print(\"Conv_T_other ->\", new_label)\n",
    "print(\"Saved:\", out_map)\n",
    "print(\"Saved:\", out_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fc786d-bd27-4eee-9ce0-05af44d628ad",
   "metadata": {},
   "source": [
    "### 8. QA final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911a2b2-2533-4bca-8c30-eae28a5e4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QA FINAL — Conv_T_other_cleanup\")\n",
    "print(\"=\"*80)\n",
    "print(\"Input:\", IN_PATH)\n",
    "print(\"Output dir:\", OUT_DIR)\n",
    "print(\"n_T_cells:\", int(nT))\n",
    "print(\"n_Conv_T_other_in_T:\", int(n_conv))\n",
    "print(\"Mapping JSON:\", out_map)\n",
    "print(\"Decision TXT:\", out_dec)\n",
    "print(\"=\"*80)\n",
    "print(\"\\n[OK] Conv_T_other caracterizado + mapping final generado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

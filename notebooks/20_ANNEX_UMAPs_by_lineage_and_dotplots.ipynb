{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8586da8-414b-4e35-bab2-f53a563b4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANNEX — UMAPs por linaje + dotplots de subanotación (Level2_final)\n",
    "# Reusa: OUT_FILTER + Level2_final_map.json + markers.py + overrides\n",
    "#\n",
    "# OUTPUTS:\n",
    "#   figures_final/annex_lineage_umap_dotplots/\n",
    "#     - Annex_UMAP_<linaje>_colored_by_Level2final.png\n",
    "#     - Annex_Dotplot_<linaje>_Level2final_2markers.png\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encuentro 'data_processed' subiendo desde: {start}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Paths\n",
    "# -----------------------------\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "OUT_FILTER = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "\n",
    "FIG_DIR = PROJECT_ROOT / \"figures_final\"\n",
    "OUT_SUM = PROJECT_ROOT / \"summary_tables_final\"\n",
    "ANNEX_DIR = FIG_DIR / \"annex_lineage_umap_dotplots\"\n",
    "ANNEX_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MAP_PATH = OUT_SUM / \"Level2_final_map.json\"\n",
    "EMB_PATH = OUT_SUM / \"UMAP_Harmony_embeddings.csv\"\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"OUT_FILTER  :\", OUT_FILTER)\n",
    "print(\"MAP_PATH    :\", MAP_PATH)\n",
    "print(\"EMB_PATH    :\", EMB_PATH)\n",
    "print(\"ANNEX_DIR   :\", ANNEX_DIR)\n",
    "\n",
    "if not OUT_FILTER.exists(): raise FileNotFoundError(OUT_FILTER)\n",
    "if not MAP_PATH.exists(): raise FileNotFoundError(MAP_PATH)\n",
    "if not EMB_PATH.exists(): raise FileNotFoundError(EMB_PATH)\n",
    "\n",
    "with open(MAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    level2_map = json.load(f)\n",
    "\n",
    "# -----------------------------\n",
    "# Import markers.py\n",
    "# -----------------------------\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from AI_Package.markers.markers import geneMarkers_level2, symbols_to_varnames\n",
    "\n",
    "# base Level2 -> genes (2+ por subtipo, según markers.py)\n",
    "lvl2_to_symbols = {}\n",
    "for _l1, subdict in geneMarkers_level2.items():\n",
    "    for _l2, genes in subdict.items():\n",
    "        if genes:\n",
    "            lvl2_to_symbols[_l2] = list(genes)\n",
    "\n",
    "# overrides EXACTOS (copiados de tu notebook final)\n",
    "OVERRIDE_2MARKERS = {\n",
    "    \"B_Other\":       [\"MS4A1\", \"CD74\"],\n",
    "    \"CD4_Memory\":    [\"IL7R\", \"CCR7\"],\n",
    "    \"ISG_Myeloid\":   [\"ISG15\", \"IFIT3\"],\n",
    "    \"MonoDC_Other\":  [\"LYZ\", \"FCER1G\"],\n",
    "    \"HSCs\":          [\"CD34\", \"KIT\"],\n",
    "    \"Plasma\":        [\"MZB1\", \"JCHAIN\"],\n",
    "    \"pDC\":           [\"IL3RA\", \"IRF7\"],\n",
    "}\n",
    "for l2, genes2 in OVERRIDE_2MARKERS.items():\n",
    "    if (l2 not in lvl2_to_symbols) or (len([g for g in lvl2_to_symbols.get(l2, []) if g]) < 2):\n",
    "        lvl2_to_symbols[l2] = genes2\n",
    "\n",
    "# orden final (consistente con Fig1C)\n",
    "order_by_group = {\n",
    "    \"B\":     [\"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"B_Other\"],\n",
    "    \"Plasma\":[\"Plasma\"],\n",
    "    \"pDC\":   [\"pDC\"],\n",
    "    \"T\":     [\"CD4_Naive\",\"CD4_Memory\",\"CD8_Naive\",\"CD8_Effector_Cytotoxic\",\"Treg\",\"MAIT\",\"GammaDelta_T\",\"Proliferative_T\",\"Exhausted_T\"],\n",
    "    \"NK\":    [\"NK\"],\n",
    "    \"Mono\":  [\"Classical_Mono\",\"NonClassical_Mono\",\"ISG_Myeloid\",\"MonoDC_Other\"],\n",
    "    \"DC\":    [\"cDC1\",\"cDC2\",\"DC4\",\"aDC\"],\n",
    "    \"HSCs\":  [\"HSCs\"],\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Load object in backed mode\n",
    "# -----------------------------\n",
    "adata_b = sc.read_h5ad(OUT_FILTER, backed=\"r\")\n",
    "\n",
    "need = [\"patientID\", \"disease\", \"Level1_refined\", \"Level2\"]\n",
    "missing = [c for c in need if c not in adata_b.obs.columns]\n",
    "if missing:\n",
    "    adata_b.file.close()\n",
    "    raise KeyError(f\"Faltan columnas en obs: {missing}\")\n",
    "\n",
    "obs = adata_b.obs[need].copy()\n",
    "obs.index = obs.index.astype(str)\n",
    "obs[\"Level2_final\"] = obs[\"Level2\"].astype(str).replace(level2_map).astype(str)\n",
    "\n",
    "# RBC-out para annex\n",
    "lineages = sorted(set(obs[\"Level1_refined\"].astype(str).unique()))\n",
    "lineages = [x for x in lineages if x != \"RBC\"]\n",
    "print(\"\\nLineages (Level1_refined, sin RBC):\", lineages)\n",
    "\n",
    "# -----------------------------\n",
    "# Load embeddings (CSV)\n",
    "# -----------------------------\n",
    "emb = pd.read_csv(EMB_PATH, index_col=0)\n",
    "emb.index = emb.index.astype(str)\n",
    "\n",
    "# columnas mínimas esperadas\n",
    "for c in [\"UMAP1_harmony\", \"UMAP2_harmony\", \"Level1_refined\", \"Level2_final\"]:\n",
    "    if c not in emb.columns:\n",
    "        adata_b.file.close()\n",
    "        raise KeyError(f\"Falta columna '{c}' en {EMB_PATH}. Tiene: {emb.columns.tolist()}\")\n",
    "\n",
    "# Alinear emb <-> obs por índice (células)\n",
    "common = emb.index.intersection(obs.index)\n",
    "if len(common) == 0:\n",
    "    adata_b.file.close()\n",
    "    raise ValueError(\n",
    "        \"No hay intersección entre índices de embeddings y obs del h5ad.\\n\"\n",
    "        \"Revisa que UMAP_Harmony_embeddings.csv use obs_names como índice.\"\n",
    "    )\n",
    "\n",
    "emb = emb.loc[common].copy()\n",
    "obs = obs.loc[common].copy()\n",
    "print(\"\\nCélulas alineadas (common):\", len(common))\n",
    "\n",
    "# ============================================================\n",
    "# Helpers\n",
    "# ============================================================\n",
    "sc.settings.autoshow = False\n",
    "\n",
    "def save_lineage_umap(df_sub: pd.DataFrame, out_png: Path, title: str):\n",
    "    # AnnData mínimo SOLO para plot\n",
    "    a = ad.AnnData(\n",
    "        X=np.zeros((df_sub.shape[0], 1), dtype=np.float32),\n",
    "        obs=df_sub[[\"disease\", \"Level1_refined\", \"Level2_final\"]].copy()\n",
    "    )\n",
    "    a.obsm[\"X_umap_harmony\"] = df_sub[[\"UMAP1_harmony\", \"UMAP2_harmony\"]].to_numpy().astype(np.float32)\n",
    "\n",
    "    ax = sc.pl.embedding(\n",
    "        a,\n",
    "        basis=\"umap_harmony\",\n",
    "        color=\"Level2_final\",\n",
    "        show=False,\n",
    "        frameon=False,\n",
    "        title=title,\n",
    "        legend_loc=\"right margin\",\n",
    "        legend_fontsize=6\n",
    "    )\n",
    "    fig = ax.figure\n",
    "    fig.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def make_lineage_dotplot(cell_ids, lineage: str, present_l2, out_png: Path):\n",
    "    # orden de subtipos: usa order_by_group si existe, si no, alphabetical\n",
    "    if lineage in order_by_group:\n",
    "        order = [l2 for l2 in order_by_group[lineage] if l2 in present_l2] + sorted(\n",
    "            [l2 for l2 in present_l2 if l2 not in order_by_group[lineage]]\n",
    "        )\n",
    "    else:\n",
    "        order = sorted(present_l2)\n",
    "\n",
    "    # genes: 2 por subtipo (dedup, orden estable)\n",
    "    gene_symbols = []\n",
    "    for l2 in order:\n",
    "        gene_symbols.extend(lvl2_to_symbols.get(l2, [])[:2])\n",
    "    seen = set()\n",
    "    gene_symbols = [g for g in gene_symbols if g and not (g in seen or seen.add(g))]\n",
    "\n",
    "    # map symbols -> var_names reales presentes\n",
    "    gene_varnames = symbols_to_varnames(adata_b, gene_symbols)\n",
    "    gene_varnames = [v for v in gene_varnames if v is not None]\n",
    "\n",
    "    if len(gene_varnames) == 0:\n",
    "        print(f\"[WARN] {lineage}: no se encontró ningún marcador en var_names.\")\n",
    "        return\n",
    "\n",
    "    # cargar solo genes necesarios, solo células del linaje (cell_ids = obs_names)\n",
    "    ad_view = adata_b[cell_ids, gene_varnames]\n",
    "    ad_mem = ad_view.to_memory()\n",
    "\n",
    "    # añadir Level2_final (ordenado)\n",
    "    ad_mem.obs[\"Level2_final\"] = obs.loc[ad_mem.obs_names, \"Level2_final\"].astype(str).values\n",
    "    ad_mem.obs[\"Level2_final\"] = pd.Categorical(ad_mem.obs[\"Level2_final\"], categories=order, ordered=True)\n",
    "\n",
    "    # layer preferido\n",
    "    use_layer = \"log1p_10k\" if \"log1p_10k\" in ad_mem.layers else None\n",
    "\n",
    "    dp = sc.pl.dotplot(\n",
    "        ad_mem,\n",
    "        var_names=gene_varnames,\n",
    "        groupby=\"Level2_final\",\n",
    "        layer=use_layer,\n",
    "        use_raw=False,\n",
    "        dendrogram=False,\n",
    "        standard_scale=\"var\",\n",
    "        show=False,\n",
    "        return_fig=True,\n",
    "    )\n",
    "    dp = dp.add_totals().style(dot_edge_color=\"black\", dot_edge_lw=0.5)\n",
    "    dp.savefig(out_png, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(\"all\")\n",
    "\n",
    "# ============================================================\n",
    "# LOOP por linaje: UMAP + Dotplot\n",
    "# ============================================================\n",
    "for lin in lineages:\n",
    "    print(\"\\n====\", lin, \"====\")\n",
    "\n",
    "    # subset por linaje usando embeddings (ya alineadas con obs)\n",
    "    df_sub = emb.loc[emb[\"Level1_refined\"].astype(str) == lin].copy()\n",
    "    if df_sub.shape[0] == 0:\n",
    "        print(\"[SKIP] sin células en embeddings\")\n",
    "        continue\n",
    "\n",
    "    # ---- UMAP por linaje ----\n",
    "    out_umap = ANNEX_DIR / f\"Annex_UMAP_{lin}_colored_by_Level2final.png\"\n",
    "    save_lineage_umap(df_sub, out_umap, title=f\"{lin} — UMAP (Harmony) colored by Level2_final\")\n",
    "    print(\"Saved:\", out_umap)\n",
    "\n",
    "    # ---- dotplot subanotación por linaje ----\n",
    "    # CAMBIO CLAVE: cell_ids = lista de obs_names (NO boolean mask)\n",
    "    mask_bool = (obs[\"Level1_refined\"].astype(str) == lin)\n",
    "    cell_ids = obs.index[mask_bool].tolist()\n",
    "\n",
    "    present_l2 = sorted(set(obs.loc[mask_bool, \"Level2_final\"].astype(str).unique()))\n",
    "    out_dot = ANNEX_DIR / f\"Annex_Dotplot_{lin}_Level2final_2markers.png\"\n",
    "    make_lineage_dotplot(cell_ids, lin, present_l2, out_dot)\n",
    "    print(\"Saved:\", out_dot)\n",
    "\n",
    "adata_b.file.close()\n",
    "print(\"\\n[OK] Annex generado en:\", ANNEX_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9669a9-bf86-4ecb-b052-4818c6a3de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CHECK: ¿UMAP_Harmony_embeddings.csv está alineado con OUT_FILTER.h5ad?\n",
    "# - Verifica columnas UMAP1/UMAP2\n",
    "# - Verifica que el índice (obs_names) coincide con el .h5ad\n",
    "# - Verifica solape y orden (si es 100% igual, perfecto)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(f\"No encuentro 'data_processed' subiendo desde: {start}\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "OUT_SUM = PROJECT_ROOT / \"summary_tables_final\"\n",
    "\n",
    "OUT_FILTER = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "EMB_PATH   = OUT_SUM / \"UMAP_Harmony_embeddings.csv\"\n",
    "\n",
    "print(\"OUT_FILTER:\", OUT_FILTER)\n",
    "print(\"EMB_PATH  :\", EMB_PATH)\n",
    "\n",
    "# --- load ---\n",
    "adata_b = sc.read_h5ad(OUT_FILTER, backed=\"r\")\n",
    "emb = pd.read_csv(EMB_PATH, index_col=0)\n",
    "\n",
    "# --- 1) columnas Harmony ---\n",
    "need_cols = [\"UMAP1_harmony\", \"UMAP2_harmony\"]\n",
    "missing_cols = [c for c in need_cols if c not in emb.columns]\n",
    "print(\"\\n[1] UMAP columns check:\")\n",
    "print(\"  missing_cols:\", missing_cols)\n",
    "if missing_cols:\n",
    "    raise KeyError(f\"Faltan columnas en EMB_PATH: {missing_cols}\")\n",
    "\n",
    "# --- 2) índices ---\n",
    "idx_h5ad = adata_b.obs_names\n",
    "idx_csv = emb.index.astype(str)\n",
    "\n",
    "print(\"\\n[2] Index sizes:\")\n",
    "print(\"  n_h5ad:\", len(idx_h5ad))\n",
    "print(\"  n_csv :\", len(idx_csv))\n",
    "\n",
    "set_h5ad = set(map(str, idx_h5ad))\n",
    "set_csv  = set(map(str, idx_csv))\n",
    "\n",
    "inter = set_h5ad & set_csv\n",
    "only_h5ad = set_h5ad - set_csv\n",
    "only_csv  = set_csv - set_h5ad\n",
    "\n",
    "print(\"\\n[3] Overlap:\")\n",
    "print(\"  intersection:\", len(inter), f\"({len(inter)/len(set_h5ad):.3%} of h5ad)\")\n",
    "print(\"  only_in_h5ad:\", len(only_h5ad))\n",
    "print(\"  only_in_csv :\", len(only_csv))\n",
    "\n",
    "# --- 3) ¿coinciden EXACTOS y en el mismo orden? ---\n",
    "exact_same = (len(idx_h5ad) == len(idx_csv)) and (list(map(str, idx_h5ad)) == idx_csv.tolist())\n",
    "print(\"\\n[4] Exact same index + same order?:\", exact_same)\n",
    "\n",
    "# --- 4) si NO es exacto, ¿al menos puedes reordenar el CSV al orden del h5ad?\n",
    "can_reorder = (len(only_h5ad) == 0) and (len(set_csv) >= len(set_h5ad))\n",
    "print(\"[5] Can reorder CSV to h5ad order (h5ad subset of csv)?:\", can_reorder)\n",
    "\n",
    "# muestra ejemplos si hay problemas\n",
    "if not exact_same:\n",
    "    if len(only_h5ad) > 0:\n",
    "        print(\"\\nEjemplos only_in_h5ad:\", list(sorted(only_h5ad))[:5])\n",
    "    if len(only_csv) > 0:\n",
    "        print(\"Ejemplos only_in_csv :\", list(sorted(only_csv))[:5])\n",
    "\n",
    "adata_b.file.close()\n",
    "\n",
    "print(\"\\n[OK] Check terminado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

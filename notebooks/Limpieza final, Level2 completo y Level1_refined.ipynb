{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d110e2-9af8-46e2-b3f4-1563b2e668a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBXX – Limpieza final, Level2 completo y Level1_refined\n",
    "# (MISMO NOTEBOOK que funcionaba, con el ÚNICO cambio de eliminar RBC de los outputs)\n",
    "# + HOTFIX post-NB09: excluir RBC_and_HSC y mapear DC3 como DC en Level1_refined\n",
    "\n",
    "# ============================================================\n",
    "# 0) Imports y paths\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Scanpy:\", sc.__version__)\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data_processed\").exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"No pude localizar la raíz del proyecto (no encuentro carpeta 'data_processed' en parents). \"\n",
    "        f\"Start={start}\"\n",
    "    )\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "DATA_PROCESSED = PROJECT_ROOT / \"data_processed\"\n",
    "\n",
    "IN_PATH = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_annotated.h5ad\"\n",
    "OUT_FULL   = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_annotated_clean.h5ad\"\n",
    "OUT_FILTER = DATA_PROCESSED / \"TFM_CIRRHOSIS_main_filtered_for_analysis.h5ad\"\n",
    "\n",
    "print(\"NOTEBOOK_DIR :\", NOTEBOOK_DIR)\n",
    "print(\"PROJECT_ROOT :\", PROJECT_ROOT)\n",
    "print(\"IN_PATH      :\", IN_PATH)\n",
    "print(\"OUT_FULL     :\", OUT_FULL)\n",
    "print(\"OUT_FILTER   :\", OUT_FILTER)\n",
    "\n",
    "if not IN_PATH.exists():\n",
    "    raise FileNotFoundError(f\"No existe IN_PATH:\\n{IN_PATH}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) Cargar objeto anotado y revisar estado actual\n",
    "# ============================================================\n",
    "adata = sc.read_h5ad(IN_PATH)\n",
    "print(adata)\n",
    "\n",
    "print(\"\\nColumnas obs:\")\n",
    "print(adata.obs.columns.tolist())\n",
    "\n",
    "print(\"\\nDistribución Level1:\")\n",
    "print(adata.obs[\"Level1\"].value_counts())\n",
    "\n",
    "if \"Level2\" in adata.obs.columns:\n",
    "    print(\"\\nDistribución Level2 (top 30):\")\n",
    "    print(adata.obs[\"Level2\"].value_counts().head(30))\n",
    "else:\n",
    "    print(\"\\n[AVISO] No existe columna 'Level2' en adata.obs.\")\n",
    "\n",
    "# Comprobar NaN en Level2 por Level1\n",
    "if \"Level2\" in adata.obs.columns:\n",
    "    print(\"\\nConteo de NaN en Level2 por Level1:\")\n",
    "    tmp = adata.obs.copy()\n",
    "    tmp[\"is_Level2_NA\"] = tmp[\"Level2\"].isna()\n",
    "    print(tmp.groupby(\"Level1\")[\"is_Level2_NA\"].sum())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) Completar Level2 para RBC / HSCs / Plasma / pDC\n",
    "# ============================================================\n",
    "LEVEL1_TO_LEVEL2_FILL = {\n",
    "    \"RBC\": \"RBC\",\n",
    "    \"HSCs\": \"HSCs\",\n",
    "    \"Plasma\": \"Plasma\",\n",
    "    \"pDC\": \"pDC\",\n",
    "}\n",
    "\n",
    "if \"Level2\" not in adata.obs.columns:\n",
    "    adata.obs[\"Level2\"] = np.nan\n",
    "\n",
    "lvl2 = adata.obs[\"Level2\"].astype(\"object\")\n",
    "\n",
    "for lvl1, lvl2_name in LEVEL1_TO_LEVEL2_FILL.items():\n",
    "    mask = (adata.obs[\"Level1\"] == lvl1) & (lvl2.isna())\n",
    "    n_before = mask.sum()\n",
    "    if n_before > 0:\n",
    "        print(f\"Asignando Level2='{lvl2_name}' a {n_before} células con Level1='{lvl1}' y Level2 NaN\")\n",
    "        lvl2.loc[mask] = lvl2_name\n",
    "    else:\n",
    "        print(f\"No hay células con Level1='{lvl1}' y Level2 NaN (n=0)\")\n",
    "\n",
    "adata.obs[\"Level2\"] = pd.Categorical(lvl2)\n",
    "\n",
    "print(\"\\nDistribución Level2 tras rellenar linajes simples:\")\n",
    "print(adata.obs[\"Level2\"].value_counts())\n",
    "\n",
    "print(\"NaN total en Level2 (DESPUÉS del fill):\", adata.obs[\"Level2\"].isna().sum())\n",
    "tmp = adata.obs.copy()\n",
    "tmp[\"is_Level2_NA\"] = tmp[\"Level2\"].isna()\n",
    "print(tmp.groupby(\"Level1\")[\"is_Level2_NA\"].sum())\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) Marcar poblaciones doublet-like / artefacto\n",
    "# ============================================================\n",
    "DOUBLETS_LEVEL2 = [\n",
    "    \"Platelet_like_T\",\n",
    "    \"T_NK_doublets\",\n",
    "    \"Myeloid_like_T\",\n",
    "]\n",
    "\n",
    "if not set(DOUBLETS_LEVEL2).issubset(set(adata.obs[\"Level2\"].cat.categories)):\n",
    "    print(\"\\n[INFO] Alguna categoría de DOUBLETS_LEVEL2 no está en Level2. Revisa la lista si hace falta.\")\n",
    "    print(\"Categorías Level2 actuales:\", adata.obs[\"Level2\"].cat.categories)\n",
    "\n",
    "adata.obs[\"doublet_like\"] = adata.obs[\"Level2\"].isin(DOUBLETS_LEVEL2)\n",
    "\n",
    "print(\"\\nConteo de doublet_like=True por Level2 (limpio, sin ceros):\")\n",
    "print(adata.obs.loc[adata.obs[\"doublet_like\"], \"Level2\"].astype(str).value_counts())\n",
    "\n",
    "print(\"\\nTotal doublets-like:\", int(adata.obs[\"doublet_like\"].sum()))\n",
    "print(\"Total células:\", adata.n_obs)\n",
    "\n",
    "# IMPORTANTE: NO filtramos aquí (para no duplicar memoria).\n",
    "# El filtrado se hace en la celda siguiente (“Crear objeto filtrado…”).\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) Crear objeto filtrado sin doublets y SIN RBC (RBC-out)\n",
    "# ============================================================\n",
    "adata_full = adata  # alias explícito por claridad\n",
    "\n",
    "# HOTFIX post-NB09:\n",
    "# - excluir RBC y RBC_and_HSC del filtrado (RBC-out robusto)\n",
    "RBC_LIKE_L1 = [\"RBC\", \"RBC_and_HSC\"]\n",
    "\n",
    "# Filtrado downstream (sin doublets) + RBC-out -> VISTA (view), NO copia\n",
    "mask_keep = (\n",
    "    (~adata_full.obs[\"doublet_like\"].to_numpy())\n",
    "    & (~adata_full.obs[\"Level1\"].astype(str).isin(RBC_LIKE_L1).to_numpy())\n",
    ")\n",
    "adata_filt = adata_full[mask_keep]  # <- NO .copy()\n",
    "\n",
    "print(\"\\n=== Resumen tras filtrar doublets + RBC-out (SIN COPY, no duplica RAM) ===\")\n",
    "print(adata_filt)\n",
    "print(\"\\nLevel1 (filtrado):\")\n",
    "print(adata_filt.obs[\"Level1\"].value_counts())\n",
    "print(\"\\nLevel2 (filtrado, top 30):\")\n",
    "print(adata_filt.obs[\"Level2\"].value_counts().head(30))\n",
    "\n",
    "print(\"Doublet categories after filter (should be 0):\")\n",
    "print(int(adata_filt.obs[\"Level2\"].isin(DOUBLETS_LEVEL2).sum()))\n",
    "\n",
    "print(\"RBC-like presentes en filtrado (debería ser 0):\")\n",
    "print(int(adata_filt.obs[\"Level1\"].astype(str).isin(RBC_LIKE_L1).sum()))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Construir Level1_refined (T vs NK, Mono vs DC…)\n",
    "# ============================================================\n",
    "# 1) Empezamos con Level1_refined = Level1\n",
    "adata_filt.obs[\"Level1_refined\"] = adata_filt.obs[\"Level1\"].astype(\"object\")\n",
    "\n",
    "# Subtipos T dentro de T_and_NK\n",
    "T_L2 = [\n",
    "    \"CD4_Naive\",\n",
    "    \"CD8_Naive\",\n",
    "    \"CD8_Effector_Cytotoxic\",\n",
    "    \"Conv_T_other\",\n",
    "    \"MAIT\",\n",
    "    \"GammaDelta_T\",\n",
    "    \"Treg\",\n",
    "    \"Proliferative_T\",\n",
    "    \"Exhausted_T\",\n",
    "]\n",
    "\n",
    "NK_L2 = [\"NK\"]\n",
    "\n",
    "MONO_L2 = [\n",
    "    \"Classical_Mono\",\n",
    "    \"NonClassical_Mono\",\n",
    "    \"ISG_Myeloid\",\n",
    "    \"MonoDC_Other\",\n",
    "]\n",
    "\n",
    "# HOTFIX post-NB09: incluir DC3 como DC\n",
    "DC_L2 = [\n",
    "    \"cDC1\",\n",
    "    \"cDC2\",\n",
    "    \"DC4\",\n",
    "    \"aDC\",\n",
    "    \"DC3\",\n",
    "]\n",
    "\n",
    "# Linajes simples que se mantienen tal cual\n",
    "# (RBC está aquí por consistencia con el histórico, pero ya no está en adata_filt por RBC-out)\n",
    "SIMPLE_L1 = [\"B\", \"Plasma\", \"pDC\", \"RBC\", \"HSCs\"]\n",
    "\n",
    "# a) Linajes simples\n",
    "mask_simple = adata_filt.obs[\"Level1\"].isin(SIMPLE_L1)\n",
    "print(f\"[INFO] Linajes simples (B/Plasma/pDC/RBC/HSCs): {mask_simple.sum()} células\")\n",
    "\n",
    "# b) Dentro de T_and_NK: separar T vs NK (usando Level2)\n",
    "mask_TNK = adata_filt.obs[\"Level1\"] == \"T_and_NK\"\n",
    "mask_T = mask_TNK & adata_filt.obs[\"Level2\"].isin(T_L2)\n",
    "mask_NK = mask_TNK & adata_filt.obs[\"Level2\"].isin(NK_L2)\n",
    "\n",
    "print(f\"[INFO] T subtypes dentro de T_and_NK      → 'T'  : {mask_T.sum()} células\")\n",
    "print(f\"[INFO] NK subtypes dentro de T_and_NK     → 'NK' : {mask_NK.sum()} células\")\n",
    "\n",
    "adata_filt.obs.loc[mask_T, \"Level1_refined\"] = \"T\"\n",
    "adata_filt.obs.loc[mask_NK, \"Level1_refined\"] = \"NK\"\n",
    "\n",
    "# c) Dentro de Mono_and_DC: separar Mono vs DC (usando Level2)\n",
    "mask_MonoDC = adata_filt.obs[\"Level1\"] == \"Mono_and_DC\"\n",
    "mask_Mono = mask_MonoDC & adata_filt.obs[\"Level2\"].isin(MONO_L2)\n",
    "mask_DC   = mask_MonoDC & adata_filt.obs[\"Level2\"].isin(DC_L2)\n",
    "\n",
    "print(f\"[INFO] Mono subtypes dentro de Mono_and_DC → 'Mono': {mask_Mono.sum()} células\")\n",
    "print(f\"[INFO] DC subtypes dentro de Mono_and_DC   → 'DC'  : {mask_DC.sum()} células\")\n",
    "\n",
    "adata_filt.obs.loc[mask_Mono, \"Level1_refined\"] = \"Mono\"\n",
    "adata_filt.obs.loc[mask_DC,   \"Level1_refined\"] = \"DC\"\n",
    "\n",
    "print(\"\\n[CHECK] Distribución final de Level1_refined:\")\n",
    "print(adata_filt.obs[\"Level1_refined\"].value_counts())\n",
    "\n",
    "# HOTFIX: incluir DC3 también en el universo esperado\n",
    "ALL_KNOWN_L2 = set(\n",
    "    T_L2 + NK_L2 + MONO_L2 + DC_L2 +\n",
    "    [\n",
    "        \"B_Naive\", \"B_Memory\", \"B_Activated\", \"B_Atypical\", \"B_Other\",\n",
    "        \"RBC\", \"HSCs\", \"Plasma\", \"pDC\",\n",
    "        \"DC3\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "l2_present = set(pd.Series(adata_filt.obs[\"Level2\"]).dropna().unique())\n",
    "unknown_l2 = sorted(l2_present - ALL_KNOWN_L2)\n",
    "\n",
    "print(\"\\n[CHECK] Level2 presentes en el objeto que NO están en las listas esperadas:\")\n",
    "print(unknown_l2)\n",
    "\n",
    "bad = adata_filt.obs[\"Level1_refined\"].isin([\"T_and_NK\", \"Mono_and_DC\"]).sum()\n",
    "print(\"Cells still labeled T_and_NK / Mono_and_DC in Level1_refined:\", int(bad))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) (Opcional) Eliminar columna Type_L1L2\n",
    "# ============================================================\n",
    "for col in [\"Type_L1L2\", \"TypeL1L2\"]:\n",
    "    if col in adata_full.obs.columns:\n",
    "        print(f\"Eliminando columna '{col}' de adata_full.obs\")\n",
    "        del adata_full.obs[col]\n",
    "    if col in adata_filt.obs.columns:\n",
    "        print(f\"Eliminando columna '{col}' de adata_filt.obs\")\n",
    "        del adata_filt.obs[col]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) Guardar objetos finales (OUT_FULL sin RBC; OUT_FILTER ya sin RBC)\n",
    "# ============================================================\n",
    "# Asegurarnos de que las nuevas columnas son categóricas donde tiene sentido\n",
    "adata_full.obs[\"Level2\"] = adata_full.obs[\"Level2\"].astype(\"category\")\n",
    "adata_full.obs[\"doublet_like\"] = adata_full.obs[\"doublet_like\"].astype(bool)\n",
    "\n",
    "# IMPORTANTE RBC-out: quitamos categorías no usadas en el filtrado para que RBC no \"aparezca\" como categoría vacía\n",
    "if pd.api.types.is_categorical_dtype(adata_filt.obs[\"Level2\"]):\n",
    "    adata_filt.obs[\"Level2\"] = adata_filt.obs[\"Level2\"].cat.remove_unused_categories()\n",
    "\n",
    "adata_filt.obs[\"Level2\"] = adata_filt.obs[\"Level2\"].astype(\"category\")\n",
    "adata_filt.obs[\"Level1_refined\"] = adata_filt.obs[\"Level1_refined\"].astype(\"category\")\n",
    "adata_filt.obs[\"doublet_like\"] = adata_filt.obs[\"doublet_like\"].astype(bool)\n",
    "\n",
    "print(\"\\nGuardando objeto completo (con doublets marcados) en (RBC-out):\")\n",
    "print(\" \", OUT_FULL)\n",
    "adata_full[~adata_full.obs[\"Level1\"].astype(str).isin(RBC_LIKE_L1)].write_h5ad(OUT_FULL, compression=\"gzip\")\n",
    "\n",
    "print(\"\\nGuardando objeto filtrado (sin doublets, con Level1_refined) en (ya RBC-out):\")\n",
    "print(\" \", OUT_FILTER)\n",
    "adata_filt.write_h5ad(OUT_FILTER, compression=\"gzip\")\n",
    "\n",
    "print(\"\\n[OK] Guardado completado.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) Mini-check final (sanity check rápido)\n",
    "# ============================================================\n",
    "print(\"=== CHECK FINAL ===\")\n",
    "print(\"Objeto completo (en RAM) :\", adata_full)\n",
    "print(\"Objeto filtrado (en RAM) :\", adata_filt)\n",
    "\n",
    "print(\"\\nLevel1_refined en adata_filt:\")\n",
    "print(adata_filt.obs[\"Level1_refined\"].value_counts())\n",
    "\n",
    "print(\"\\nDoublets en adata_full (deberían ser > 0) y en adata_filt (debería ser 0):\")\n",
    "print(\"doublet_like True en full :\", int(adata_full.obs[\"doublet_like\"].sum()))\n",
    "print(\"doublet_like True en filt :\", int(adata_filt.obs[\"doublet_like\"].sum()))\n",
    "\n",
    "print(\"\\nRBC-like en adata_filt (debería ser 0):\", int((adata_filt.obs[\"Level1\"].astype(str).isin(RBC_LIKE_L1)).sum()))\n",
    "print(\"Conv_T_other count (filtrado):\", int(adata_filt.obs[\"Level2\"].value_counts().get(\"Conv_T_other\", 0)))\n",
    "print(\"DC3 count (filtrado):\", int(adata_filt.obs[\"Level2\"].value_counts().get(\"DC3\", 0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfm_scRNA)",
   "language": "python",
   "name": "tfm_scrna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
